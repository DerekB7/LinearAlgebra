{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that julia code can be run for free at:\n",
    "https://juliabox.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_rows = 9\n",
    "n_cols = 12\n",
    "# both should be integers\n",
    "\n",
    "assert(m_rows < n_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable values: \n",
      "[0.431642,-0.47488,0.0,-1.20209,-0.599423,-0.931772,0.0,-0.452475,-0.581162,0.0,-0.527145,-0.425087]\n"
     ]
    }
   ],
   "source": [
    "# the snow plowing problem, part B\n",
    "# this was also posted online, and saved in \"diet_problem_recut_somewhat.ipynb\"\n",
    "\n",
    "# idea, for a short wide matrix -- i.e. full row rank but underdetermined sytem of equations -- \n",
    "# perhaps we want to select a solution vector x, in the form Ax = b, but we want (a non-unique) x \n",
    "# that has the minimum L1 norm\n",
    "# note that using primal simplex means our resulting vector should be sparse\n",
    "# note that we have closed form / analytic solutions for the case of underdetermined system of equations, \n",
    "# and we want to minimize the L2 norm of the solution vector x\n",
    "# however for the L1 norm case, it is just a linear programming approach\n",
    "\n",
    "using JuMP\n",
    "\n",
    "mymodel = Model()\n",
    "\n",
    "\n",
    "A = randn(m_rows, n_cols) \n",
    "b = randn(m_rows)\n",
    "# iid standard normal r.v.'s populate these matrices\n",
    "# note that (in standard form) there is zero probability of A not having full row rank\n",
    "\n",
    "\n",
    "@variable(mymodel,    x[i = 1:n_cols] ) \n",
    "@variable(mymodel,    y[i = 1:n_cols] >= 0) \n",
    "@constraint(mymodel, -y .<= x)\n",
    "@constraint(mymodel,  y .>= x)\n",
    "# in effect y is the absolute value version of x\n",
    "\n",
    "@constraint(mymodel, *(A,x) .== b)\n",
    "# always need to maintain this equality\n",
    "\n",
    "@objective(mymodel, Min, sum(y))\n",
    "# minimize the L1 norm\n",
    "\n",
    "# Solve the optimization problem\n",
    "solve(mymodel)\n",
    "println(\"Variable values: \\n\", getvalue(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{Float64,1}:\n",
       " 0.431642\n",
       " 0.47488 \n",
       " 0.0     \n",
       " 1.20209 \n",
       " 0.599423\n",
       " 0.931772\n",
       " 0.0     \n",
       " 0.452475\n",
       " 0.581162\n",
       " 0.0     \n",
       " 0.527145\n",
       " 0.425087"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getvalue(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
