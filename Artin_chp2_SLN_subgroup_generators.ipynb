{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is there a way to streamline the argument using the fact that kernels give normal subgroups?  \n",
    "\n",
    "I.e. consider $SL_n(\\mathbb R)$ as the kernel of $GL_n(\\mathbb R)$ under the determinant homomorphism.  It's immediate from results in chapter 2 that this is a normal subgroup.  I wonder if this implies all generators are elementary matrices of type 1 -- i.e. because all other generators (ignoring trivial case of identity matrix) have nonzero determinant $\\neq 1$    \n",
    "\n",
    "if we tweak the problem to consider  \n",
    "$SL_n(\\mathbb F)$ is a subgroup of $GL_n(\\mathbb F)$  \n",
    "where $\\mathbb F$ is a finite field (introduced in chapter 3) the below results follow because $SL_n(\\mathbb F)$ is a (sub)group that contains all elementary matrices of type 1.  for any natural number $n$ and and prime characteristic $p$, there are necessarily finitely many matrices in  $GL_n(\\mathbb F)$ which implies finitely many in $SL_n(\\mathbb F)$.  If we consider the group table or graph.... but I'm not quite sure this holds... I need to think more about these paths....  \n",
    "\n",
    "idea would be doing this in $SL_n(\\mathbb F_p)$ should imply the result in $SL_n(\\mathbb Q)$ when all coefficients are written as integers (i.e. after clearing the denominator), by selecting large enough $p$ for the finite field 'equivalent'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 2 Subgroups \n",
    "\n",
    "**18**   \n",
    "part (a) is deferred until the end, as it is implied by the more difficult part (c) \n",
    "\n",
    "**(b)**   \n",
    "$SL_n(\\mathbb R)$   \n",
    "is a subgroup of $GL_n(\\mathbb R)$  \n",
    "\n",
    "\n",
    "i.) $\\mathbf A \\in SL_n(\\mathbb R) \\longrightarrow \\mathbf A\\in GL_n(\\mathbb R)$  since $\\mathbf A$ is n x n with non-zero determinant   \n",
    "ii.) closure: $\\mathbf A^{(1)}, \\mathbf A^{(2)} \\in SL_n(\\mathbb R) \\longrightarrow \\big(\\mathbf A^{(1)}\\mathbf A^{(2)} \\big) \\in SL_n(\\mathbb R)$ because $\\det\\big(\\mathbf A^{(1)}\\mathbf A^{(2)}\\big) = \\det\\big(\\mathbf A^{(1)}\\big)\\det\\big(\\mathbf A^{(2)}\\big) = 1\\cdot 1 = 1$  \n",
    "iii.) identity: $\\det\\big(\\mathbf I\\big) = 1\\longrightarrow \\mathbf I \\in SL_n(\\mathbb R)$    \n",
    "iv.) inverses:  $\\mathbf A^{-1} \\in SL_n(\\mathbb R)$ for $  \\mathbf A \\in SL_n(\\mathbb R)$ as both have determinant of 1  \n",
    "\n",
    "\n",
    "**(c)**    \n",
    "This is an asterisk'd problem i.e. marked as a challenge problem  \n",
    "(note in the case of $n=1$, there is nothing to do as a 1 x 1 matrix with determinant one is just the scalar of 1.)  \n",
    "\n",
    "we want to prove that $ \\mathbf A \\in SL_n(\\mathbb R)$ is generated by elementary matrices of the first type i.e. triangular matrices with ones on the diagonal (i.e. the only elementary matrices with determinant 1 -- which is a case of the determinant homomorphism shedding a *lot* of insight)   \n",
    "\n",
    "approach: prove it for the 2 x 2 case then proceed by induction  \n",
    "\n",
    "*a special case of interest*  \n",
    "diagonal matrices \n",
    "\n",
    "$\\begin{bmatrix}\n",
    "a_{1,1} & 0\\\\ \n",
    " 0 & a_{1,1}^{-1}\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "while we would typically split this into the product of 2 elementary matrices of the third type, we could e.g. multiply by an elementary matrices  of the 1st type to get  \n",
    "\n",
    "$\\mathbf E_2\\mathbf E_1\\begin{bmatrix}\n",
    "a_{1,1} & 0\\\\ \n",
    " 0 & a_{1,1}^{-1}\n",
    "\\end{bmatrix} = \\mathbf E_2 \\begin{bmatrix}\n",
    "a_{1,1} & 0\\\\ \n",
    " d\\cdot a_{1,1} & a_{1,1}^{-1}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "(1+\\gamma d )a_{1,1} & \\gamma a_{1,1}^{-1}\\\\ \n",
    " d\\cdot a_{1,1} & a_{1,1}^{-1}\n",
    "\\end{bmatrix}$     \n",
    "\n",
    "where our matrix looks a lot more like a \"regular\" 2x2 matrix.  So if we reason backwards for some arbitrary matrix that is 2x2 with determinant 1,\n",
    "$\\begin{bmatrix}\n",
    "a & c\\\\ \n",
    " d & b\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "we want the diagonal components to be each 1 before we do row reduction.  \n",
    "\n",
    "*remark:*  \n",
    "this problem is done over reals as finite fields are not introduced until the next chapter.  The result should work in essentially the same way except for finite fields though results are pecuiliar in fields of characteristic 2 since SLN and GLN are the same.  We also would have to settle for upper triangular form \n",
    "$\\begin{bmatrix}\n",
    "a & c\\\\ \n",
    " 0 & b\n",
    "\\end{bmatrix}$  \n",
    "as we couldn't make all components nonzero in $\\mathbb F_2$, otherwise it would be the ones matrix with determinant 0.  \n",
    "\n",
    "\n",
    "**Lemma:** $SL_2(\\mathbb R)$   **is generated by elementary matrices of the first type**  \n",
    "\n",
    "we have   \n",
    "$\\mathbf A = \\begin{bmatrix}\n",
    "a & c\\\\ \n",
    " d & b\n",
    "\\end{bmatrix}$  \n",
    "and know  \n",
    "$\\det\\big(\\mathbf A\\big) = ab - cd = 1$  \n",
    "this proof will try to cover all essential steps without getting bogged down in minutiae   \n",
    "\n",
    "note if $a,b$ each equal $1$ and $c,d =0$, then there is nothing to do.  The below assumes that this isn't the case.  \n",
    "\n",
    "*main idea:*  \n",
    "apply elementary matrices \n",
    "$\\mathbf E_{-1}$ and $\\mathbf E_{-2}$ as preparation so that \n",
    "\n",
    "$\\mathbf A = \\begin{bmatrix}\n",
    "a' & c'\\\\ \n",
    " d' & b'\n",
    "\\end{bmatrix}$   \n",
    "\n",
    "where each component is nonzero  \n",
    "\n",
    "with  \n",
    "$\\mathbf E_1 = \\begin{bmatrix}\n",
    "1 & \\gamma_1 \\\\ \n",
    " 0 & 1\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "where  \n",
    "$a' + \\gamma_1 d' = 1$  i.e. $\\gamma_1 = (-a' +1)\\cdot (d')^{-1}$   \n",
    "\n",
    "so we have   \n",
    "\n",
    "$\\mathbf E_1 \\mathbf A = \\begin{bmatrix}\n",
    "1 & c''\\\\ \n",
    " d'' & b''\n",
    "\\end{bmatrix}$   \n",
    "\n",
    "now with  \n",
    "$\\mathbf E_2 = \\begin{bmatrix}\n",
    "1 & 0 \\\\ \n",
    " \\gamma_2 & 1\n",
    "\\end{bmatrix}$   \n",
    "we have  \n",
    "\n",
    "$\\mathbf E_2 \\mathbf E_1 \\mathbf A = \\begin{bmatrix}\n",
    "1 & c'''\\\\ \n",
    " d''' & 1\n",
    "\\end{bmatrix}$  \n",
    "the determinant is still 1 since  \n",
    "$\\det\\big(\\mathbf E_2 \\mathbf E_1 \\mathbf A\\big)=\\det\\big(\\mathbf E_2\\big) \\det\\big(\\mathbf E_1\\big) \\det\\big( \\mathbf A\\big) = 1 \\cdot 1 \\cdot 1 = 1$  \n",
    "\n",
    "so we know  \n",
    "\n",
    "$c''' \\cdot d''' = 0$  \n",
    "\n",
    "i.e. at least one component is 0.  WLOG we can assume $d''' = 0$ (i.e. if not the case, transpose and run the below process on the transposed matrix, then transpose back at the end), so  \n",
    "\n",
    "$\\mathbf E_2 \\mathbf E_1 \\mathbf A = \\begin{bmatrix}\n",
    "1 & c'''\\\\ \n",
    " 0 & 1\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "now select  \n",
    "\n",
    "$\\mathbf E_3 = \\begin{bmatrix}\n",
    "1 & -c''' \\\\ \n",
    " 0 & 1\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "and we have  \n",
    "\n",
    "$\\mathbf E_3\\mathbf E_2 \\mathbf E_1 \\mathbf A = \\mathbf I$  \n",
    "\n",
    "hence \n",
    "$\\mathbf A^{-1} = \\mathbf E_3\\mathbf E_2 \\mathbf E_1$  \n",
    "\n",
    "\n",
    "$\\mathbf A = \\big( \\mathbf E_3\\mathbf E_2 \\mathbf E_1\\big)^{-1}= \\big(\\mathbf E_1^{-1}\\mathbf E_2^{-1}\\mathbf E_3^{-1}\\big) $   \n",
    "i.e. $\\mathbf A$ is generated by elementary matrices of the first type   \n",
    "\n",
    "(for an alternative close, re-run the above argument on $\\mathbf B \\in SL_{n}(\\mathbb R)$ to see \n",
    "$\\mathbf E_3\\mathbf E_2 \\mathbf E_1 \\mathbf B = \\mathbf I$, and select $\\mathbf B:= \\mathbf A^{-1}$ which implies in this case that $\\mathbf A = \\mathbf E_3\\mathbf E_2 \\mathbf E_1$. The conclusion in either case is that $\\mathbf A$ is generated by elementary matrices of the first type.)  \n",
    "\n",
    "- - - - -  \n",
    "we now have a lemma that any 2x2 matrix with determinant 1 is generated by elementary matrices of the first type  \n",
    "\n",
    "**corollary:**  \n",
    "\n",
    "any n x n diagonal matrix of the form  \n",
    "$\\mathbf D = \\begin{bmatrix}\n",
    "(a_{1,1}')^{-1} & 0 & \\mathbf 0^T\\\\ \n",
    "0 & a_{1,1}' & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}$    \n",
    "is generated by elementary matrices of the first type, by blocked multiplication of matrices, and application of the above lemma.  I.e. \n",
    "\n",
    "\n",
    "$\\mathbf D = \\begin{bmatrix}\n",
    "\\mathbf E_3 & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\mathbf E_2 & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\mathbf E_1 & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\mathbf E_{-1} & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\mathbf E_{-2} & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}$    \n",
    "\n",
    "- - - - -  \n",
    "**inductive proof that all of** $SL_n(\\mathbb R)$  **is generated by elementary matrices of the first type** \n",
    "\n",
    "**base case**  \n",
    "direct application of the Lemma   \n",
    "\n",
    "**inductive case**  \n",
    "by inductive hypothesis, we know that a member of  $SL_{n-1}(\\mathbb R)$ is generated by elementary matrices of the first type.  The plan of attack is to reduce the n dimensional matrix case to the the n-1 dimensional case by first zeroing everything but the diagonal component in column one, and in row one.  Then we call on our inductive hypothesis.  For natural number $n\\geq 3$    \n",
    "\n",
    "we consider    \n",
    "$\\mathbf A^{-1} \\in SL_{n}(\\mathbb R)$  \n",
    "\n",
    "from chapter 1 we know we may apply a sequence of elementary matrices (of the first type) to the left of $\\mathbf A^{-1}$ to reduce it to having all zeros in the first column below the diagonal.  i.e.  \n",
    "\n",
    "$\\mathbf B = \\mathbf E_k\\mathbf E_{k-1}\\dots \\mathbf E_1\\mathbf A^{-1} = \\begin{bmatrix}\n",
    "\\alpha & \\mathbf v^T\\\\ \n",
    "\\mathbf 0 & \\mathbf X\n",
    "\\end{bmatrix}$    \n",
    "\n",
    "where $\\mathbf Y \\in \\mathbb R^\\text{(n-1) x (n-1)}$   \n",
    "\n",
    "and by further reduction we have  \n",
    "$\\mathbf E_r\\mathbf E_{r-1}\\dots \\mathbf E_{k+1} \\mathbf A^{-1}\\mathbf E_1\\dots \\mathbf E_{k-1}\\mathbf E_k   =  \\begin{bmatrix}\n",
    "a_{1,1}' & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Y\n",
    "\\end{bmatrix}$     \n",
    "\n",
    "*remark:*   \n",
    "If from the outset that the top left corner of  $\\mathbf A^{-1}$ is $\\neq 0$, then the above argument works smoothly.  If that is not the case, we can observe that at least one component of the top row of $\\mathbf A^{-1}$  must be non-zero (or else determinant is zero), so applying a (lower triangular) elementary matrix of type one to the right of $\\mathbf A^{-1}$  then given a resulting matrix whose top left corner is nonzero; to streamline this we just assume WLOG that the top left corner is non-zero to begin with.   \n",
    "\n",
    "\n",
    "= = = = = =    \n",
    "*chapter 3 note*  \n",
    "\n",
    "The first leg of this is equivalent to noting that we have a rank n matrix so there are n linearly independent vectors.  If we delete the first row we now have n-1 linearly independent vectors which form a basis in the n-1 space, and hence the first column of this short fat matrix may be written as a linear combination of these vectors.  In the edge case where this short fat matrix $\\mathbf F$ has $\\mathbf x \\neq \\mathbf 0$ and $\\mathbf F \\mathbf x = \\mathbf 0$ but $x_1 =0$, we can consider $x_j = \\gamma \\neq 0$  first apply an elementary matrix to the right of $\\mathbf A^{-1}$, i.e. before truncation, where the elementary matrix adds $1$ times the first column of $\\mathbf A^{-1}$.  Then after deleting the first row, and revisiting $\\mathbf F' \\mathbf x' = \\mathbf 0$ we'd see $x_1'= -\\gamma \\neq 0$ and hence we'd have the desired linear dependent relation.  \n",
    "\n",
    "the second leg is conceptually simpler as we'd have isolated $\\alpha \\neq 0$ in the first stage (we know it isn't zero because if it was then the entire first column would be zero and the matrix would have zero determinant, a contradiction) and we simply apply elementary matrices of the first type on the right, subtracting the appropriate scaled amount of $\\alpha$ from each cell in the first row, in column $j=2,3,...,n$  \n",
    "\n",
    "= = = = = =   \n",
    "now we know   \n",
    "\n",
    "$\\det\\Big(\\begin{bmatrix}\n",
    "a_{1,1}' & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Y\n",
    "\\end{bmatrix}\\Big) = a_{1,1}' \\cdot \\big(\\mathbf Y\\big) = 1$  \n",
    "$= \\det\\big(\\mathbf E_r\\big)\\det\\big(\\mathbf E_{r-1}\\big)\\dots \\det\\big(\\mathbf E_{k+1}\\big)\\det\\big(\\mathbf A^{-1}\\big)\\det\\big(\\mathbf E_1\\big)\\dots \\det\\big(\\mathbf E_{k-1}\\big)\\det\\big(\\mathbf E_k\\big) = 1\\cdot 1 \\cdot .... \\cdot 1 \\cdot 1$   \n",
    "\n",
    "\n",
    "now consider  \n",
    "$\\begin{bmatrix}\n",
    "a_{1,1}' & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Y\n",
    "\\end{bmatrix}\\mathbf D = \\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z\n",
    "\\end{bmatrix}$  \n",
    "\n",
    "or  \n",
    "\n",
    "$\\begin{bmatrix}\n",
    "a_{1,1}' & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Y\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z\n",
    "\\end{bmatrix}\\mathbf D^{-1}$  \n",
    "\n",
    "with  \n",
    "$\\mathbf D = \\begin{bmatrix}\n",
    "\\frac{1}{a_{1,1}'} & 0 & \\mathbf 0^T\\\\ \n",
    "0 & a_{1,1}' & \\mathbf 0^T\\\\ \n",
    " \\mathbf 0 & \\mathbf 0 & \\mathbf I_{n-2}\n",
    "\\end{bmatrix}$   \n",
    "\n",
    "so $\\det\\big(\\mathbf D\\big) = 1$  which implies $\\det\\big(\\mathbf Z\\big)= 1$  \n",
    "\n",
    "and by induction hypothesis since $\\mathbf Z \\in SL_{n-1}(\\mathbb R)$ we know that it is generated by type 1 elementary matrices which we can embed via blocked multiplication   \n",
    "\n",
    "i.e.  \n",
    "$\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf E_{m}^{(n-1)}\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf E_{m-1}^{(n-1)}\n",
    "\\end{bmatrix}\\dots\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf E_1^{(n-1)}\n",
    "\\end{bmatrix}$   \n",
    "\n",
    "note:  since $SL_{n-1}(\\mathbb R)$ is a subgroup, this immediately tells us that $\\mathbf Z^{-1}$ is generated by type one elementary matrices as well.  \n",
    "\n",
    "*and*  \n",
    "by our corollary we know $\\mathbf D$ and its inverse, is generated by type 1 elementary matrices.  \n",
    "so putting this all together we have  \n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z\n",
    "\\end{bmatrix}\\mathbf D^{-1}= \\mathbf E_r\\mathbf E_{r-1}\\dots \\mathbf E_{k+1} \\mathbf A^{-1}\\mathbf E_1\\dots \\mathbf E_{k-1}\\mathbf E_k   =  \\begin{bmatrix}\n",
    "a_{1,1}' & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Y\n",
    "\\end{bmatrix} $  \n",
    "\n",
    "or  \n",
    "\n",
    "$\\mathbf I_n = \\big(\\mathbf D\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z\n",
    "\\end{bmatrix}^{-1}\\mathbf E_r\\mathbf E_{r-1}\\dots \\mathbf E_{k+1}\\big) \\big(\\mathbf A^{-1}\\mathbf E_1\\dots \\mathbf E_{k-1}\\mathbf E_k\\big) $  \n",
    "$= \\big(\\mathbf A^{-1}\\mathbf E_1\\dots \\mathbf E_{k-1}\\mathbf E_k\\big)\\big(\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z^{-1}\n",
    "\\end{bmatrix}\\mathbf D\\mathbf E_r\\mathbf E_{r-1}\\dots \\mathbf E_{k+1}\\big)    $  \n",
    "$= \\big(\\mathbf A^{-1}\\big)\\big(\\mathbf E_1\\dots \\mathbf E_{k-1}\\mathbf E_k\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z^{-1}\n",
    "\\end{bmatrix}\\mathbf D\\mathbf E_r\\mathbf E_{r-1}\\dots \\mathbf E_{k+1}\\big)    $  \n",
    "\n",
    "which implies that \n",
    "\n",
    "$\\big(\\mathbf A^{-1}\\big)^{-1}=\\mathbf A = \\mathbf E_1\\dots \\mathbf E_{k-1}\\mathbf E_k\\begin{bmatrix}\n",
    "1 & \\mathbf 0^T\\\\ \n",
    "\\mathbf 0 & \\mathbf Z^{-1}\n",
    "\\end{bmatrix}\\mathbf D\\mathbf E_r\\mathbf E_{r-1}\\dots \\mathbf E_{k+1}  $\n",
    "\n",
    "where each matrix is explicitly a type 1 elementary matrix, or is generated by type 1 elementary matrices, and the choice of $\\mathbf A \\in SL_n(\\mathbb R) $  was arbitrary which proves the claim for this (sub)group.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**corollary:**  \n",
    "any matrix $\\mathbf B\\in GL_n(\\mathbb R)$ with $\\det\\big(\\mathbf B\\big) = c \\neq 0$  is a coset of $SL_n(\\mathbb R) $  \n",
    "i.e. write it out, by selecting elementary matrix of the third type with determinant $c$   \n",
    "$\\mathbf A := \\big(\\mathbf E^{-1}  \\mathbf B\\big) \\in SL_n(\\mathbb R)$  \n",
    "because  \n",
    "$\\det\\big(\\mathbf A\\big) = \\det\\big(\\mathbf E^{-1}  \\mathbf B\\big) = \\det\\big(\\mathbf E^{-1}\\big)\\det\\big(\\mathbf B\\big) = \\det\\big(\\mathbf E\\big)^{-1}\\det\\big(\\mathbf B\\big) = c^{-1}\\cdot c = 1$   \n",
    "\n",
    "hence \n",
    "\n",
    "$\\mathbf E\\mathbf A = \\mathbf B$  is a coset of $SL_n(\\mathbb R)$  \n",
    "(this in effect the answer to part a of the question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**corollary:**  \n",
    "chp 2 misc problems 8 and 9\n",
    "\n",
    "any $\\mathbf A \\in SL_n(\\mathbb R) $  \n",
    "is path connected to the identity matrix $\\mathbf I_n$ \n",
    "because path connectedness is an equivalence relation closed under composition (/transitive property)  and \n",
    "any  $\\mathbf A \\in SL_n(\\mathbb R) $\n",
    "\n",
    "may be written as a the product of finitely many elementary matrices of the first type.  \n",
    "\n",
    "There is an obvious path connection between type one elementary matrices and the identity matrix, in that  \n",
    "for $\\tau \\in [0,1]$  \n",
    "$f(\\tau) = (1-\\tau)\\cdot \\mathbf I_n  + \\tau \\cdot \\mathbf E$  \n",
    "\n",
    "which is triangular with ones on the diagonal for all $\\tau \\in [0,1]$ hence  \n",
    "$\\det\\big(f(\\tau)\\big) = 1$ for $\\tau \\in [0,1]$   \n",
    "\n",
    "\n",
    "any matrix $\\mathbf B \\in GL_n(\\mathbb R)$   \n",
    "$= \\mathbf E^{(3)} \\mathbf A$ \n",
    "with $\\mathbf A \\in SL_n(\\mathbb R) $  \n",
    "\n",
    "where $\\det\\big(\\mathbf B\\big) = \\det\\big(\\mathbf E^{(3)}\\big) = c$  \n",
    "\n",
    "i) \n",
    "for $c \\gt 0$ consider again the simple linear path of \n",
    "$f(\\tau) = (1-\\tau)\\cdot \\mathbf I_n  + \\tau \\cdot \\mathbf E^{(3)}$  \n",
    "which is diagonal, hence  \n",
    "$\\det\\big(f(\\tau)\\big) = (1-\\tau)\\cdot 1 + \\tau \\cdot c \\geq (1-\\tau)\\cdot \\min(1,c) + \\tau \\cdot \\min(1,c) = \\min(1,c) \\gt 0$  \n",
    "\n",
    "and hence any $\\mathbf B \\in GL_n(\\mathbb R)$ with positive determinant is a connected component -- i.e. it is path connected to the identity.  \n",
    "\n",
    "\n",
    "ii.)  for $c \\lt 0$, for *any* satisfying path with \n",
    "$f(0) = \\mathbf I_n$ and \n",
    "$f(1) = \\mathbf B$  \n",
    "we have \n",
    "\n",
    "$\\det\\big(f(0)\\big) = 1$  \n",
    "$\\det\\big(f(1)\\big) \\lt 0 $  \n",
    "\n",
    "but the determinant is a continuous function of the components a matrix, hence by intermediate value theorem there must be some $\\tau \\in (0,1)$ where $f\\big(\\tau \\big) =0$ and the matrix given by $f\\big(\\tau \\big)$ is *not* a member of $GL_n(\\mathbb R)$ hence the set of matrices with negative determinants are not connected components. And since this set does not include the identity, it cannot be a subgroup, etc.  (Note: this disconnectedness does not hold if we were to consider $GL_n(\\mathbb C)$)   \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
