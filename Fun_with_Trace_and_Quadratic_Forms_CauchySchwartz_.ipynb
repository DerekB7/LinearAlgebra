{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity the field will be reals, though the results can be easily extended to complex numbers.  \n",
    "\n",
    "Note: I was originally looking for a different approach to proving Cauchy-Schwartz, using something simple and powerful with the trace operation, but I somehow ended up using eigenvalues and the Schur Inequality... which is a lot heavier duty machinery than I had wanted... sigh...\n",
    "\n",
    "consider some vector $\\mathbf x =  \\begin{bmatrix}\n",
    "x_1\\\\ \n",
    "x_2\\\\ \n",
    "\\vdots \\\\ \n",
    "x_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "and some other vector,  $\\mathbf y =  \\begin{bmatrix}\n",
    "y_1\\\\ \n",
    "y_2\\\\ \n",
    "\\vdots \\\\ \n",
    "y_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "now consider the outer product given by \n",
    "\n",
    "$\\mathbf {xy}^T =  \\begin{bmatrix}\n",
    "x_1 y_1 & x_1 y_2 &...& x_1 y_n\\\\ \n",
    "x_2 y_1 & x_2 y_2 & ... & x_2 y_n \\\\ \n",
    "\\vdots & \\vdots & \\ddots &\\vdots \\\\ \n",
    "x_n y_1 & x_n y_2 &.... & x_n y_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "From here, consider where we want the squared Frobenius norm of $\\mathbf {xy}^T$ \n",
    "\n",
    "$\\big\\vert\\big\\vert \\mathbf {xy}^T\\big\\vert\\big\\vert_{F}^2 = trace\\Big(\\big(\\mathbf {xy}^T\\big)^T \\big( \\mathbf {xy}^T\\big)\\Big) = trace\\Big( \\mathbf {yx}^T \\mathbf {xy}^T\\Big) = trace\\Big( \\mathbf{y}^T \\mathbf{yx}^T \\mathbf {x}\\Big) = \\mathbf {y}^T\\mathbf y \\mathbf x^T \\mathbf {x}  = \\big\\vert\\big\\vert \\mathbf{y}\\big\\vert\\big\\vert_{2}^2\\big\\vert\\big\\vert \\mathbf {x}\\big\\vert\\big\\vert_{2}^2$\n",
    "\n",
    "where the middle equalities made use of the cyclic property of the trace\n",
    "\n",
    "Unfortunately, this seems to be going off in the deep end.  We conclude the proof with the following:\n",
    "\n",
    "$ \\big\\vert\\big\\vert \\mathbf{y}\\big\\vert\\big\\vert_{2}^2\\big\\vert\\big\\vert \\mathbf {x}\\big\\vert\\big\\vert_{2}^2 = trace\\Big(\\big(\\mathbf {\\mathbf {xy}}^T\\big)^T \\big( \\mathbf {\\mathbf {xy}}^T\\big)\\Big) \n",
    "\\geq trace\\Big( \\big(\\mathbf {xy}^T\\big) \\big(\\mathbf {xy}^T\\big)\\Big) = trace\\Big(\\mathbf {xy}^T\\Big)^2$\n",
    "\n",
    "hence \n",
    "\n",
    "$\\big\\vert\\big\\vert \\mathbf{y}\\big\\vert\\big\\vert_{2}^2\\big\\vert\\big\\vert \\mathbf {x}\\big\\vert\\big\\vert_{2}^2 = \\Big(\\Sigma_{i=1}^{n}y_i^2\\Big) \\Big(\\Sigma_{i=1}^{n}x_i^2\\Big)  \\geq \\Big(\\Sigma_{i=1}^{n}x_iy_i\\Big)^2= trace\\Big(\\mathbf {xy}^T\\Big)^2  $\n",
    "\n",
    "\n",
    "noting that \n",
    "\n",
    "$trace\\Big(\\big(\\mathbf {\\mathbf {xy}}^T\\big)^T \\big( \\mathbf {\\mathbf {xy}}^T\\big)\\Big)\n",
    "\\geq trace\\Big( \\big(\\mathbf {xy}^T\\big) \\big(\\mathbf {xy}^T\\big)\\Big) $\n",
    "\n",
    "via the Schur Inequality.  (Also see the cell below -- we can ignore Schur Inequality and directly interpret this in terms of maximal eigenvalues.) \n",
    "\n",
    "and that \n",
    "\n",
    "$trace\\Big( \\big(\\mathbf {xy}^T \\big) \\big(\\mathbf {xy}^T\\big)\\Big) = trace\\Big(\\mathbf {xy}^T\\Big)^2$ \n",
    "because $\\big(\\mathbf {xy}^T\\big)$ is a rank one matrix and hence its trace is equal to its sole non zero eigenvalue, and when you multiply that matrix by itself, we see that each eigenvalue gets squared, via the Schur decomposition, hence the resulting trace is simply the value of the original eigenvalue -- $trace\\Big(\\mathbf {xy}^T\\Big)$-- squared. More simply, we can of course, just use the cyclic property of the trace to re-write $trace\\Big( \\big(\\mathbf {xy}^T\\big) \\big(\\mathbf {xy}^T\\big)\\Big) = trace\\Big( \\mathbf {xy}^T\\mathbf {xy}^T\\Big) = trace\\Big( \\mathbf y^T \\mathbf {xy}^T\\mathbf {x}\\Big) = trace\\Big( \\big(\\mathbf y^T \\mathbf {x}\\big) \\big(\\mathbf y^T \\mathbf {x}\\big)\\Big)$, which is equal to $trace\\Big(\\mathbf y^T \\mathbf {x}\\Big)^2 = trace\\Big(\\mathbf {xy}^T\\Big)^2 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that instead of using the Schur Inequality (which strictly speaking should have had an absolute value / magnitude included in there),  consider the maximum eigenvalue problem, where we have a rank one matrix, $\\mathbf B$, this time over a complex numbers field\n",
    "\n",
    "\n",
    "$\\mathbf B = \\mathbf{xy}^H$.  While we know that $\\mathbf B$ is a rank one matrix, the argument to be made is even more general: the magnitude of the largest eigenvalue of $\\big(\\mathbf {BB}\\big)$ is $\\leq$ the largest eigenvalue of $\\mathbf B^H \\mathbf B$, or equivalently, the magnitude of the largest eigenvalue of $\\mathbf B$ ($\\lambda_1$) is $\\leq$ the largest singular value of $\\mathbf B$ ($\\sigma_1$).\n",
    "\n",
    "The approach taken here uses quadratic forms.  So consider the case of maximizing $\\mathbf B^H \\mathbf B$ vs $\\mathbf {BB}$\n",
    "\n",
    "max $\\big \\vert \\mathbf v^H \\mathbf B^H \\mathbf B \\mathbf v \\big \\vert \\geq$ max $\\big \\vert \\mathbf v^H \\mathbf{BB}\\mathbf v \\big \\vert$\n",
    "\n",
    "where we constrain the length (2 norm) of $\\mathbf v$, which for simplicity will be one: $\\mathbf v^H \\mathbf v = 1 = \\big \\vert \\big \\vert \\mathbf v \\big \\vert \\big \\vert_2^{2} = \\big \\vert \\big \\vert \\mathbf v \\big \\vert \\big \\vert_2$ \n",
    "\n",
    "We know via diagonalization arguments (and Lagrange Multipliers), that some quadratic form $\\big \\vert \\mathbf v^H \\mathbf C \\mathbf v\\big \\vert$ subject to $\\mathbf v ^H \\mathbf v = 1$ is maximized when all of $\\mathbf v$ is allocated to the eigenvalue(s) with the largest magnitude of the Hermitian matrix $\\mathbf C$.  Unfortunately, we have no reason to believe $\\mathbf {BB}$ is Hermitian or even non-defective, which complicates things a bit.  But consider having well ordered eigenvalues for $\\mathbf B$ where $\\big \\vert \\lambda_1 \\big \\vert \\geq \\big \\vert\\lambda_2 \\big \\vert\\geq \\big \\vert \\lambda_3 \\big \\vert \\geq ... \\geq \\big \\vert\\lambda_n \\big \\vert$, with associated eigenvectors $\\mathbf v_1, \\mathbf v_2, \\mathbf v_3, ... , \\mathbf v_n$.  Note that there is a simple argument which tells us that allocating to eigenvector $\\mathbf v_k$ where $k \\geq 2$ is (weakly) dominated by $\\mathbf v_1$.  \n",
    "\n",
    "$\\big \\vert \\mathbf v_1^H \\mathbf{BB}\\mathbf v_1 \\big \\vert \\geq \\big \\vert \\mathbf v_k^H \\mathbf{BB}\\mathbf v_k \\big \\vert$\n",
    "\n",
    "$\\big \\vert \\mathbf v_1^H \\mathbf{B}\\big(\\mathbf B \\mathbf v_1\\big) \\big \\vert \\geq \\big \\vert \\mathbf v_k^H \\mathbf{B}\\big( \\mathbf B \\mathbf v_k \\big) \\big \\vert$\n",
    "\n",
    "$\\big \\vert \\mathbf v_1^H \\mathbf{B} \\lambda_1 \\mathbf v_1 \\big \\vert \\geq \\big \\vert\\mathbf v_k^H \\mathbf{B}\\lambda_k \\mathbf v_k \\big \\vert$\n",
    "\n",
    "$\\big \\vert \\lambda_1 \\mathbf v_1^H \\big(\\mathbf{B} \\mathbf v_1\\big) \\big \\vert \\geq \\big \\vert \\lambda_k \\mathbf v_k^H \\big(\\mathbf{B} \\mathbf v_k\\big) \\big \\vert$\n",
    "\n",
    "$\\big \\vert \\lambda_1 \\mathbf v_1^H \\lambda_1 \\mathbf v_1 \\big \\vert \\geq \\big \\vert \\lambda_k \\mathbf v_k^H \\lambda_k \\mathbf v_k \\big \\vert$\n",
    "\n",
    "$\\big \\vert \\lambda_1^2 (\\mathbf v_1^H \\mathbf v_1) \\big \\vert \\geq \\big \\vert \\lambda_k^2 (\\mathbf v_k^H \\mathbf v_k) \\big \\vert$\n",
    "\n",
    "$\\big \\vert \\lambda_1^2 *1\\big \\vert \\geq \\big \\vert \\lambda_k^2 *1 \\big \\vert$  \n",
    "$\\big \\vert \\lambda_1^2\\big \\vert \\geq \\big \\vert\\lambda_k^2 \\big \\vert$  \n",
    "$\\big \\vert \\lambda_1\\big \\vert^2 \\geq \\big \\vert\\lambda_k \\big \\vert^2$  \n",
    "$\\big \\vert \\lambda_1\\big \\vert \\geq \\big \\vert\\lambda_k \\big \\vert$   \n",
    "\n",
    "hence we have a simple exchange argument that tells us any time we allocate to $\\mathbf v_k$ we can get a result greater than or equal to it, by allocating that amount instead to $\\mathbf v_1$.  Thus we can do no better than allocating everything in $\\mathbf v$ to the eigenpair $\\lambda_1, \\mathbf v_1$\n",
    "\n",
    "We return to our original equation, with respect to eigenvalues:\n",
    "\n",
    "max $\\big \\vert  \\mathbf v^H \\mathbf B^H \\mathbf B \\mathbf v \\big \\vert \\geq$ max $\\big \\vert \\mathbf v_1^H \\mathbf{BB}\\mathbf v_1 \\big \\vert$\n",
    "\n",
    "max $\\big \\vert \\mathbf v^H \\mathbf B^H \\mathbf B \\mathbf v \\big \\vert = $ max $ \\mathbf v^H \\mathbf B^H \\mathbf B \\mathbf v  \\geq \\big \\vert \\lambda_1^2\\big \\vert $\n",
    "\n",
    "note that we always have the option / backup plan, on the left hand side, of also allocating to $\\mathbf v_1$ \n",
    "\n",
    "$\\mathbf v_1^H \\mathbf B^H \\mathbf B \\mathbf v_1 = \\big \\vert \\lambda_1^2\\big \\vert $  \n",
    "\n",
    "$\\big(\\mathbf v_1^H \\mathbf B^H\\big) \\big(\\mathbf B \\mathbf v_1 \\big) = \\big \\vert \\lambda_1^2\\big \\vert $  \n",
    "\n",
    "$\\big(\\mathbf {B}\\mathbf v_1\\big)^H \\big(\\mathbf B \\mathbf v_1 \\big) = \\big \\vert \\lambda_1^2 \\big \\vert $  \n",
    "$\\big(\\lambda_1 \\mathbf v_1\\big)^H \\big(\\lambda_1 \\mathbf v_1 \\big) = \\big \\vert \\lambda_1^2 \\big \\vert $  \n",
    "$\\lambda_1^H \\lambda_1 \\big(\\mathbf v_1^H \\mathbf v_1\\big) = \\big \\vert \\lambda_1^2 \\big \\vert $  \n",
    "$\\lambda_1^H \\lambda_1 *1  = \\big \\vert \\lambda_1^2\\big \\vert $    \n",
    "$\\lambda_1^H \\lambda_1  = \\big \\vert \\lambda_1^2 \\big \\vert $  \n",
    "\n",
    "Where the final statement is true by the math of complex numbers. A quick detour justifying this is shown below.\n",
    "\n",
    "- - - - \n",
    "To justify this, consider that we can simply note that $\\big \\vert \\lambda_1^2\\big \\vert = \\big \\vert \\lambda_1 \\big \\vert^2 = \\lambda_1^H \\lambda_1$.\n",
    "\n",
    "Alternatively, for a more granular view, consider the case where:  \n",
    "$\\lambda_1 = \\alpha - \\beta i $, where $\\alpha$ and $\\beta$ are real valued scalars. Accordingly, the magnitude of $\\lambda_1$ is $\\big\\vert \\lambda_1\\big\\vert = \\big(\\alpha^2 + \\beta^2\\big)^\\frac{1}{2}$. Then $\\lambda_1^2 = \\alpha^2 + \\beta^2  i^2 - 2\\alpha\\beta i = \\alpha^2 - \\beta^2 - 2\\alpha\\beta i$, with magnitude of $\\big \\vert \\lambda_1^2\\big \\vert = \\Big(\\big(\\alpha^2 - \\beta^2\\big)^2 + \\big( - 2\\alpha\\beta\\big)^2\\Big)^{\\frac{1}{2}}= \\Big(\\alpha^4 + \\beta^4 - 2 \\alpha^2 \\beta^2 + 4 \\alpha^2\\beta^2)\\Big)^{\\frac{1}{2}} = \\Big(\\alpha^4 + \\beta^4 + 2 \\alpha^2 \\beta^2 \\Big)^{\\frac{1}{2}}$ \n",
    "\n",
    "and note that $\\lambda_1 ^H \\lambda_1 = \\alpha^2 + \\beta^2$, with magnitude equal to $\\big \\vert \\lambda_1^H \\lambda_1 \\big \\vert = \\Big(\\big(\\alpha^2 + \\beta^2\\big)^2 + \\big(0\\big)^2 \\Big)^{\\frac{1}{2}} = \\Big(\\alpha^4 + \\beta^4 + 2 \\alpha \\beta \\Big)^{\\frac{1}{2}} = \\big \\vert \\lambda_1^2\\big \\vert = \\alpha^2 + \\beta^2  = \\Big(\\big(\\alpha^2 + \\beta^2\\big)^\\frac{1}{2}\\Big)^2 = \\big\\vert \\lambda_1\\big\\vert ^2 $\n",
    "- - - - \n",
    "\n",
    "Thus when trying to maximize the magnitude of $\\mathbf v^H \\mathbf B^H \\mathbf B \\mathbf v$, we have a lower bound equal to $ \\big \\vert \\lambda_1^2 \\big\\vert$.  Equivalently, we can say: $\\sigma_1^2 \\geq \\big \\vert \\lambda_1^2 \\big\\vert$ and $\\sigma_1 \\geq \\big \\vert \\lambda_1 \\big\\vert$, where $\\sigma_1$ is the largest singular value of $\\mathbf B$ and thus $\\sigma_1^2$ is the largest eigenvalue of $\\mathbf B^H \\mathbf B$\n",
    "\n",
    "For a simple example of this fact, consider:\n",
    "\n",
    "$\\mathbf B = \\left[\\begin{matrix}2 & 3 & 4\\\\4 & 10 & -1\\\\1 & 3 & 4\\end{matrix}\\right]$\n",
    "\n",
    "where $\\lambda_1 \\approx 11.57$, but $\\sigma_1 \\approx 11.87$, hence $\\sigma_1$ exceeds the lower bound set by $\\lambda_1$ \n",
    "- - - -\n",
    "Back to the original problem at hand, in the special case where $\\mathbf B$ is a square, rank one matrix  \n",
    "\n",
    "$trace \\big(\\mathbf B ^H \\mathbf B\\big) \\geq \\big \\vert trace\\big(\\mathbf{BB}\\big) \\big \\vert$, because  \n",
    "\n",
    "$trace \\big(\\mathbf B ^H \\mathbf B\\big) = \\sigma_1^2$ and $trace\\big(\\mathbf{BB}\\big) = \\lambda_1^2 $, and we know $\\sigma_1^2 \\geq \\big \\vert \\lambda_1^2 \\big\\vert$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
