{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stumbled onto this inequality while working on problem 8.7 (SVMs) in 'Learning From Data'\n",
    "\n",
    "(all matrices are finite dimensional and real valued)\n",
    "\n",
    "$\\mathbf 1 =\\begin{bmatrix}\n",
    "1\\\\ \n",
    "1\\\\ \n",
    "\\vdots \\\\ \n",
    "1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "$\\mathbf X^T = \n",
    "\\bigg[\\begin{array}{c|c|c|c}\n",
    "\\mathbf x_1 & \\mathbf x_2 &\\cdots & \\mathbf x_{N}\n",
    "\\end{array}\\bigg]\n",
    "$   \n",
    "\n",
    "\n",
    "Thus $\\mathbf{X X}^T$ is a symmetric, positive semi-definite, $N$x$N$ matrix\n",
    "\n",
    "**claim:**\n",
    "\n",
    "$N \\cdot \\text{trace}\\big(\\mathbf{X X}^T\\big) \\geq \\mathbf 1^T \\mathbf{X X}^T \\mathbf 1 = sum \\big(\\mathbf{X X}^T\\big)$\n",
    "\n",
    "That is, a scalar of $N$ multiplied by the sum of the $N$ diagonal elements that come from $\\text{trace}\\big(\\mathbf{X X}^T\\big)$ must be at least as big as the sum of the entire $N^2$ elements in $\\mathbf{X X}^T$\n",
    "\n",
    "- - - - -  \n",
    "*subsequent note*  \n",
    "if we view the ones vector as an n x 1 matrix the above result is immediately implied by the submultiplicativity of the Frobenius norm i.e. we have  \n",
    "\n",
    "$\\sqrt{N} \\cdot \\text{trace}\\big(\\mathbf{X X}^T\\big)^\\frac{1}{2} = \\Big \\Vert \\mathbf 1 \\Big \\Vert_F \\Big \\Vert \\mathbf  X^T\\Big \\Vert_F  \\geq \\Big \\Vert  \\mathbf{X}^T\\mathbf 1 \\Big \\Vert_F =  \\text{trace}\\big(\\mathbf 1^T \\mathbf{X X}^T \\mathbf 1\\big)^\\frac{1}{2}  = \\big(\\mathbf 1^T \\mathbf{X X}^T \\mathbf 1\\big)^\\frac{1}{2}  \\geq 0$   \n",
    "\n",
    "squaring both sides then gives the result  \n",
    "\n",
    "- - - - -  \n",
    "\n",
    "\n",
    "Note that $\\mathbf {X X}^T$ is symmetric and may be diagonalized.  The degenerate case where $\\mathbf X$ is the zero matrix is trivially true, and excluded from this writeup.\n",
    "\n",
    "note that $\\text{trace}(\\mathbf {X X}^T) =  \\Sigma_{k=1}^{N} \\mathbf x_k^T \\mathbf x_k = \\mathbf x_1^T \\mathbf x_1 + \\mathbf x_2^T \\mathbf x_2 + ... + \\mathbf x_N^T \\mathbf x_N = \\mathbf 1^T\\big(\\mathbf x_1\\circ \\mathbf x_1 + \\mathbf x_2\\circ \\mathbf x_2 + ... + \\mathbf x_N \\circ \\mathbf x_N\\big) = N \\mathbf 1^T E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] $\n",
    "\n",
    "Further, notice that $\\big(\\mathbf 1^T \\mathbf{X}\\big) \\big(\\mathbf X^T \\mathbf 1\\big)= \\big(\\mathbf X^T \\mathbf 1\\big)^T \\big(\\mathbf X^T \\mathbf 1\\big) = E\\big[N\\mathbf x\\big]^TE\\big[N\\mathbf x\\big] = N^2 \\mathbf 1^T \\Big( E\\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big) $\n",
    "\n",
    "where $\\circ$ denotes the Hadarmard product, and $E\\big[ \\big]$ denotes taking the expected value / arithmetic mean (we can think of the column vectors in $\\mathbf X^T$ as being uniformly distributed, if helpful)\n",
    "\n",
    "**proof:**  \n",
    "$N \\cdot \\text{trace}\\big(\\mathbf{X X}^T\\big) = N^2 \\mathbf 1^T E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] \\geq N^2 \\mathbf 1^T \\Big( E\\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big)= \\mathbf 1^T \\mathbf{X X}^T \\mathbf 1$\n",
    "\n",
    "because: \n",
    "\n",
    "$ \\mathbf 1^T E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] \\geq \\mathbf 1^T \\Big( E\\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big)$\n",
    "\n",
    "equivalently:\n",
    "\n",
    "$ \\big(\\mathbf{e_1 + e_2 + ... + e_N} \\big)^T  E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] \\geq \\big(\\mathbf{e_1 + e_2 + ... + e_N} \\big)^T \\Big( E\\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big)$\n",
    "\n",
    "where $\\mathbf e_k$ denotes the kth unit standard vector (i.e. column slice of the $N$ x $N$ Identity matrix) for $k = \\{1, 2, ..., N\\}$\n",
    "\n",
    "The above is true due to Jensen's Inequality.  In fact Jensen's Inequality makes an even stronger statement:\n",
    "\n",
    "$ \\mathbf e_k^T \\Big(E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big]\\Big) \\geq \\mathbf e_k^T \\Big( E\\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big)$\n",
    "\n",
    "which can be re-written as:\n",
    "\n",
    "$  E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] .\\geq  \\Big( E\\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big)$\n",
    "\n",
    "where $.\\geq$ denotes elevement-wise comparisons between the vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative proof uses quadratic forms.  This approach can be easily altered to accomodate complex numbers.\n",
    "\n",
    "As in the above writeup, we banish from discussion the case of $\\mathbf X$ being the zero matrix, hence $ \\big \\vert \\big \\vert \\mathbf X\\big \\vert \\big \\vert_F \\gt 0$.\n",
    "\n",
    "claim: $N * \\text{trace}\\big(\\mathbf{X X}^T\\big) \\geq \\mathbf 1^T \\mathbf{X X}^T \\mathbf 1 = sum \\big(\\mathbf{X X}^T\\big)$\n",
    "\n",
    "where $\\mathbf 1 =\\begin{bmatrix}\n",
    "1\\\\ \n",
    "1\\\\ \n",
    "\\vdots \\\\ \n",
    "1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\mathbf b  := \\frac{1}{\\sqrt N} \\mathbf 1 $ \n",
    "\n",
    "so $\\mathbf 1^T \\mathbf 1 = N = \\mathbf b^T \\mathbf b (\\sqrt(N))^2 = 1 * N = N$\n",
    "\n",
    "We can factorize $\\big(\\mathbf{X X}^T\\big) = \\mathbf U \\mathbf D \\mathbf U^T$, where $\\mathbf U$ is orthogonal and $\\mathbf D$ is a diagonal matrix with $\\lambda_k$ in position $\\mathbf D_{k,k}$\n",
    "\n",
    "The matrix given by $\\big(\\mathbf{X X}^T\\big)$ is symmetric, positive semi-definite, hence eigenvalues are real and non-negative. Let the eigenvalues be ordered such that $\\mathbf \\lambda_1 \\geq \\mathbf \\lambda_2 \\geq ... \\geq \\lambda_N \\geq 0$\n",
    "\n",
    "\n",
    "consider that $N * \\text{trace}\\big(\\mathbf{X X}^T\\big) = N * \\text{trace}\\big(\\mathbf U \\mathbf D \\mathbf U^T\\big) = N * \\text{trace}\\big(\\mathbf U^T\\mathbf U \\mathbf D \\big)= N * \\text{trace}\\big(\\mathbf D \\big) =  N * \\big( \\lambda_1 + \\lambda_2 + ... + \\lambda_N \\big) $\n",
    "\n",
    "\n",
    "on the other hand, consider maximizing the quadratic form \n",
    "\n",
    "max $\\mathbf 1^T \\mathbf{X X}^T \\mathbf 1$  \n",
    "max $\\mathbf 1^T \\big(\\mathbf U \\mathbf D \\mathbf U^T\\big) \\mathbf 1$  \n",
    "max $\\sqrt(N) \\mathbf b^T \\big(\\mathbf U \\mathbf D \\mathbf U^T\\big) \\sqrt(N) \\mathbf b$  \n",
    "max $N \\big(\\mathbf b^T \\mathbf U \\big) \\mathbf D \\big(\\mathbf U^T \\mathbf b \\big)$  \n",
    "max $N \\big(\\mathbf U^T \\mathbf b \\big)^T \\mathbf D \\big(\\mathbf U^T \\mathbf b \\big)$\n",
    "  \n",
    "where $\\mathbf U^T \\mathbf b := \\mathbf y$\n",
    "\n",
    "hence $\\big \\vert \\big \\vert \\mathbf y \\big \\vert\\big \\vert_2^2 = \\big \\vert \\big \\vert \\mathbf U^T \\mathbf b \\big \\vert\\big \\vert_2^2 = \\big \\vert \\big \\vert \\mathbf b \\big \\vert\\big \\vert_2^2 = 1$\n",
    "\n",
    "max $N \\big(\\mathbf y \\big)^T \\mathbf D \\big(\\mathbf y \\big)$\n",
    "\n",
    "max $N \\big( \\lambda_1 y_1^2 + \\lambda_2 y_2^2 + ... + \\lambda_N y_N^2\\big)$\n",
    "\n",
    "which is the familiar diagonalization argument for allocating all of $\\mathbf y $ to $y_1$, i.e. $\\mathbf y = \\mathbf e_1$ (the first column slice of the N x N Identity Matrix) -- otherwise we use a familiar exchange argument to prove $\\mathbf y = \\mathbf e_1$ is the (weakly) dominant solution.  \n",
    "\n",
    "Thus we have \n",
    "\n",
    "$N * \\text{trace}\\big(\\mathbf{X X}^T\\big) =  N * \\big( \\lambda_1 + \\lambda_2 + ... + \\lambda_N \\big) \\geq N \\big(\\lambda_1 \\big)= N \\big( \\lambda_1 1^2 + \\lambda_2 0^2 + ... + \\lambda_N 0^2\\big) = \\mathbf e_1^T D \\mathbf e_1 $\n",
    "\n",
    "Thus we can say \n",
    "\n",
    "$N * \\text{trace}\\big(\\mathbf{X X}^T\\big) \\gt \\mathbf 1^T \\mathbf{X X}^T\\mathbf 1$ \n",
    "\n",
    "**except there is equality if and only if** $\\mathbf X$ **is a rank one matrix**, where its dominant (i.e. not in the null space) left singular vector  $\\propto \\mathbf 1$.  More specifically, equality holds iff $\\mathbf X^T$ **is a rank one matrix of the form **\n",
    "\n",
    "$\\mathbf X^T = \n",
    "\\bigg[\\begin{array}{c|c|c|c}\n",
    "\\mathbf x_1 & \\mathbf x_1 &\\cdots & \\mathbf x_{1}\n",
    "\\end{array}\\bigg]\n",
    "= \\mathbf x_1 \\mathbf 1^T$   \n",
    "\n",
    "where, as before, the ones vector, has N scalar values equal to one in it, i.e. $\\mathbf 1^T \\mathbf 1 = N$\n",
    "\n",
    "\n",
    "Thus $\\mathbf {XX}^T= \\big(\\mathbf {x_1 1}^T\\big)^T \\mathbf x_1 \\mathbf 1^T =\\mathbf {1 x_1}^T \\mathbf x_1 \\mathbf 1^T = (\\mathbf x_1^T \\mathbf x_1) \\mathbf{11}^T$\n",
    "\n",
    "$N * \\text{trace}\\big(\\mathbf{X X}^T\\big) = N * \\text{trace}\\big( (\\mathbf x_1^T \\mathbf x_1) * \\mathbf{11}^T\\big) = N *(\\mathbf x_1^T \\mathbf x_1) \\text{trace}\\big(  \\mathbf1 \\mathbf 1^T \\big) =N *(\\mathbf x_1^T \\mathbf x_1) \\text{trace}\\big(  \\mathbf1^T \\mathbf 1 \\big) = N^2 *(\\mathbf x_1^T \\mathbf x_1) $\n",
    "\n",
    "and equivalently  \n",
    "$\\mathbf 1^T \\mathbf{X X}^T\\mathbf 1 = \\mathbf 1^T  \\big( \\mathbf 1 \\mathbf x_1^T \\mathbf x_1 \\mathbf 1^T\\big) \\mathbf 1 =  \\big(\\mathbf 1^T  \\mathbf 1\\big) \\big(\\mathbf x_1^T \\mathbf x_1 \\big) \\big(\\mathbf 1^T \\mathbf 1\\big) = (N) (\\mathbf x_1^T \\mathbf x_1)(N) = N^2 *(\\mathbf x_1^T \\mathbf x_1)$\n",
    "\n",
    "This has a nice interpretation in terms of Jensen's Inequality, whereby \n",
    "\n",
    "$\\mathbf 1^T \\Big(E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] - E \\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big) = 0$, or  $ \\Big(E\\big[ \\mathbf{x} \\circ \\mathbf {x}\\big] - E \\big[\\mathbf x\\big] \\circ E\\big[\\mathbf x\\big]\\Big) = \\mathbf 0$ \n",
    "\n",
    "because by making every column in $\\mathbf X^T$ the same, we homogenized the distribution such that there is now zero variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another even simpler take:**  \n",
    "\n",
    "for some real valued vector $\\mathbf x_k$, note that via the 1 trick and direct application of Cauchy Schwarz, we have:  \n",
    "\n",
    "$\\mathbf 1^T \\big(\\mathbf x_k \\mathbf x_k^T\\big) \\mathbf 1 = \\big(\\mathbf 1^T \\mathbf x_k\\big) \\big( \\mathbf x_k^T \\mathbf 1\\big)  = \\big(\\mathbf 1^T \\mathbf x_k\\big)^2 \\leq \\big(\\mathbf 1^T \\mathbf 1\\big) \\big( \\mathbf x_k^T \\mathbf x_k\\big) = N \\big\\Vert \\mathbf x_k \\big \\Vert_2^2 $ \n",
    "\n",
    "using the rank one update / outer product interpretation of matrix multiplication, we have:  \n",
    "\n",
    "$\\mathbf X \\mathbf X^T = \\sum_{k=1}^N \\mathbf x_k \\mathbf x_k^T $  \n",
    "\n",
    "combining the two we have \n",
    "\n",
    "$\\mathbf 1^T \\mathbf X \\mathbf X^T \\mathbf 1 = \\mathbf 1^T \\Big(\\sum_{k=1}^N \\mathbf x_k \\mathbf x_k^T\\Big)\\mathbf 1 =  \\Big(\\sum_{k=1}^N \\mathbf 1^T \\mathbf x_k \\mathbf x_k^T \\mathbf 1 \\Big) \\leq \\Big(\\sum_{k=1}^N\\big(\\mathbf 1^T \\mathbf 1\\big) \\big( \\mathbf x_k^T \\mathbf x_k\\big) \\Big) =  N \\Big(\\sum_{k=1}^N \\big \\Vert \\mathbf x_k\\big \\Vert_2^2 \\Big)  = N *\\text{trace}\\Big(\\mathbf X \\mathbf X^T\\Big)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another even simpler take:**  \n",
    "\n",
    "using the rank one update / outer product interpretation of matrix multiplication, we have:  \n",
    "\n",
    "$\\mathbf X \\mathbf X^T = \\sum_{k=1}^N \\mathbf x_k \\mathbf x_k^T $  \n",
    "\n",
    "\n",
    "for some real valued vector $\\mathbf x_k$, note that via the 1 trick and direct application of Cauchy Schwarz, we have:  \n",
    "\n",
    "$\\mathbf 1^T \\big(\\mathbf x_k \\mathbf x_k^T\\big) \\mathbf 1 = \\big(\\mathbf 1^T \\mathbf x_k\\big) \\big( \\mathbf x_k^T \\mathbf 1\\big)  = \\big(\\mathbf 1^T \\mathbf x_k\\big)^2 \\leq \\big(\\mathbf 1^T \\mathbf 1\\big) \\big( \\mathbf x_k^T \\mathbf x_k\\big) = N \\big\\Vert \\mathbf x_k \\big \\Vert_2^2 $ \n",
    "\n",
    "thus we can sum over the bound and see \n",
    "\n",
    "$\\mathbf 1^T \\Big(\\mathbf X \\mathbf X^T \\big) \\mathbf 1  = \\mathbf 1^T \\Big(\\sum_{k=1}^N \\mathbf x_k \\mathbf x_k^T\\Big) \\mathbf 1 = \\sum_{k=1}^N\\big(\\mathbf 1^T \\mathbf x_k\\big)^2 \\leq \\sum_{k=1}^N \\big(\\mathbf 1^T \\mathbf 1\\big) \\big( \\mathbf x_k^T \\mathbf x_k\\big) = \\big(\\mathbf 1^T \\mathbf 1\\big)\\sum_{k=1}^N  \\big( \\mathbf x_k^T \\mathbf x_k\\big) = N \\big\\Vert \\mathbf x_k \\big \\Vert_2^2 $ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy import fftpack\n",
    "np.set_printoptions(precision = 2, linewidth=180)\n",
    "from scipy.linalg import ldl\n",
    "# https://scipy.github.io/devdocs/generated/scipy.linalg.ldl.html\n",
    "# this is LDL^T factorization and it seems to be a relatively new addition to scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26,  0.78,  0.66, ...,  0.38,  0.1 ,  0.58],\n",
       "       [ 0.37,  0.63,  0.78, ...,  0.67,  0.08,  0.44],\n",
       "       [ 0.07,  0.02,  0.18, ...,  0.38,  0.77,  0.64],\n",
       "       ..., \n",
       "       [ 0.24,  0.05,  0.9 , ...,  0.88,  0.81,  0.44],\n",
       "       [ 0.91,  0.69,  0.91, ...,  0.02,  0.26,  0.84],\n",
       "       [ 0.04,  0.71,  0.86, ...,  0.11,  0.27,  0.78]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 50\n",
    "d = 50\n",
    "\n",
    "\n",
    "X = np.random.random((m,d))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   8.3 ,   8.29, ...,   7.94,  10.  ,   7.03],\n",
       "       [  8.3 ,   0.  ,   7.69, ...,   6.96,   8.55,   6.82],\n",
       "       [  8.29,   7.69,   0.  , ...,   9.38,  11.23,   7.25],\n",
       "       ..., \n",
       "       [  7.94,   6.96,   9.38, ...,   0.  ,   7.18,   8.51],\n",
       "       [ 10.  ,   8.55,  11.23, ...,   7.18,   0.  ,  10.99],\n",
       "       [  7.03,   6.82,   7.25, ...,   8.51,  10.99,   0.  ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = X.T @ X \n",
    "J = np.ones(G.shape)\n",
    "ones_v = np.ones(G.shape[0])\n",
    "g = np.diag(G)\n",
    "\n",
    "g_outer = np.outer(g, ones_v)\n",
    "\n",
    "D = g_outer + g_outer.T - 2*G\n",
    "\n",
    "D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.02, -0.23,  0.02, ...,  0.4 , -0.59,  0.6 ],\n",
       "       [-0.23,  3.82,  0.21, ...,  0.79,  0.03,  0.6 ],\n",
       "       [ 0.02,  0.21,  4.3 , ..., -0.18, -1.07,  0.63],\n",
       "       ..., \n",
       "       [ 0.4 ,  0.79, -0.18, ...,  4.72,  1.17,  0.21],\n",
       "       [-0.59,  0.03, -1.07, ...,  1.17,  4.79, -1.  ],\n",
       "       [ 0.6 ,  0.6 ,  0.63, ...,  0.21, -1.  ,  4.21]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some techniques in this cell from \"miniature_7_euclidean_distance_more_mds_proof.pdf\" in the 33 miniatures folder\n",
    "# this nicely ties in with the PDF here \n",
    "\n",
    "H = np.eye(D.shape[0])-np.ones(D.shape)/D.shape[0]\n",
    "B = -1/2*H @ D @ H.T \n",
    "# the transpose is for convenience of notation only, as H is symmetric \n",
    "B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L, Diagonal, perm = ldl(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00e+00,   0.00e+00,   0.00e+00, ...,   0.00e+00,   0.00e+00,   0.00e+00],\n",
       "       [ -5.66e-02,   1.00e+00,   0.00e+00, ...,   0.00e+00,   0.00e+00,   0.00e+00],\n",
       "       [  4.05e-03,   5.67e-02,   1.00e+00, ...,   0.00e+00,   0.00e+00,   0.00e+00],\n",
       "       ..., \n",
       "       [  1.00e-01,   2.13e-01,  -5.29e-02, ...,   1.00e+00,   0.00e+00,   0.00e+00],\n",
       "       [ -1.46e-01,  -1.16e-03,  -2.49e-01, ...,   7.42e-01,   1.00e+00,   0.00e+00],\n",
       "       [  1.50e-01,   1.67e-01,   1.38e-01, ...,  -1.74e+00,  -1.00e+00,   1.00e+00]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False], dtype=bool)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(Diagonal)>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(Diagonal[-1,-1])\n",
    "# this is a zero being registered as a a negative number which is somewhat problematic\n",
    "Diagonal[Diagonal <0] = 0\n",
    "# I need to double check that I did the masking correct here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tilde = L @ D **(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = X_tilde.T @ X_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.  ,   59.38,   44.28, ...,  105.08,  108.  ,   42.13],\n",
       "       [  59.38,    0.  ,   48.56, ...,   85.3 ,  100.12,   42.92],\n",
       "       [  44.28,   48.56,    0.  , ...,  106.94,  115.86,   33.82],\n",
       "       ..., \n",
       "       [ 105.08,   85.3 ,  106.94, ...,    0.  ,   34.11,  139.32],\n",
       "       [ 108.  ,  100.12,  115.86, ...,   34.11,    0.  ,  128.9 ],\n",
       "       [  42.13,   42.92,   33.82, ...,  139.32,  128.9 ,    0.  ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(np.diag(K), ones_v) + np.outer(ones_v, np.diag(K)) - 2 * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   8.3 ,   8.29, ...,   7.94,  10.  ,   7.03],\n",
       "       [  8.3 ,   0.  ,   7.69, ...,   6.96,   8.55,   6.82],\n",
       "       [  8.29,   7.69,   0.  , ...,   9.38,  11.23,   7.25],\n",
       "       ..., \n",
       "       [  7.94,   6.96,   9.38, ...,   0.  ,   7.18,   8.51],\n",
       "       [ 10.  ,   8.55,  11.23, ...,   7.18,   0.  ,  10.99],\n",
       "       [  7.03,   6.82,   7.25, ...,   8.51,  10.99,   0.  ]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2347603208433938e-13"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(L @ Diagonal @ L.T - B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.2140511112361"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(np.diag(Diagonal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.2140511112361"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(Diagonal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 338.29 +0.00e+00j,   -8.28 -1.76e-17j,   -8.15 -1.40e-16j,   -8.43 +1.58e-16j,   -8.53 +2.81e-16j,   -7.81 +1.76e-16j,   -8.82 +7.02e-17j,   -8.12 -7.02e-17j,\n",
       "         -6.69 +5.62e-16j,   -8.41 -3.16e-16j,   -8.86 +7.02e-17j,  -10.41 -1.40e-16j,   -7.07 +3.16e-16j,   -6.42 +2.81e-16j,  -10.34 +7.02e-17j,   -9.91 -1.40e-16j,\n",
       "         -7.88 -8.43e-16j,  -11.43 -2.11e-16j,   -8.93 -1.40e-16j,  -10.19 +2.81e-16j,   -8.90 -7.02e-17j,  -10.19 -5.27e-17j,   -8.93 +2.72e-16j,  -11.43 +7.02e-17j,\n",
       "         -7.88 +8.43e-16j,   -9.91 +2.11e-16j,  -10.34 -7.02e-17j,   -6.42 +7.02e-17j,   -7.07 -4.56e-16j,  -10.41 +5.27e-16j,   -8.86 +2.81e-16j,   -8.41 +2.11e-16j,\n",
       "         -6.69 -5.62e-16j,   -8.12 -2.98e-16j,   -8.82 +3.16e-16j,   -7.81 +3.51e-16j,   -8.53 -1.22e-15j,   -8.43 -1.05e-16j,   -8.15 -3.16e-16j,   -8.28 -2.11e-16j])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fft_one_way = np.fft.fft(D)\n",
    "fft_one_way = np.fft.fft(D, norm='ortho')\n",
    "fft_one_way\n",
    "# result = np.fft.fft(np.conj(fft_one_way).T).T\n",
    "result = np.fft.fft(np.conj(fft_one_way).T, norm='ortho').T\n",
    "\n",
    "np.diag(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 338.29,   -8.28,   -8.15,   -8.43,   -8.53,   -7.81,   -8.82,   -8.12,   -6.69,   -8.41,   -8.86,  -10.41,   -7.07,   -6.42,  -10.34,   -9.91,   -7.88,  -11.43,   -8.93,\n",
       "        -10.19,   -8.9 ,  -10.19,   -8.93,  -11.43,   -7.88,   -9.91,  -10.34,   -6.42,   -7.07,  -10.41,   -8.86,   -8.41,   -6.69,   -8.12,   -8.82,   -7.81,   -8.53,   -8.43,\n",
       "         -8.15,   -8.28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.real(np.diag(result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.real(np.diag(result)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16, -0.07,  0.1 , ..., -0.13,  0.18, -0.24],\n",
       "       [-0.16, -0.15, -0.03, ...,  0.23,  0.16, -0.  ],\n",
       "       [-0.16,  0.19, -0.18, ...,  0.03,  0.25, -0.12],\n",
       "       ..., \n",
       "       [-0.16,  0.26, -0.  , ..., -0.01, -0.12, -0.25],\n",
       "       [-0.16,  0.06,  0.16, ..., -0.32, -0.01, -0.19],\n",
       "       [-0.16,  0.06,  0.2 , ..., -0.2 ,  0.12,  0.11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.random.random(G.shape)\n",
    "B[:,0] *= 0\n",
    "B[:,0] += 1\n",
    "Q, R = np.linalg.qr(B)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 338.29,   -8.41,   -8.91,   -7.21,   -7.8 ,  -13.86,  -10.37,   -8.34,   -9.48,   -5.74,   -7.77,   -8.47,   -7.76,   -7.94,   -9.47,   -7.41,   -8.71,   -7.53,  -10.  ,\n",
       "         -7.3 ,   -9.14,  -10.04,   -9.07,   -7.03,   -6.79,   -9.31,  -12.11,   -8.57,   -5.67,   -8.95,   -9.99,   -6.51,   -6.22,   -9.36,   -9.08,  -10.75,  -10.77,   -7.77,\n",
       "         -8.55,  -10.15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(Q.T @ D @ Q)\n",
    "# grabs the diagonal of the result matrix and puts it in a vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.38e+02,  -5.59e+00,   6.58e+00, ...,   3.83e+00,  -1.03e-01,  -6.15e-01],\n",
       "       [ -5.59e+00,  -8.41e+00,  -1.90e+00, ...,  -1.35e-01,   8.92e-01,  -1.03e+00],\n",
       "       [  6.58e+00,  -1.90e+00,  -8.91e+00, ...,   1.67e-01,   4.91e-01,  -4.01e-02],\n",
       "       ..., \n",
       "       [  3.83e+00,  -1.35e-01,   1.67e-01, ...,  -7.77e+00,   1.13e+00,  -2.27e-01],\n",
       "       [ -1.03e-01,   8.92e-01,   4.91e-01, ...,   1.13e+00,  -8.55e+00,   9.82e-01],\n",
       "       [ -6.15e-01,  -1.03e+00,  -4.01e-02, ...,  -2.27e-01,   9.82e-01,  -1.02e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.T @ D @ Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -2.83e+01,  -2.48e+01,  -2.19e+01,  -2.15e+01,  -2.05e+01,  -1.93e+01,  -1.80e+01,  -1.56e+01,  -1.43e+01,  -1.36e+01,  -1.30e+01,  -1.20e+01,  -1.18e+01,  -1.07e+01,\n",
       "         -1.03e+01,  -9.52e+00,  -8.26e+00,  -7.90e+00,  -7.40e+00,  -6.57e+00,  -5.79e+00,  -5.13e+00,  -4.20e+00,  -3.87e+00,  -3.78e+00,  -3.44e+00,  -3.38e+00,  -2.88e+00,\n",
       "         -2.35e+00,  -2.14e+00,  -1.65e+00,  -1.53e+00,  -1.42e+00,  -8.92e-01,  -8.19e-01,  -4.52e-01,  -4.20e-01,  -3.26e-01,  -2.25e-01,   3.40e+02]),\n",
       " array([[-0.01,  0.1 , -0.18, ...,  0.13, -0.23,  0.11],\n",
       "        [ 0.24,  0.15, -0.14, ..., -0.22,  0.29,  0.02],\n",
       "        [-0.24,  0.06,  0.28, ..., -0.04,  0.03,  0.07],\n",
       "        ..., \n",
       "        [ 0.06,  0.2 ,  0.02, ...,  0.15,  0.02,  0.01],\n",
       "        [-0.16, -0.19, -0.18, ..., -0.25, -0.12, -0.33],\n",
       "        [ 0.01, -0.44, -0.21, ...,  0.07, -0.2 ,  0.1 ]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_similar = Q @ D @ Q.T\n",
    "np.linalg.eigh(D_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0605739337042905e-13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_v @ D_similar @ ones_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3,  1, -3],\n",
       "       [20,  3, 10],\n",
       "       [ 2, -2,  4]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[-3,1,-3],[20,3,10],[2,-2,4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-107.88    0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "    0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.      0.    147.88]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 40.  ,  21.23,  18.71, ...,  21.2 ,  18.62,  17.17],\n",
       "       [ 21.23,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "       [ 18.71,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "       ..., \n",
       "       [ 21.2 ,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "       [ 18.62,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "       [ 17.17,   0.  ,   0.  , ...,   0.  ,   0.  ,   0.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# side project here: \n",
    "G = B.T @ B\n",
    "G[1:,1:] *=0 \n",
    "G\n",
    "# a rank two matrix...  \n",
    "# I want to estimate eigs of this real symmetric matrix\n",
    "eigs = np.linalg.eigvalsh(G)\n",
    "print(eigs)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15952.133329366981"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_sum = 0\n",
    "for k in range(1, G.shape[0]):\n",
    "    running_sum += G[0,k] * G[k,0]\n",
    "    \n",
    "running_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.30882747345578"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sqrt(running_sum*2) + G[0,0])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31904.26665873397"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(G.T @ G) - G[0,0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15952.133329366985"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigs[-1] * eigs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,  -4.,  -3.,  18.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.poly(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2. +0.00e+00j,  3. +1.19e-07j,  3. -1.19e-07j])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
