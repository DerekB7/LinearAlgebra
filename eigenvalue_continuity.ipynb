{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in general for scalars in $\\mathbb C$  \n",
    "\n",
    "the fact that eigenvalues, as roots to the characteristic polynomial vary continuously with their coefficients (see discussion below) and that coefficients to the characteristic polynomial vary continuously with entries in a matrix (standard proof uses principle minors -- for an alternative proof using trace and various matrix powers see \"Schurs_Inequality.ipynd\"), means that eigenvalues vary continously with components of a matrix.  \n",
    "\n",
    "**insert skeptch of proof that roots to monic polynomial vary continuously with coefficients using rudiments of planar topology, in particular winding numbers count roots, a useful inequality from Beardon, and a basic linear homotopy.**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that eigenvalues vary continuously with matrix components allows some rather nice analytical proofs of results involving eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular it allows for some very nice proofs of results with Hermitian (inclusive of real symmetric) matrices since the eigenvalues vary contiuously with components of the matrix, but so long as we ensure Hermiticity the entire time, we know the eigenvalues must be real, and we may make use of Intermediate Value Theorem, in particular with respect to sign changes in eigenvalues implies a zero in between, which has rank implications, and we may use rank as a useful invariant along the way.  (There is some machinery buried, however, related to a theorem from Kato which ensures we can actually parameterize the eigenvalues as continuous functions... see \"Eigenvalue Continuity and Gerschgorin's Theorem\" by Li and Zhang  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sylvester's Law of Inertia**  \n",
    "\n",
    "*note:* this closely follows the approach in Meyer's Matrix Analysis, an accordingly usese QR factorization, though we could just as easily use SVD or other spectral theorem related results  \n",
    "\n",
    "The argument is for Hermitian $\\mathbf A \\in \\mathbb C^{\\text{n  x  n}}$, the matrix has a certain number of positive, negative and zero eigenvalues $\\big(r, k, m\\big)$ (where $n=r+k+m$) which is called the signature.  This is invariant under congruence transforms.  I.e. for any invertible $\\mathbf B \\in \\mathbb C^{\\text{n  x  n}}$  the signature of \n",
    "\n",
    "$\\mathbf B^* \\mathbf{AB}$ is the same as that for $\\mathbf A$.  \n",
    "\n",
    "\n",
    "*proof:*  \n",
    "\n",
    "run QR factorization on $\\mathbf B$ to get $\\mathbf B = \\mathbf Q\\mathbf R$. Since $\\mathbf B$ is non-singular we know the diagonal components of $\\mathbf R$ are non-zero, and infact we insist they are positive (if they are not positive make use of diagonal matrix $\\mathbf D$ which has all components on the unit circle such that $\\big(\\mathbf {DR}\\big)$ has all positive components on the diagonal and see that \n",
    "\n",
    "$\\mathbf B = \\mathbf Q \\mathbf R = \\mathbf Q \\mathbf I\\mathbf R = \\mathbf Q \\mathbf D^* \\mathbf D \\mathbf R = \\big(\\mathbf Q \\mathbf D^*\\big) \\big(\\mathbf D \\mathbf R\\big) $\n",
    "\n",
    "where $\\big(\\mathbf Q \\mathbf D^*\\big)$ is unitary and $\\big(\\mathbf D \\mathbf R\\big)$ is upper triangular with positive components on the diagonal.  Accordingly we assume WLOG that $B = \\mathbf Q\\mathbf R$ with $\\mathbf R$ having strictly positive entries on the diagonal.  \n",
    "\n",
    "now consider \n",
    "\n",
    "$\\mathbf X(\\tau) := \\tau \\mathbf Q + (1-\\tau)\\mathbf Q \\mathbf R = \\mathbf Q\\big(\\tau \\mathbf I + (1-\\tau) \\mathbf R\\big)$  \n",
    "for $\\tau \\in [0,1]$  \n",
    "\n",
    "and notice that for any $\\tau$ in the domain $\\det\\big(\\mathbf X(\\tau)\\big) \\neq 0$  \n",
    "\n",
    "finally considering \n",
    "\n",
    "$\\mathbf Y(\\tau) := \\mathbf X^*(\\tau)\\mathbf A\\mathbf X(\\tau)$  \n",
    "or  \n",
    "$\\mathbf Y(\\tau) = \\big(\\tau \\mathbf I + (1-\\tau) \\mathbf R^*\\big)\\mathbf Q^* \\mathbf A\\mathbf Q\\big(\\tau \\mathbf I + (1-\\tau) \\mathbf R\\big)$  \n",
    "\n",
    "where $\\mathbf Y(\\tau)$ is Hermitian for any $\\tau \\in [0,1]$  \n",
    "\n",
    "in particular   \n",
    "$\\mathbf Y(0)= \\mathbf Q^*\\mathbf R^* \\mathbf A\\mathbf Q\\mathbf R = \\mathbf B^* \\mathbf A\\mathbf B$  \n",
    "$\\mathbf Y(1) = \\mathbf Q^* \\mathbf A\\mathbf Q$  \n",
    "which is similar to $\\mathbf A$ and hence has the same eigenvalues as $\\mathbf A$  \n",
    "\n",
    "and for any $\\tau \\in [0,1]$  \n",
    "\n",
    "$\\text{rank}\\big(\\mathbf Y(\\tau)\\big) = \\text{rank}\\big(\\mathbf A\\big)$  \n",
    "(because $\\mathbf X(\\tau)$ is always invertible)  \n",
    "hence rank is a key invariant.    \n",
    "\n",
    "\n",
    "The proof follows in two stages:   \n",
    "*stage 1:*  consider the case where $\\text{rank}\\big(\\mathbf A\\big) = n$, i.e. our matrix of interest is invertible.  It is immediate that \n",
    "$\\mathbf Y(0)$ has the same signature $\\big(r, k, m\\big)$ as $\\mathbf Y(1)$ because if it did not then (at least) one of the eigenvalues changed sign and by intermediate value theorem there is some $\\tau^* $   where   \n",
    "$\\text{rank}\\big(\\mathbf Y(\\tau^*)\\big) \\lt n$ which contradicts the constancy of rank.  \n",
    "\n",
    "*stage 2:* consider the case where $\\text{rank}\\big(\\mathbf A\\big) = n-m \\lt n$    \n",
    "There are two ways to finish.  One is again to observe that rank is an invariant for $\\mathbf Y(\\tau)$ and if there is a change in signature then at least one sign change occurred and some eigenvalue went from positive to negative (or vice versa) crossing zero in between.  Topologically we observe that the preimage of each and every eigenvalue taking value zero is a closed set, since the image point $[0]$ is closed.  Inevitably this means that if a 'crossing' occurred then there must be too many eigenvalues equal to zero (rank deficiency) or too few eigenvalues equal to zero (rank excess) for some $\\tau^*$ when (one of) the crossing(s) ocurred.  This is conceptually simple but not so easy to write out.  \n",
    "\n",
    "An alternative approach is the one suggested, in effect by Meyer.  Supposing $\\mathbf A$ is singular, put all of its $n$ eigenvalues in a set.  There are $l$ distinct eigenvalues and call the minimum pairwise distance between these $l$ eigenvalues $d_1$.  Now re-run the argument \n",
    "\n",
    "$\\mathbf Y(\\tau, \\alpha) = \\mathbf X^*(\\tau)\\big(\\mathbf A + \\alpha \\mathbf I\\big)\\mathbf X(\\tau)$  \n",
    "\n",
    "where $\\alpha$ is a real valued slack parameter, initially set equal to $0$.  Supposing for a contradiction that the signature changes, we know it must have occurred by a change in positives vs negative (since zeros constant as rank is invariant) and assume WLOG that the number of positives decreases and the number of negatives decreased.  Now look at the eigenvalues of \n",
    "$\\mathbf Y(0,\\alpha =0)$  \n",
    "\n",
    "and again place them in a set, computing the minimum pairwise distance between them, calling it $d_2$.  \n",
    "\n",
    "Now set $\\alpha = \\alpha^* = \\frac{1}{2}\\min{d_1,d_2}$  \n",
    "\n",
    "and we have a contradiciton because $\\mathbf Y(0,\\alpha =\\alpha^*)$ has the same signature as $\\mathbf Y(0,\\alpha =0)$, and in particular has extra negative signs (the affine shift of eigenvalues was too small to have a sign crossing), but $\\big(\\mathbf A + \\alpha^* \\mathbf I\\big)$ is non-singular so we know it cannot have had a sign change for $\\tau \\in [0,1]$ by the stage one argument, and in fact it has the same number of negative eigenvalues as $\\mathbf A$ which is which is equal to the number of negative eigenvalues in $\\mathbf Y(0,\\alpha =\\alpha^*)$ strictly less than the number of negative eigenvalues of $\\mathbf Y(0,\\alpha =\\alpha^*)$, a contradiction.  \n",
    "\n",
    "*this second stage argument could be cleaned up / streamlined a bit*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://cklixx.people.wm.edu/ELA-LiZhangMS4123.pdf  \n",
    "\n",
    "the interpretation for the non-singular of $\\mathbf A$  \n",
    "with \n",
    "\n",
    "$p_(x,\\tau) = \\det\\big(x\\mathbf I - \\mathbf Y(\\tau)\\big)$    \n",
    "(or equivalently considering this as a linear combination of the minors of $\\mathbf Y(\\tau)$  or using newton's identity on $\\mathbf Y(\\tau)$)  \n",
    "\n",
    "compute a winding number around  \n",
    "the circle centered at m, with radius $m$  and $m$ chosen such that it is bigger than any possible eigenvalue of $\\mathbf Y(t)$  -- e.g. using Schur's Test and operator 2 norm submultiplicativity (aka Schatten $\\infty$ norm) we have  \n",
    "\n",
    "$\\Big \\Vert \\mathbf Y(\\tau)\\Big \\Vert_2 $  \n",
    "$= \\Big \\Vert \\big(\\tau \\mathbf I + (1-\\tau) \\mathbf R^*\\big)\\mathbf Q^* \\mathbf A\\mathbf Q\\big(\\tau \\mathbf I + (1-\\tau) \\mathbf R\\big)\\Big \\Vert_2 $  \n",
    "$\\leq \\Big \\Vert \\big(\\tau \\mathbf I + (1-\\tau) \\mathbf R\\big)\\Big \\Vert_2^2 \\Big \\Vert\\mathbf Q^* \\mathbf A\\mathbf Q\\Big \\Vert_2  $   \n",
    "$\\leq \\Big\\{\\tau^2 \\Big \\Vert \\mathbf I\\big \\Vert_2^2 + 2\\tau(1-\\tau) \\big \\Vert \\mathbf I \\big \\Vert_2 \\cdot \\big \\Vert \\mathbf R\\Big \\Vert_2 + (1-\\tau) \\big \\Vert \\mathbf R \\big \\Vert_2^2\\Big\\} \\big \\Vert \\mathbf A\\big \\Vert_2  $   \n",
    "$\\lt \\Big\\{1 + \\big \\Vert \\mathbf R\\Big \\Vert_2 + \\big \\Vert \\mathbf R \\big \\Vert_2^2\\Big\\} \\big \\Vert \\mathbf A\\big \\Vert_2  $   (noting that $2\\tau(1-\\tau)\\leq \\frac{1}{2} \\lt 1$ by $\\text{GM}\\leq \\text{AM}$ and $\\big\\Vert \\mathbf I \\big \\Vert_2 = 1$)  \n",
    "$=\\Big\\{1 + \\big \\Vert \\mathbf B\\Big \\Vert_2 + \\big \\Vert \\mathbf B \\big \\Vert_2^2\\Big\\} \\big \\Vert \\mathbf A\\big \\Vert_2  $  \n",
    "and we can bound the maximal singular value of $\\mathbf B$ by applying the Schur Test (i.e. maximal row magnitude sum (L1 norm of each row and take the max) times maximal column magnitude sum, then take square root -- see \"Fun with trace\" notebook in linear algebra folder) so $\\big \\Vert \\mathbf B\\big \\Vert_2 = \\sigma \\leq \\gamma_1$   -- and we can apply the same test/inequality to $\\mathbf A$ to get $\\big \\Vert \\mathbf A\\big \\Vert_2 = \\sigma \\leq \\gamma_2$  \n",
    "\n",
    "and selecting \n",
    "\n",
    "$2m:=\\Big(1 + \\gamma_1 + \\gamma_1^2 \\Big) \\gamma_2$  \n",
    "(Gerschgorin discs may also be used instead of the Schur test)  \n",
    "\n",
    "gives a satisfactory result.  \n",
    "\n",
    "note:  \n",
    "an even easier approach is to use the fact that  \n",
    "$\\sigma \\leq \\big(\\sum_{k=1}^n \\sigma_k\\big)^\\frac{1}{2} = \\big \\Vert \\mathbf M \\big \\Vert_F$  \n",
    "and then use subadditivity and submultiplicativity of the Frobenius norm to get a very simple and crude upper bound on maximal singular value (or maximal magnitude eigenvalue)  \n",
    "\n",
    "\n",
    "now we may compute the winding number around (about zero) over this closed circular path radius $m$ centered at $m$ and observe that we have a homotopy from $\\tau \\in [0,1]$  between  \n",
    "\n",
    "$p_(x,0) \\to p(x,1)$  \n",
    "\n",
    "The value zero can never be in this path because \n",
    "$p_(x,\\tau)$ only has real roots (Hermitian matrices generate the polynomial), and our closed path in our domain only intersects the real axis in two locations -- $2m$ and $0$ neither of which can be roots to  $p_(x,\\tau)$ because the maximal eigenvalue of $p(x,\\tau)$ is $\\lt 2m$  and $p(0,\\tau) \\neq 0$  because $\\text{rank}\\big(\\mathbf Y(\\tau)\\big) = n$ for any $\\tau \\in [0,1]$.  \n",
    "\n",
    "This means \n",
    "$p_(x,0)$ and $p(x,1)$  \n",
    "have the same winding number and hence same number of roots in this region -- and indeed on the entire positive real line (since neither may have eigenvalues $\\gt 2m$).  Neither $p_(x,0)$ nor $p(x,1)$ has eigenvalues of $x=0$ and they have the same degree, so they must have the same number of negative eigenvalues as well.  \n",
    "- - - -  \n",
    "As in the Meyer setup, this implies the result even when $\\text{rank}\\big(\\mathbf A\\big) \\lt n$.  In this case we call the smallest magnitude negative eigenvalue of $\\mathbf A:= d$ (where $d \\lt 0$)  \n",
    "\n",
    "(if $\\mathbf A$ has no negative eigenvalues then the desired result is immediate because $\\mathbf A$ is positive semidefinite and $\\mathbf B^* \\mathbf{AB} = \\mathbf B^* \\mathbf C^* \\mathbf {CB} $  so the product is positive semi-definite, and we note that rank doesn't change when multiplying by an invertible matrix, so we proceed by assuming as least one negative eigenvalue -- and there are in any case finitely many of them)  \n",
    "\n",
    "now consider re-running the above argument on  \n",
    "$\\mathbf A'_k := \\mathbf A + \\frac{\\vert d\\vert}{1 + k}\\mathbf I$  \n",
    "\n",
    "This gives a density argument in the simplest form because  \n",
    "$\\lambda_i\\big(\\mathbf A'_k\\big) = \\lambda_i\\big(\\mathbf A\\big) + \\frac{\\vert d\\vert}{1 + k}$  \n",
    "or  \n",
    "$\\lambda_i\\big(\\mathbf A\\big) = \\lambda_i\\big(\\mathbf A'_k\\big)-\\frac{\\vert d\\vert}{1 + k}  $  \n",
    "\n",
    "\n",
    "so this tells us that we have $\\text{rank}\\big(\\mathbf A'_k\\big) = n$ for all natural numbers $k$ and that the number of negative eigenvalues of $\\mathbf A'_k$ is the same as the number of negative eigenvalues of $\\mathbf A$   \n",
    "\n",
    "Application of the prior result tells us that for all negative eigenvalues of $\\mathbf A'$ we have that they are still negative after the congruence transform (i.e. $\\mathbf B^* \\mathbf A'_k \\mathbf B$) \n",
    "so for any negative eigenvalue (recalling that the multiplicities are the same for $\\mathbf A'$ and $\\mathbf A$) we have  \n",
    "\n",
    "$\\lambda_i\\big(\\mathbf A'_k\\big) \\lt 0 \\longrightarrow \\lambda_i\\big(\\mathbf B^* \\mathbf A'_k \\mathbf B\\big) \\lt 0 $   \n",
    "\n",
    "This combined with the topological continuity of eigenvalues gives the desired result -- i.e. suppose for a contradiction that the number of positive eigenvalues in $\\mathbf B^*\\mathbf A\\mathbf B$ is strictly greater than in $\\mathbf A$, since $\\mathbf B^*\\mathbf A\\mathbf B$ and $\\mathbf A$ have the same rank (which implies same number of zero eigenvalues) this means some negative eigenvalue of $\\mathbf A$ must have 'crossed over' into a positive one.  We can   lower bound this distance by considering \n",
    "\n",
    "$\\lambda_{\\text{min positive}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) -  \\lambda_{\\text{smallest magnitude negative}}\\big(\\mathbf A\\big) \\geq \\lambda_{\\text{min positive}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) - 0 = \\lambda_{\\text{min positive}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) = c \\gt 0 $\n",
    "\n",
    "with  \n",
    "$\\lambda_{\\text{min positive}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) = c $    \n",
    "\n",
    "since the eigenvalues vary (topologically) continuously with the components of the matrix, we select $\\epsilon := \\frac{c}{3} \\gt 0$ which implies a $\\delta \\gt 0$ neighborhood where \n",
    "\n",
    "if $\\big \\Vert \\mathbf B^*\\mathbf A\\mathbf B - \\mathbf C \\big \\Vert_F \\lt 0 \\longrightarrow \\text{eigenvalue difference}\\big(\\mathbf B^*\\mathbf A\\mathbf B - \\mathbf C\\big) \\lt \\epsilon$  \n",
    "\n",
    "setting $\\mathbf C:= \\mathbf B^*\\mathbf A'_k\\mathbf B$  \n",
    "\n",
    "$\\big \\Vert \\mathbf B^*\\mathbf A\\mathbf B - \\mathbf C \\big \\Vert_F = \\frac{\\vert d\\vert}{1 + k}\\big \\Vert \\mathbf B^*\\mathbf B \\big \\Vert_F \\lt \\delta$   \n",
    "for large enough k gives  \n",
    "\n",
    "$c \\leq \\text{magnitude of eigenvalue difference}\\big(\\mathbf B^*\\mathbf A\\mathbf B - \\mathbf C\\big) \\lt \\epsilon =\\frac{c}{3}$   \n",
    "which is a contradiction \n",
    "\n",
    "(where eigenvalue difference is taken to be the minimum magnitude over all permutations, e.g. as on the 2nd page in the above cited paper from Li and Zhang-- equivalently, the metric used when proving topological eigenvalue continuity in Horn and Johnson 2nd edition of *Matrix Analysis*)  \n",
    "\n",
    "This implies we cannot have an increase in the multiplicities of the positive eigenvalues after the congruence transform, i.e. with $\\mathbf B^*\\mathbf A\\mathbf B$, and re-running the argument on $-\\mathbf A$ implies that we cannot have an increase in the number of negative eigenvalues of $\\mathbf A$ after the congruence transform. Since the number of zero eigenvalues (i.e. dimension of nullspace for hermitian matriceso or equivalently: rank) is preserved under congruence transform, we have  \n",
    "\n",
    "$\\lambda_{\\text{number positive}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) \\leq \\lambda_{\\text{number positive}}\\big(\\mathbf A\\big)$  \n",
    "$\\lambda_{\\text{number negative}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) \\leq \\lambda_{\\text{number negative}}\\big(\\mathbf A\\big)$  \n",
    "$\\lambda_{\\text{number zero}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) = \\lambda_{\\text{number zero}}\\big(\\mathbf A\\big)$  \n",
    "\n",
    "\n",
    "\n",
    "and summing over the bound we have  \n",
    "\n",
    "$n $  \n",
    "$= \\lambda_{\\text{number positive}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) + \\lambda_{\\text{number negative}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big) + \\lambda_{\\text{number zero}}\\big(\\mathbf B^*\\mathbf A\\mathbf B\\big)$  \n",
    "$\\leq \\lambda_{\\text{number positive}}\\big(\\mathbf A\\big) + \\lambda_{\\text{number negative}}\\big(\\mathbf A\\big) + \\lambda_{\\text{number zero}}\\big(\\mathbf A\\big)$  \n",
    "$ = n$  \n",
    "\n",
    "where equality is reach **iff** each inequality is an equality -- and since equality *is* reached we know the multiplicities must be the same.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With continuity of eigenvalues in hand we can easily prove some other interesting results, in particular   \n",
    " **Cauchy's Theorem of Interlacing of Eigenvalues**      \n",
    "\n",
    "Consider in particular an \n",
    "\n",
    "$\\text{n  x   r}$ matrix $\\mathbf Q$ with mutually orthnormal columns but $r\\lt n$, so \n",
    "\n",
    "$\\mathbf Q^* \\mathbf Q = \\mathbf I_r$  but   \n",
    "$\\mathbf Q \\mathbf Q^* = \\mathbf P$  which is a projector (hermitian and idempotent).  \n",
    "\n",
    "the result holds in general however **we focus on the the most important special case of** $r := n-1$  \n",
    "**some cleanup is needed around this point**  \n",
    "\n",
    "what Cauchy's Interlacing Theorem says is that the $n$ eigenvalues of $\\mathbf A$ interlace with those of $(n-1)$ eigenvalues of $\\big(\\mathbf Q^* \\mathbf A\\mathbf Q\\big)$, i.e.  \n",
    "\n",
    "$\\lambda_1 \\geq \\sigma_1 \\geq \\lambda_2 \\geq \\sigma_2 \\geq .... \\geq\\lambda_{n-2} \\geq \\sigma_{n-2}\\geq \\lambda_{n-1}\\geq \\sigma_{n-1} \\geq \\lambda_n$  \n",
    "\n",
    "to prove this we start by observing that operating solely with square matrices (i.e. everything $n$ by $n$) is easier than changing dimensions, and the case of *simple* eigenvalues --i.e. where all eigenvalues are unique-- is easiest.  We start here with the *simple eigenvalue case* and build out the general proof.    \n",
    "\n",
    "In particular, referencing the e.g. the vandermonde matrices writeup, note that \n",
    "\n",
    "$\\mathbf Q^*\\mathbf A \\mathbf Q $ has the same non-zero eigenvalues as \n",
    "$\\mathbf Q\\mathbf Q^*\\mathbf A  = \\mathbf P \\mathbf A  = \\mathbf P^2 \\mathbf A  $  \n",
    "and \n",
    "$\\mathbf P^2 \\mathbf A  $  has the same eigenvalues as $\\mathbf P \\mathbf A \\mathbf P =  \\mathbf P \\mathbf A \\mathbf P^*$  \n",
    "because they all have the same traces.  However $\\mathbf P^2 \\mathbf A  $ and $\\mathbf P \\mathbf A \\mathbf P^*$ are $\\text{n  x  n}$ like $\\mathbf A$ and the latter is Hermitian as well so it is easiest to work with.  \n",
    "\n",
    "\n",
    "note that  \n",
    "$\\mathbf P = \\mathbf Q\\mathbf D \\mathbf Q^* = \\mathbf Q \\begin{bmatrix}\n",
    "\\mathbf I_r & \\mathbf 0\\mathbf 0^T \\\\ \n",
    " \\mathbf 0\\mathbf 0^T& \\big(\\mathbf 0\\mathbf 0^T\\big)_{n-r}\n",
    "\\end{bmatrix} \\mathbf Q^*$ \n",
    "\n",
    "so when we consider  the eigenvalues of\n",
    "$\\mathbf P \\mathbf A \\mathbf P^* = \\mathbf Q\\mathbf D \\mathbf Q^*  \\mathbf A \\mathbf Q\\mathbf D \\mathbf Q^*  = \\mathbf Q\\mathbf D \\big(\\mathbf Q^*  \\mathbf A \\mathbf Q\\big)\\mathbf D \\mathbf Q^* = \\mathbf Q\\mathbf D \\mathbf B\\mathbf D \\mathbf Q^*$   \n",
    "\n",
    "where $\\mathbf B$ is similar to $\\mathbf A$.  We can further simplify this by noting that \n",
    "\n",
    "$\\mathbf P \\mathbf A \\mathbf P^* $ is similar to $\\mathbf D \\mathbf B\\mathbf D $ hence it is enough to consider the spectra of $\\mathbf D \\mathbf B\\mathbf D  = \\mathbf D \\mathbf B\\mathbf D^* $  \n",
    "*remark: this is one of the common use cases of interlacing -- when we want to 'grab' an n-1 principle submatrix (which by graph isomorphism arguments we can always assume WLOG that we want the submatrix in the upper left hand corner)*  \n",
    "\n",
    "\n",
    "now consider \n",
    "\n",
    "$\\mathbf X(\\tau) = \\tau\\mathbf D + (1-\\tau)\\mathbf I_n$  \n",
    "for $\\tau \\in [0,1]$  \n",
    "\n",
    "note that for $\\tau \\in [0,1)$ we know $\\mathbf X(\\tau) = \\tau\\mathbf D + (1-\\tau)\\mathbf I_n$  is non-singular (and Hermitian positive definite in particular)  \n",
    "\n",
    "and  \n",
    "$\\mathbf Y(\\tau) = \\mathbf X(\\tau)\\mathbf B \\mathbf X(\\tau) = \\mathbf X(\\tau)^*\\mathbf B \\mathbf X(\\tau)$  \n",
    "\n",
    "so by Sylvester's Law of Interia, we know that for $\\tau \\in [0,1)$  \n",
    "$\\text{signature}\\big(\\mathbf Y(\\tau)\\big) = \\text{signature}\\big(\\mathbf B\\big) = \\text{signature}\\big(\\mathbf A\\big)$\n",
    "\n",
    "the proof follows by iterating through **tbc n or n+1** $n+1$ steps, i.e. considering \n",
    "\n",
    "$\\big(\\mathbf A + \\gamma_i \\mathbf I_n\\big)$  which is similar to $\\big(\\mathbf B + \\gamma_i \\mathbf I_n\\big)$  \n",
    "\n",
    "where the $\\gamma_i \\in \\mathbb R$ are chosen such that \n",
    "\n",
    "i=0  \n",
    "$\\big(\\mathbf B + \\gamma_i \\mathbf I_n\\big)$  \n",
    "is positive definite, i.e. with signature $(n,0,0)$ \n",
    "**tbc, may want to delete the i=0 case**  \n",
    "\n",
    "i=1   \n",
    "$\\big(\\mathbf B + \\gamma_i \\mathbf I_n\\big)$  \n",
    "is positive-semi definite with a single eigenvalue equal to zero \n",
    "i.e. with signature $(n-1,0,1)$ \n",
    "\n",
    "i=2  \n",
    "$\\big(\\mathbf B + \\gamma_i \\mathbf I_n\\big)$  \n",
    "with signature $(n-2,1,1)$ \n",
    "\n",
    "and in general for $i \\in \\{1,2,...,n\\}$  \n",
    "$\\big(\\mathbf B + \\gamma_i \\mathbf I_n\\big)$  \n",
    "with signature $(n-i,i-1,1)$   \n",
    "**TBC whether it is n or r here**  \n",
    "\n",
    "- - - - -  \n",
    "the proof itself works by toggling 3 different interpretations of what we are after \n",
    "\n",
    "1.) looking at the spectra of \n",
    "$\\big(\\mathbf A + \\gamma_i \\mathbf I\\big)$  vs  \n",
    "$\\Big(\\mathbf Q^* \\big(\\mathbf A + \\gamma_i \\mathbf I_n\\big)\\mathbf Q\\Big)= \\Big(\\big(\\mathbf Q^* \\mathbf A\\mathbf Q\\big) + \\gamma_i\\mathbf I_r\\Big)$  \n",
    "\n",
    "i.e. from this viewpoing it is clear that $\\mathbf A$ has each of its $n$ eigenvalues incremented (shifted) by $\\gamma_i$ and it is also clear that each of the $r$ eigenvalues of $\\Big(\\big(\\mathbf Q^* \\mathbf A\\mathbf Q\\big)$  are incremented by $\\gamma_i$. This means that $\\gamma_i$ cannot change orderings of eigenvalues i.e. whether \n",
    "$\\sigma_j \\leq \\lambda_k$ is independent of $\\gamma_i$  \n",
    "\n",
    "\n",
    "2.) then ignoring the *(n-r)* extra eigenvalues equal to zero that are here, consider the 'equivalent' spectra of  \n",
    "$\\mathbf D \\big(\\mathbf B + \\gamma_i \\mathbf I\\big)\\mathbf D$  \n",
    "\n",
    "3.) We can back into the results of in the case of (2) by using  \n",
    "$\\mathbf Y_i(\\tau) = \\mathbf X(\\tau)\\big(\\mathbf B + \\gamma_i \\mathbf I\\big) \\mathbf X^*(\\tau)$\n",
    "- - - -  \n",
    "so for $i = 1, ..., n$  \n",
    "\n",
    "in case of i=1 \n",
    "we have \n",
    "$\\mathbf Y_1(\\tau)$   \n",
    "has signature $(n-1,0,1)$  \n",
    "for $\\tau \\in [0,1)$   \n",
    "and for $\\tau = 1$  we have \n",
    "has signature $(\\leq n-r,0, \\geq r)$  \n",
    "But this tells us that $\\sigma_r$ i.e. the smallest eigenvalue for $\\mathbf Q^*\\mathbf A \\mathbf Q $ is at least zero and in particular  $0 = \\lambda_n +\\gamma_1 \\leq \\sigma_r +\\gamma_1 $  \n",
    "\n",
    "in case of i=2  \n",
    "we have \n",
    "$\\mathbf Y_2(\\tau)$   \n",
    "has signature $(n-2,1,1)$  \n",
    "for $\\tau \\in [0,1)$   \n",
    "and for $\\tau = 1$  we have \n",
    "has signature $(\\leq n-2-1,\\leq 1, \\geq 1)$  *needs cleaned up*  \n",
    "But this tells us that $\\sigma_{r-1}$ i.e. the 2nd smallest eigenvalue for $\\mathbf Q^*\\mathbf A \\mathbf Q $ is at least zero and in particular  \n",
    "$0 = \\lambda_{n-1} +\\gamma_2 \\leq \\sigma_{r-1} +\\gamma_2 $   \n",
    "\n",
    "however we also know that  \n",
    "$\\lambda_n+\\gamma_2 \\leq \\sigma_r + \\gamma_2\\leq 0 =\\lambda_{n-1}+ \\gamma_2$   \n",
    "i.e. in effect the $\\sigma_r +\\gamma_2$ was the 1 negative eigenvalue for $\\tau \\in [0,1)$.  How do we know this?  \n",
    "**we should be able to streamline it right here**  \n",
    "\n",
    "\n",
    "Consider some sufficiently small $\\delta \\gt 0$ and observe  \n",
    "\n",
    "$\\lambda_n+\\gamma_2 - \\delta \\leq \\sigma_r + \\gamma_2- \\delta \\leq -\\delta =\\lambda_{n-1}+ \\gamma_2 -\\delta \\lt 0$    \n",
    "i.e. for a contradiction if $\\sigma_r +\\gamma_2 \\gt 0$  then for small enough $\\delta$   \n",
    "$\\sigma_r +\\gamma_2 -\\delta \\gt 0$   \n",
    "(i.e. all eigs of the projected matrix are non-negative)  \n",
    "but in this case \n",
    "$\\mathbf Y_2(\\tau)$   \n",
    "has signature $(n-2,2,0)$  \n",
    "for $\\tau \\in [0,1)$   \n",
    "and for $\\tau = 1$ the signature is such that there is exactly one zero but if $\\sigma_r +\\gamma_2 -\\delta \\gt 0$  then all eigenvalues of the (n-1 x n-1) are greater than zero i.e. there is a signature $(n-1,0,1)$ which is impossible because there would need to be a $\\tau^*\\in [0,1)$ where the signature $(n-1,2,1)$ , a contradiction \n",
    "\n",
    "in effect the issue is there cannot be a continuous mapping of the signature   \n",
    "$ (n-2,2,0) \\to (n-1,0,1)$   \n",
    "with the LHS for any $\\tau \\in [0,1)$   and the latter for $\\tau = 1$  \n",
    "because any negative eigenvalue (middle coordinate) must first pass through zero (right coordinate) before becoming negative (left coordinate).  \n",
    "- - - -   \n",
    "\n",
    "and for $\\tau = 1$  we have \n",
    "has signature $(\\leq n-2-r,\\leq 1, \\geq r)$  *needs cleaned up*  \n",
    "But this tells us that $\\sigma_{r-k+1}$ i.e. the kth smallest eigenvalue for $\\mathbf Q^*\\mathbf A \\mathbf Q $ is at least zero and in particular  \n",
    "*indices are off around k here and need cleaned up*  \n",
    "$0 = \\lambda_{n-k+1} +\\gamma_k \\leq \\sigma_{r-k+1} +\\gamma_k $  \n",
    "and by a similar as before argument \n",
    "$\\sigma_{r-k+2} \\leq \\lambda_{n-k+1}$  \n",
    "where as before assume for a contradiction $\\sigma_{r-k+2} \\gt \\lambda_{n-k+1}$ and select sufficiently small $\\delta \\gt 0$ such that  \n",
    "$\\sigma_{r-k+2} +\\gamma_k -\\delta \\gt 0\\gt \\lambda_{n-k+1}+\\gamma_k -\\delta$   \n",
    "but then we have  \n",
    "\n",
    "$\\mathbf Y_k(\\tau)$   \n",
    "has signature $(n-k,k,0)$  \n",
    "for $\\tau \\in [0,1)$   \n",
    "\n",
    "but $\\mathbf Y_k(\\tau=1)$   \n",
    "has signature $(n-k+1,*,*)$  \n",
    "which is, again, a contradiction, because this implies that a negative eigenvalue became positive without first becoming zero.  \n",
    "\n",
    "thus we have  \n",
    " $\\lambda_{n-k+1} \\leq \\sigma_{r-k+2} $ \n",
    "\n",
    "and by earlier iteration / induction hypothesis we now have the chain  \n",
    "\n",
    "$\\sigma_{r-k+1} \\geq \\lambda_{r-k+1} \\geq \\sigma_{r-k+2} \\geq \\lambda_{r-k+2} \\geq .... \\geq \\lambda_{n-2} \\geq \\sigma_{r-1}\\geq \\lambda_{n-1}\\geq \\sigma_{r} \\geq \\lambda_n$    \n",
    "or  \n",
    "$\\sigma_{n-k} \\geq \\lambda_{r-k+1} \\geq \\sigma_{n-k+1} \\geq \\lambda_{r-k+2} \\geq .... \\geq \\lambda_{n-2} \\geq \\sigma_{n-2}\\geq \\lambda_{n-1}\\geq \\sigma_{r-1} \\geq \\lambda_n$    \n",
    "\n",
    "selecting $k=n-1$ gives almost the entire chain  \n",
    "$\\sigma_1 \\geq \\lambda_2 \\geq \\sigma_2 \\geq .... \\geq\\lambda_{n-2} \\geq \\sigma_{n-2}\\geq \\lambda_{n-1}\\geq \\sigma_{n-1} \\geq \\lambda_n$ \n",
    "\n",
    "and selecting $k=n$ confirms that $\\lambda_1 \\geq \\sigma_1$ giving us the entire chain of inequalities  \n",
    "$\\lambda_1 \\geq \\sigma_1 \\geq \\lambda_2 \\geq \\sigma_2 \\geq .... \\geq\\lambda_{n-2} \\geq \\sigma_{n-2}\\geq \\lambda_{n-1}\\geq \\sigma_{n-1} \\geq \\lambda_n$   \n",
    "as desired \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**residual items clean up and address the non-simple eigenvalue case** \n",
    "\n",
    "for the non-simple case it may be prudent to review what was written to see if it can be directly adapted to cover non-simple eigenvalues (with small modification to the signatures).   \n",
    "\n",
    "alternatively, we can note that any Hermitian matrix with non-simple eigenvalues, where $\\mathbf C = \\mathbf Q\\Lambda \\mathbf Q^*$  \n",
    "$\\mathbf C \\to \\text{simple} = \\mathbf C + \\sum_{i} \\delta_i \\mathbf q_i\\mathbf q_i^* = \\mathbf A$ \n",
    "for index i associated with nonsimple eigenvalues and *very* small $\\delta_i$  (in particular less than say $\\frac{1}{N}$ where natural number $N\\geq n$ the minimum distance between distinct eigenvalues  \n",
    "\n",
    "then for this $\\mathbf A$ we have the interlacing  \n",
    "\n",
    "$\\lambda_1 \\geq \\sigma_1 \\geq \\lambda_2 \\geq \\sigma_2 \\geq .... \\geq\\lambda_{n-2} \\geq \\sigma_{n-2}\\geq \\lambda_{n-1}\\geq \\sigma_{n-1} \\geq \\lambda_n$   \n",
    "\n",
    "or more technically since each value is a function of the $N$ chosen (and a sequence in N, N+1, N+2,... )   \n",
    "$\\lambda_1^{(N)} \\geq \\sigma_1^{(N)} \\geq \\lambda_2^{(N)} \\geq \\sigma_2^{(N)} \\geq .... \\geq\\lambda_{n-2}^{(N)} \\geq \\sigma_{n-2}^{(N)}\\geq \\lambda_{n-1}^{(N)}\\geq \\sigma_{n-1}^{(N)} \\geq \\lambda_n^{(N)}$   \n",
    "\n",
    "but as $N \\to \\infty$ we recover $\\mathbf C$ and the inequalities still hold by basic properties of limits of real sequences and inequalities (of course the nonsimple eigenvalues squeeze certain interlaced values as a result).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note: \"Cauchyâ€™s Interlace Theorem forEigenvalues of Hermitian Matrices\"*  \n",
    "https://pdfs.semanticscholar.org/68b2/f12f71940481380503651adc8306d2d70a7e.pdf\n",
    "\n",
    "mentions that the Cauchy Interlace Theorem has been proven via use of Sylvester's Law of Inertia...  \n",
    "and cites  \n",
    "\n",
    "page 186 of  \n",
    "B. N. Parlett,The Symmetric Eigenvalue Problems, Prentice-Hall, Englewood Cliffs, NJ, 1980\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
