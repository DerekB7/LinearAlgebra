{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This posting is my notes on Kronecker Products.  It is mostly a re-cut of the materials found here: \n",
    "\n",
    "http://www.siam.org/books/textbooks/OT91sample.pdf \n",
    "\n",
    "with some interesting extensions that I added (e.g. the relationship between Kronecker and Hadamard Products.)  \n",
    "\n",
    "In general, the field for this posting is $\\mathbb C$\n",
    "\n",
    "all matrices and vectors in this post are finite dimensional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "defintion of Kronecker product: \n",
    "\n",
    "$\\mathbf B \\otimes  \\mathbf C = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix}$\n",
    "\n",
    "where $\\mathbf B$ is  $m$ x $n$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**claim: The Kronecker Product is Associative **\n",
    "\n",
    "**proof: **\n",
    "\n",
    "where $\\mathbf B$ is  $m$ x $n$ and $\\mathbf C$ is $p$ x $q$\n",
    "\n",
    "let $\\mathbf W: = \\big(\\mathbf C \\otimes  \\mathbf E\\big) = \\begin{bmatrix}\n",
    "c_{1,1}\\mathbf E & \\cdots & c_{1,q}\\mathbf E\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "c_{p,1}\\mathbf E & \\cdots & c_{p,q}\\mathbf E\n",
    "\\end{bmatrix}$   \n",
    "\n",
    "- - - - \n",
    "\n",
    "by inspection, we see: \n",
    "\n",
    "\n",
    "$\\big(\\mathbf B \\otimes  \\mathbf C \\big) \\otimes \\mathbf E = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix} \\otimes \\mathbf E = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf W & \\cdots & b_{1,n}\\mathbf W\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf W & \\cdots & b_{m,n}\\mathbf W\n",
    "\\end{bmatrix} = \\mathbf B \\otimes  \\mathbf W = \\mathbf B \\otimes  \\big(\\mathbf C  \\otimes \\mathbf E\\big)$\n",
    "\n",
    "*commentary: The other (high brow) approach is to recognize the Kronecker product as a special case of the tensor product and then remember the associativity of the tensor product.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*some technical nits:*   \n",
    "    \n",
    "The article points out that, if $\\mathbf x \\in \\mathbb C^m$ and $\\mathbf y \\in \\mathbb C^n$\n",
    "\n",
    "$\\mathbf {xy}^H = \\mathbf x  \\otimes \\mathbf y^H $\n",
    "\n",
    "I.e. that we get and $m$ x $n$, rank one matrix\n",
    "\n",
    "also note\n",
    "\n",
    "$\\mathbf x^H \\otimes \\mathbf y = \\mathbf y  \\mathbf x^H $\n",
    "\n",
    "but \n",
    "\n",
    "$\\mathbf x \\otimes \\mathbf y$\n",
    "\n",
    "is a vector with $mn$ entries.  \n",
    "\n",
    "I think other sources may write \n",
    "\n",
    "$\\mathbf x  \\otimes \\bar{\\mathbf y} $ when they actually mean $\\mathbf x  \\otimes \\mathbf y^H $\n",
    "\n",
    "*conclusion: take extra care when considering Kronecker Products of vectors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "where $\\mathbf B \\in \\mathbb C^{m x n}$ and $\\mathbf X \\in \\mathbb C^{m x n}$, $\\mathbf C \\in \\mathbb C^{r x s}$\n",
    "\n",
    "*Kronecker products distribute across addition*\n",
    "\n",
    "**claim:**  \n",
    "$\\big(\\mathbf B \\otimes \\mathbf C \\big) + \\big(\\mathbf X \\otimes \\mathbf C \\big) = \\big(\\mathbf B  + \\mathbf X \\big) \\otimes \\mathbf C  $\n",
    "\n",
    "**proof**\n",
    "\n",
    "$\\big(\\mathbf B \\otimes \\mathbf C \\big) + \\big(\\mathbf X \\otimes \\mathbf C \\big)$  \n",
    "$ =   \n",
    "\\begin{bmatrix} b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix}  + \\begin{bmatrix}\n",
    "x_{1,1}\\mathbf C & \\cdots & x_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "x_{m,1}\\mathbf C & \\cdots & x_{m,n}\\mathbf C\n",
    "\\end{bmatrix} $  \n",
    "$= \\begin{bmatrix}\n",
    "(b_{1,1} + x_{1,1})\\mathbf C & \\cdots & (b_{1,n} + x_{1,n})\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "(b_{m,1} + x_{m,1})\\mathbf C & \\cdots & (b_{m,n} + x_{m,n} )\\mathbf C\\end{bmatrix} $  \n",
    "$  = \\big(\\mathbf B  + \\mathbf X \\big) \\otimes \\mathbf C $\n",
    "\n",
    "- - - - -\n",
    "\n",
    "**claim:**  \n",
    "$\\big(\\mathbf C \\otimes \\mathbf B \\big) + \\big(\\mathbf C \\otimes \\mathbf X \\big) = \\mathbf C  \\otimes  \\big( \\mathbf B + \\mathbf X \\big)  $\n",
    "\n",
    "\n",
    "**proof**\n",
    "\n",
    "$\\big(\\mathbf C \\otimes \\mathbf B \\big) + \\big(\\mathbf C \\otimes \\mathbf X \\big)$  \n",
    "$ =   \n",
    "\\begin{bmatrix} c_{1,1}\\mathbf B & \\cdots & c_{1,s}\\mathbf B\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "c_{r,1}\\mathbf B & \\cdots & c_{r,s}\\mathbf B\n",
    "\\end{bmatrix}  + \\begin{bmatrix} c_{1,1}\\mathbf X & \\cdots & c_{1,s}\\mathbf X\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "c_{r,1}\\mathbf X & \\cdots & c_{r,s}\\mathbf X\n",
    "\\end{bmatrix}$  \n",
    "$= \\begin{bmatrix} c_{1,1}\\big(\\mathbf B + \\mathbf X\\big) & \\cdots & c_{1,s}\\big(\\mathbf B + \\mathbf X\\big)\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "c_{r,1}\\big(\\mathbf B + \\mathbf X\\big) & \\cdots & c_{r,s}\\big(\\mathbf B + \\mathbf X\\big)\n",
    "\\end{bmatrix} $  \n",
    "$= \\mathbf C  \\otimes  \\big( \\mathbf B + \\mathbf X \\big) $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**key property:** where $\\mathbf B \\in \\mathbb C^{m x n}$, $\\mathbf C \\in \\mathbb C^{r x s}$, $\\mathbf X \\in \\mathbb C^{n x p}$, and $\\mathbf Y \\in \\mathbb C^{s x t}$\n",
    "\n",
    "$\\big(\\mathbf B \\otimes \\mathbf C \\big)\\big(\\mathbf X \\otimes \\mathbf Y\\big) = \\big(\\mathbf{BX} \\big)\\otimes \\big(\\mathbf{CY}\\big)$\n",
    "\n",
    "**proof**\n",
    "We verify this via inspection.  Note this one attribute alone is immensely useful and is key to unlocking most other attributes.\n",
    "\n",
    "\n",
    "$\\mathbf B = \\begin{bmatrix}\n",
    "\\mathbf b_1^{\\sim{T}}\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf b_m^{\\sim{T}}\\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Technical note: $\\mathbf b_k^{\\sim{T}}$ denotes the kth row vector in $\\mathbf B$.  There is no complex conjugation being suggested here.  \n",
    "\n",
    "$\\mathbf X = \n",
    "\\bigg[\\begin{array}{c|c|c|c}\n",
    "\\mathbf x_1 & \\mathbf x_2 &\\cdots & \\mathbf x_{p}\n",
    "\\end{array}\\bigg]\n",
    "$   \n",
    "\n",
    "$\\big(\\mathbf B \\otimes \\mathbf C \\big)\\big(\\mathbf X \\otimes \\mathbf Y\\big)  = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix}  \\begin{bmatrix}\n",
    "x_{1,1}\\mathbf Y & \\cdots & x_{1,p}\\mathbf Y\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "x_{n,1}\\mathbf Y & \\cdots & x_{n,p}\\mathbf Y\n",
    "\\end{bmatrix} $\n",
    "\n",
    "And we then see:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix}  \\begin{bmatrix}\n",
    "x_{1,1}\\mathbf Y & \\cdots & x_{1,p}\\mathbf Y\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "x_{n,1}\\mathbf Y & \\cdots & x_{n,p}\\mathbf Y\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "dot\\big(\\mathbf b_1^{\\sim{T}},\\mathbf x_1\\big) \\mathbf {CY} & \\cdots & dot\\big(\\mathbf b_1^{\\sim{T}},\\mathbf x_p\\big) \\mathbf {CY}\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "dot\\big(\\mathbf b_m^{\\sim{T}},\\mathbf x_1 \\big) \\mathbf {CY} & \\cdots & dot\\big(\\mathbf b_m^{\\sim{T}},\\mathbf x_p\\big) \\mathbf {CY}\n",
    "\\end{bmatrix} = \\big(\\mathbf{BX}\\big) \\otimes \\big(\\mathbf{CY}\\big)$\n",
    "\n",
    "Thus  \n",
    "\n",
    "$\\big(\\mathbf B \\otimes \\mathbf C \\big)\\big(\\mathbf X \\otimes \\mathbf Y\\big)  = \\big(\\mathbf{BX}\\big) \\otimes \\big(\\mathbf{CY}\\big)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\big(\\mathbf B \\otimes  \\mathbf C\\big)^H = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix}^H = \\big(\\mathbf B^H \\otimes  \\mathbf C^H\\big)$\n",
    "\n",
    "verify by inspection\n",
    "\n",
    "follow- up note: with respect to Hermitian operators: \n",
    "\n",
    "this means that if $\\mathbf B = \\mathbf B^H$ and $\\mathbf C = \\mathbf C^H$ then we see\n",
    "\n",
    "$\\big(\\mathbf B \\otimes  \\mathbf C\\big) = \\big(\\mathbf B^H \\otimes  \\mathbf C^H \\big) = \\big(\\mathbf B \\otimes  \\mathbf C\\big)^H$\n",
    "\n",
    "hence the matrix resulting from their Kronecker product is Hermitian as well\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "suppose that $\\mathbf B \\in \\mathbb C^{m x m}$ and $\\mathbf C \\in \\mathbb C^{n x n}$, and that each matrix is non-singular:  \n",
    "\n",
    "then \n",
    "\n",
    "$\\big(\\mathbf B \\otimes  \\mathbf C\\big)\\big(\\mathbf B \\otimes  \\mathbf C\\big)^{-1} = \\big(\\mathbf B \\otimes  \\mathbf C\\big)\\big(\\mathbf B^{-1} \\otimes  \\mathbf C^{-1}\\big)=  \\big(\\mathbf{BB}^{-1} \\otimes   \\mathbf{CC}^{-1}\\big) = \\big(\\mathbf I_m \\otimes \\mathbf I_n\\big) = \\mathbf I_{mn}$\n",
    "\n",
    "thus:\n",
    "\n",
    "$\\big(\\mathbf B \\otimes  \\mathbf C\\big)^{-1} = \\big(\\mathbf B^{-1} \\otimes  \\mathbf C^{-1}\\big)$ \n",
    "\n",
    "\n",
    "**extension:** \n",
    "\n",
    "suppose both $\\mathbf B$ and $\\mathbf C$ are non-singular $m$ x $m$ matrices.  \n",
    "\n",
    "Since the Hadamard product $\\big(\\mathbf B \\circ \\mathbf C\\big)$ is a submatrix of $\\big(\\mathbf B \\otimes  \\mathbf C\\big)^{-1}$, this tells us that $\\big(\\mathbf B \\circ \\mathbf C\\big)^{-1}$ exists if $\\mathbf B$ and $\\mathbf C$ are non-singular.  (It may also exist in other cases as well, e.g. $\\Big(\\mathbf B \\circ \\big(\\mathbf {11}^T\\big)\\Big)$ is invertible if $\\mathbf B$ is, even though $\\big(\\mathbf {11}^T\\big)$ is a rank-one matrixl; this statement is an 'if' but not an 'iff'.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we again suppose that $\\mathbf B \\in \\mathbb C^{m x m}$ and $\\mathbf C \\in \\mathbb C^{n x n}$\n",
    "\n",
    "$\\big(\\mathbf B \\otimes  \\mathbf C\\big) = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,m}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,m}\\mathbf C\n",
    "\\end{bmatrix}$\n",
    "\n",
    "and by inspection we see that \n",
    "\n",
    "$trace\\big(\\mathbf B \\otimes  \\mathbf C\\big) = b_{1,1}(c_{1,1} + c_{2,2} + ... + c_{n,n}) + b_{2,2}(c_{1,1} + c_{2,2} + ... + c_{n,n}) + ... + b_{m,m}(c_{1,1} + c_{2,2} + ... + c_{n,n})$\n",
    "\n",
    "$trace\\big(\\mathbf B \\otimes  \\mathbf C\\big) = b_{1,1}trace\\big(\\mathbf C\\big) + b_{2,2}trace\\big(\\mathbf C\\big) + ... + b_{m,m}trace\\big(\\mathbf C\\big) = \\big(b_{1,1} + b_{2,2} + ... + b_{m,m}\\big)trace\\big(\\mathbf C\\big) = trace\\big(\\mathbf B\\big)trace\\big(\\mathbf C\\big)$\n",
    "\n",
    "\n",
    "we then apply the same argument \n",
    "\n",
    "$trace\\Big(\\big(\\mathbf B \\otimes  \\mathbf C\\big)\\big(\\mathbf B \\otimes  \\mathbf C\\big)\\Big) = trace\\Big(\\big(\\mathbf B^2 \\otimes  \\mathbf C ^2 \\big)\\Big) = trace\\big(\\mathbf B^2\\big) trace\\big(\\mathbf C ^2 \\big)$\n",
    "\n",
    "and more generally for any natural number $k = \\{1, 2, 3,... \\}$, we see that \n",
    "\n",
    "$trace\\Big(\\big(\\mathbf B \\otimes  \\mathbf C\\big)^k \\Big) = trace\\Big(\\big(\\mathbf B^k \\otimes  \\mathbf C^k \\big)\\Big) = trace\\big(\\mathbf B^k\\big) trace\\big(\\mathbf C^k \\big)$\n",
    "\n",
    "The proof at the the end of the Vandermonde matrices posting tells us that if this holds for\n",
    "\n",
    "$k = \\{1,2, 3, ..., max(2m,2n) - 1\\}$\n",
    "\n",
    "where $\\lambda_i$ is the ith eigenvalue of $\\mathbf B$ and $\\mu_i$ is the ith eigenvalue of $\\mathbf C$, then we know for certain that \n",
    "\n",
    "$trace\\Big(\\big(\\mathbf B \\otimes  \\mathbf C\\big)^k \\Big) = trace\\big(\\mathbf B^k\\big) trace\\big(\\mathbf C^k \\big) = \\big(\\lambda_{1}^k + \\lambda_{2}^k + ... + \\lambda_{m}^k\\big)\\big(\\mu_{1}^k + \\mu_{2}^k + ... + \\mu_{n}^k\\big) $\n",
    "\n",
    "$trace\\Big(\\big(\\mathbf B \\otimes  \\mathbf C\\big)^k \\Big) = \\big((\\lambda_{1}\\mu_1)^k + (\\lambda_1 \\mu_2)^k +... (\\lambda_1 \\mu_n)^k + (\\lambda_{2} \\mu_1)^k + (\\lambda_{2} \\mu_2)^k +...+ (\\lambda_{2} \\mu_n)^k + ... + (\\lambda_{m} \\mu_1)^k + (\\lambda_{m} \\mu_2)^k + ... +(\\lambda_{m} \\mu_n)^k\\big)$\n",
    "\n",
    "And again we can recall the same proof at the end of the Vandermonde matrices posting, and recognize that since this relationship holds for all natural numbers $k$, then after observing that it holds for $\\geq 2(mn) -1 $ iterations, we can be certain that the above eigenvalues are uniquely specified.  That is:  \n",
    "\n",
    "$eig\\Big(\\mathbf B \\otimes  \\mathbf C\\Big) = \\{(\\lambda_{1}\\mu_1), (\\lambda_1 \\mu_2), ..., (\\lambda_1 \\mu_n), (\\lambda_{2} \\mu_1),  (\\lambda_{2} \\mu_2), ..., (\\lambda_{2} \\mu_n),  ... , (\\lambda_{m} \\mu_1), (\\lambda_{m} \\mu_2), ...,(\\lambda_{m} \\mu_n)\\}$\n",
    "\n",
    "(where the above set is technically a multi-set)\n",
    "\n",
    "That is, we know $\\Big(\\mathbf B \\otimes  \\mathbf C\\Big)$ has $mn$ eigenvalues, and we could also think of $eig\\Big(\\mathbf B \\otimes  \\mathbf C\\Big)$ as being the cartesian product of the multiset of eigenvalues for $\\mathbf B$ and the multiset of eigenvlaues for $\\mathbf C$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other results follow simply from the multiplication rule.  \n",
    "\n",
    "\n",
    "**claim:  **  \n",
    "If $\\mathbf Q$ and $\\mathbf V$ are both unitary matrices, then the matrix given by\n",
    "\n",
    "$\\big(\\mathbf Q \\otimes \\mathbf V \\big)$\n",
    "\n",
    "is also unitary.\n",
    "\n",
    "**proof:  ** \n",
    "\n",
    "$\\big(\\mathbf Q \\otimes \\mathbf V \\big)^H \\big(\\mathbf Q \\otimes \\mathbf V \\big) = \\big(\\mathbf Q^H \\otimes \\mathbf V^H \\big)\\big(\\mathbf Q \\otimes \\mathbf V \\big)= \\big(\\mathbf Q^H \\mathbf Q \\otimes \\mathbf V^H \\mathbf V \\big) = \\big(\\mathbf I_m \\otimes \\mathbf I_n \\big)= \\mathbf I_{mn}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may do SVD on $\\mathbf B = \\mathbf U_B \\mathbf \\Sigma_B \\mathbf V_B^H$ and $\\mathbf C = \\mathbf U_C \\mathbf \\Sigma_C \\mathbf V_C^H$.  Note: in this setup $\\mathbf U$ and and $\\mathbf V$ are both full rank unitary matrices while the $\\mathbf \\Sigma$ is diagonal, but generally not square.  \n",
    "\n",
    "We then have \n",
    "\n",
    "$\\Big(\\mathbf B \\otimes \\mathbf C\\Big) = \\Big(\\big(\\mathbf U_B \\mathbf \\Sigma_B \\mathbf V_B^H\\big) \\otimes \\big(\\mathbf U_C \\mathbf \\Sigma_C \\mathbf V_C^H\\big)\\Big) = \\Big(\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)\\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\big( \\mathbf V_B^H \\otimes \\mathbf V_C^H\\big)\\Big) $\n",
    "\n",
    "\n",
    "Observe that if $\\mathbf B$ is square, and $\\mathbf C$ is square, then $\\mathbf \\Sigma_B$ is square and so is $\\mathbf \\Sigma_C$.  Thus when we take the kronecker product of two *square diagonal matrices*\n",
    "\n",
    "$\\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)$\n",
    "\n",
    "the result is a square diagonal matrix.  \n",
    "\n",
    "However, in the more general non-square $\\mathbf B$ and $\\mathbf C$ case, our $\\mathbf \\Sigma_B$ and $\\mathbf \\Sigma_C$ are not square, and hence the matrix given by $\\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)$ is \"almost\" diagonal.  I.e. it has at most one non-zero entry in every row and at most one non-zero entry in every column, but these entries are not on the diagonal of the matrix.  Multiplication by suitable permutation matrices can fix this, and give us an actual, non-square matrix.\n",
    "\n",
    "Revisiting our factorization, we can say \n",
    "\n",
    "$\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)^H\\big(\\mathbf B  \\otimes \\mathbf C \\big)\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big) = \\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big) $\n",
    "\n",
    "All we need need now are suitably sized permutation matrices to multiply on the left and right by (recalling that permutation matrices are a very special case of a unitary matrix).  This gives us\n",
    "\n",
    "\n",
    "$\\mathbf P^{(l)}\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)^H\\big(\\mathbf B  \\otimes \\mathbf C \\big)\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big)\\mathbf P^{(r)} = \\mathbf P^{(l)}\\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\mathbf P^{(r)} $\n",
    "\n",
    "And now the right hand side is diagonal.  However to recover the SVD, we do the following: \n",
    "\n",
    "$\\Big(\\mathbf P^{(l)}\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)^H\\Big)^{H}\\Big(\\mathbf P^{(l)}\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)^H\\Big)\\big(\\mathbf B  \\otimes \\mathbf C \\big)\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big)\\mathbf P^{(r)} = \\Big(\\mathbf P^{(l)}\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)^H\\Big)^{H}\\mathbf P^{(l)}\\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\mathbf P^{(r)} $\n",
    "\n",
    "$\\big(\\mathbf B  \\otimes \\mathbf C \\big)\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big)\\mathbf P^{(r)} = \\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)\\big(\\mathbf P^{(l)}\\big)^H\\mathbf P^{(l)}\\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\mathbf P^{(r)} $\n",
    "\n",
    "\n",
    "$\\big(\\mathbf B  \\otimes \\mathbf C \\big) = \\big(\\mathbf B  \\otimes \\mathbf C \\big)\\Big(\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big)\\mathbf P^{(r)}\\Big)\\Big(\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big)\\mathbf P^{(r)}\\Big)^H = \\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)\\big(\\mathbf P^{(l)}\\big)^H\\mathbf P^{(l)} \\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\mathbf P^{(r)}\\Big(\\big( \\mathbf V_B \\otimes \\mathbf V_C\\big)\\mathbf P^{(r)}\\Big)^H  $\n",
    "\n",
    "\n",
    "$\\big(\\mathbf B  \\otimes \\mathbf C \\big)= \\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)\\big(\\mathbf P^{(l)}\\big)^H\\mathbf P^{(l)} \\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\mathbf P^{(r)}\\big(\\mathbf P^{(r)}\\big)^H \\big( \\mathbf V_B^H \\otimes \\mathbf V_C^H\\big)   $\n",
    "\n",
    "From here we make use of associativity and decide on how we want to interpret the result:\n",
    "\n",
    "$\\big(\\mathbf B  \\otimes \\mathbf C \\big)= \\Big(\\big(\\mathbf U_B \\otimes \\mathbf U_C\\big)\\big(\\mathbf P^{(l)}\\big)^H\\Big) \\Big(\\mathbf P^{(l)} \\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\mathbf P^{(r)}\\Big)\\Big(\\big(\\mathbf P^{(r)}\\big)^H \\big( \\mathbf V_B^H \\otimes \\mathbf V_C^H\\big) \\Big) = \\big(\\mathbf U_B \\otimes \\mathbf U_C\\big) \\big(\\mathbf \\Sigma_B  \\otimes \\mathbf \\Sigma_C \\big)\\big( \\mathbf V_B^H \\otimes \\mathbf V_C^H\\big)    $\n",
    "\n",
    "where the middle part of the equality shows the proper form of the Singular Value Decomposition (i.e. where the diagonal matrix is in fact diagonal), but the right hand side of the equality is visually most easy to interpret.  But the point is that they are equivalent.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The writeup cleverly then notes that \n",
    "\n",
    "$rank\\Big( \\big(\\mathbf B  \\otimes \\mathbf C \\big) \\Big) = rank\\big(\\mathbf B \\big) rank\\big(\\mathbf C\\big) = rank\\Big( \\big(\\mathbf C  \\otimes \\mathbf B  \\big) \\Big)$\n",
    "\n",
    "This follows directly from the above walk through of the impact of kronecker products on singular value decomposition.  \n",
    "\n",
    "*Here is an alternative take:  *\n",
    "\n",
    "This looks suspiciously like the formula for trace that was written about earlier.  Indeed we could easily use spectral theory and instead derive this, and the prior SVD component, by what we know of eigenvalues, and a glimpse of this comes from:\n",
    "\n",
    "$rank\\Big( \\big(\\mathbf B  \\otimes \\mathbf C \\big) \\Big) = rank\\Big( \\big(\\mathbf B  \\otimes \\mathbf C \\big)\\Big)\\Big( \\big(\\mathbf B  \\otimes \\mathbf C \\big)^H \\Big) = rank\\Big(\\big(\\mathbf{BB}^H\\big)  \\otimes \\big(\\mathbf{CC}^H \\big)\\Big) = rank \\big(\\mathbf{BB}^H\\big) rank\\big(\\mathbf{CC}^H \\big) = rank \\big(\\mathbf B\\big) rank\\big(\\mathbf C \\big)$\n",
    "\n",
    "note that we justify  \n",
    "$rank\\Big( \\big(\\mathbf{BB}^H\\big)  \\otimes \\big(\\mathbf{CC}^H \\big) \\Big) = rank\\big(\\mathbf{BB}^H\\big) rank\\big(\\mathbf {CC}^H \\big)$\n",
    "\n",
    "by the fact that this matrix is Hermitian and hence diagonalizable.  Thus figuring out the rank reduces to coutning all non-zero eigenvalues of $\\Big(\\big(\\mathbf{BB}^H  \\otimes \\mathbf{CC}^H \\big)\\Big)\n",
    "$.  \n",
    "\n",
    "From here, use indicator variables with value of $0$ if the eigenvalue is $0$, and a value of $1$ otherwise, for the underlying eigenvalues of $\\mathbf{BB}^H$ and $\\mathbf{CC}^H$.  \n",
    "\n",
    "$\\sum \\mathbb I \\Big(eig\\big(\\mathbf {BB}^H\\big)  \\otimes \\big(\\mathbf {CC}^H \\big)\\Big) = \\sum \\sum \\mathbb I\\Big(eig\\big(\\mathbf {BB}^H\\big)\\Big) \\mathbb I \\Big(eig\\big(\\mathbf {CC}^H \\big)\\Big) = rank\\big(\\mathbf{BB}^H\\big) rank\\big(\\mathbf {CC}^H \\big)= rank\\big(\\mathbf{B}\\big) rank\\big(\\mathbf {C} \\big)$\n",
    "\n",
    "but to flush this out in more detail seems a bit tedious.  The singular value decomposition approach, on the other hand, is succinct and to the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for operators $\\mathbf B$ and $\\mathbf C$, using Schur Decomposition, we have\n",
    "\n",
    "$\\mathbf B = \\mathbf{QRQ}^H$   \n",
    "$\\mathbf C = \\mathbf{VTV}^H$\n",
    "\n",
    "$\\big(\\mathbf B  \\otimes \\mathbf C \\big)  = \\big(\\mathbf{QRQ}^H \\otimes \\mathbf{VTV}^H \\big) = \\big(\\mathbf Q \\otimes \\mathbf{V}\\big)\\big(\\mathbf{R} \\otimes \\mathbf{T} \\big)\\big(\\mathbf{Q}^H \\otimes \\mathbf{V}^H \\big) = \\big(\\mathbf Q \\otimes \\mathbf{V}\\big)\\big(\\mathbf{R} \\otimes \\mathbf{T} \\big)\\big(\\mathbf{Q} \\otimes \\mathbf{V} \\big)^H  $\n",
    "\n",
    "where of course $\\big(\\mathbf Q \\otimes \\mathbf{V}\\big)$ is a unitary matrix, and because we have two square, upper triangular matrices in $\\mathbf R$ and $\\mathbf T$, then\n",
    "\n",
    "$\\big(\\mathbf{R} \\otimes \\mathbf{T} \\big)$\n",
    "\n",
    "is upper triangular as well.  For avoidance of doubt, consider the below, matrix,\n",
    "\n",
    "$\\big(\\mathbf R \\otimes  \\mathbf T\\big) = \\begin{bmatrix}\n",
    "r_{1,1}\\mathbf T & \\cdots & r_{1,m}\\mathbf T\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "r_{m,1}\\mathbf T & \\cdots & r_{m,m}\\mathbf T\n",
    "\\end{bmatrix}$\n",
    "\n",
    "by inspection we see that it is block upper triangular, because each $r_{i,j} = 0$ if $i \\gt j$, by definition of $\\mathbf R$ being upper triangular.  From there we consider the diagonal elements given by $r_{i,i}\\mathbf T = \\lambda_i \\mathbf T$, and because $\\mathbf T$ is upper triangular we observe that each and every block has no non-zero entries below the diagonal of $\\big(\\mathbf R \\otimes  \\mathbf T\\big)$, thus we conclude that $\\big(\\mathbf R \\otimes  \\mathbf T\\big)$ is upper triangular.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that if $\\mathbf B$ and $\\mathbf C$ are diagonalizable operators, then we may say:\n",
    "\n",
    "$\\big(\\mathbf B  \\otimes \\mathbf C \\big)  = \\Big(\\big(\\mathbf P \\mathbf \\Lambda \\mathbf P^{-1}\\big) \\otimes \\big( \\mathbf S \\mathbf D \\mathbf S^{-1} \\big)\\Big) = \\big(\\mathbf P \\otimes \\mathbf S\\big)\\big(\\mathbf \\Lambda \\otimes \\mathbf {D} \\big)\\big(\\mathbf{P}^{-1} \\otimes \\mathbf{S}^{-1} \\big) = \\big(\\mathbf P \\otimes \\mathbf S\\big)\\big(\\mathbf \\Lambda \\otimes \\mathbf {D} \\big)\\big(\\mathbf{P} \\otimes \\mathbf{S} \\big)^{-1}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remark on Kronecker Product vs  Hadamard Product\n",
    "\n",
    "\n",
    "an alternative way to view this (that I haven't seen elsewhere) is to view the operation in two steps:\n",
    "\n",
    "First 'blow up' $\\mathbf B$ and $\\mathbf C$ into the appropriate block matrices, then do the Hadamard product between them.  I.e.:\n",
    "\n",
    "where $\\mathbf {11}^H$ i.e. the appropriately sized ones matrix (i.e. in this case it has the same dimensions as $\\mathbf C$ ), and $\\circ$ denotes the Hadamard product\n",
    "\n",
    "$\\mathbf B \\otimes  \\mathbf C = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf {11}^H & \\cdots & b_{1,n}\\mathbf {11}^H\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf {11}^H & \\cdots & b_{m,n}\\mathbf {11}^H\n",
    "\\end{bmatrix} \\circ \\begin{bmatrix}\n",
    "\\mathbf C & \\cdots & \\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\mathbf C & \\cdots & \\mathbf C\n",
    "\\end{bmatrix}= \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf C & \\cdots & b_{1,n}\\mathbf C\\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "b_{m,1}\\mathbf C & \\cdots & b_{m,n}\\mathbf C\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Assuming that $\\big(\\mathbf B \\circ \\mathbf C\\big)$ is well defined, this viewpoint may help us visualize that the elements of $\\big(\\mathbf B \\circ \\mathbf C\\big)$ are contained in $\\big(\\mathbf B \\otimes \\mathbf C\\big)$.\n",
    "- - - - \n",
    "Of particular interest is the case where $\\mathbf B$ is $m$ x $m$ and $\\mathbf C$ is $m$ x $m$ as well.  Taking a closer look at this case, we see:\n",
    "\n",
    "$\\mathbf B \\otimes  \\mathbf C = \\begin{bmatrix}\n",
    "b_{1,1}\\mathbf {11}^H & b_{1,2}\\mathbf {11}^H & \\cdots & b_{1,m-1}\\mathbf {11}^H & b_{1,m}\\mathbf {11}^H\\\\ \n",
    "b_{2,1}\\mathbf {11}^H & b_{2,2}\\mathbf {11}^H & \\cdots & b_{2,m-1}\\mathbf {11}^H & b_{2,m}\\mathbf {11}^H\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "b_{m-1,1}\\mathbf {11}^H & b_{m-1,2}\\mathbf {11}^H & \\cdots & b_{m-1,m-1}\\mathbf {11}^H & b_{m-1,m}\\mathbf {11}^H\\\\ \n",
    "b_{m,1}\\mathbf {11}^H & b_{m,2}\\mathbf {11}^H & \\cdots & b_{m,m-1}\\mathbf {11}^H & b_{m,m}\\mathbf {11}^H\\\\ \n",
    "\\end{bmatrix} \\circ \\begin{bmatrix}\n",
    "\\mathbf C & \\mathbf C & \\cdots & \\mathbf C & \\mathbf C \\\\ \n",
    "\\mathbf C & \\mathbf C & \\cdots & \\mathbf C & \\mathbf C \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf C & \\mathbf C & \\cdots & \\mathbf C & \\mathbf C \\\\ \n",
    "\\mathbf C & \\mathbf C & \\cdots & \\mathbf C & \\mathbf C \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "The above matrix is $m^2$ x $m^2$.  Note that we can 'see' that the Hadamard Product is contained in the above.  Specifically,  \n",
    "\n",
    "$\\big(\\mathbf B \\circ \\mathbf C\\big)_{i,j} = \\mathbf e_i^H \\big(\\mathbf B \\otimes  \\mathbf C \\big)\\mathbf e_j  = \\big(\\mathbf B \\otimes  \\mathbf C \\big)_{i,j} $\n",
    "\n",
    "for $i,j = \\{0(m+1) + 1, 1(m+1)+1,  2(m+1)+1, ..., (m-2)(m+1)+1 , (m-1)(m+1)+1\\}$\n",
    "\n",
    "where $\\mathbf e_k$ is the standard basis vector, shown below.\n",
    "\n",
    "\n",
    "$\\mathbf I_{m^2} = \n",
    "\\bigg[\\begin{array}{c|c|c|c|c}\n",
    "\\mathbf e_1 & \\mathbf e_2 &\\cdots & \\mathbf e_{m^2 - 1} & \\mathbf e_{m^2}\n",
    "\\end{array}\\bigg]\n",
    "$   \n",
    "- - - -  \n",
    "**example: **if $\\mathbf B$ and $\\mathbf C$ were both $3$ x $ 3$ matrices, then we would have \n",
    "for $i,j = \\{1, 5, 9\\}$\n",
    "- - - -  \n",
    "\n",
    "\n",
    "For avodiance of doubt, in the below, $\\mathbf x$ is a vector with $m^2$ entries, whereas $\\mathbf y$ is a vector with $m$ entries.  \n",
    "\n",
    "\n",
    "In the case where $\\mathbf B$ and $\\mathbf C$ is Hermitian, then we know \n",
    "\n",
    "$\\big(\\mathbf B \\otimes  \\mathbf C \\big)$ is Hermitian.  We may also verify by inspection that $\\big(\\mathbf B \\circ \\mathbf C\\big)$ is Hermitian (or by reconizing it is a principal submatrix of the Hermitian matrix $\\big(\\mathbf B \\otimes  \\mathbf C \\big)$  -- either way is ok).   \n",
    "\n",
    "We now use the useful fact that maximizing and minizimizing quadratic forms, subject to a length constraint, gives the maximal and minimal eigenvalues of a Hermitian matrix.  \n",
    "\n",
    "**note: the LaTeX blocks stating the underlying optimization problem do not render properly on Github.  Viewing the notebook locally should fix this problem.** \n",
    "\n",
    "- - - - \n",
    "*The Kronecker Product optimization case (max)*  \n",
    "\n",
    "$\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& {\\text{maximize}}\n",
    "& & \\mathrm{\\mathbf x^H \\big(\\mathbf B \\otimes  \\mathbf C \\big)\\mathbf x  }\\\\\n",
    "& \\text{subject to}\n",
    "& &\\big \\Vert \\mathbf x\\big \\Vert_2^2 = 1 \\\\\n",
    "&{\\text{result}}\n",
    "&& \\mathrm{\\lambda_{max}\\big(\\mathbf B\\big)\\lambda_{max}\\big(\\mathbf C\\big)= \\lambda_{max}\\big(\\mathbf B \\otimes  \\mathbf C \\big) }\n",
    "\\end{aligned}\n",
    "\\end{equation*}$\n",
    "- - - - \n",
    "\n",
    "*and in the minimization case*  \n",
    "\n",
    "$\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& {\\text{minimize}}\n",
    "& & \\mathrm{\\mathbf x^H \\big(\\mathbf B \\otimes  \\mathbf C \\big)\\mathbf x} \\\\\n",
    "& \\text{subject to}\n",
    "& &\\big \\Vert \\mathbf x\\big \\Vert_2^2 = 1 \\\\\n",
    "&{\\text{result}}\n",
    "&& \\mathrm{\\lambda_{min}\\big(\\mathbf B\\big)\\lambda_{min}\\big(\\mathbf C\\big) = \\lambda_{min}\\big(\\mathbf B \\otimes  \\mathbf C \\big)}\n",
    "\\end{aligned}\n",
    "\\end{equation*}$\n",
    "- - - - \n",
    "\n",
    "*The Hadamard Product optimization case (max)*  \n",
    "\n",
    "$\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& {\\text{maximize}}\n",
    "& & \\mathrm{ \\mathbf y^H \\big(\\mathbf B \\circ \\mathbf C\\big) \\mathbf y = \\mathbf x^H \\big(\\mathbf B \\otimes  \\mathbf C \\big)\\mathbf x}\\\\\n",
    "& \\text{subject to}\n",
    "& &\\big \\Vert \\mathbf y\\big \\Vert_2^2 = 1 \\\\\n",
    "&&& \\big \\Vert \\mathbf x\\big \\Vert_2^2 = 1 \\\\\n",
    "&&& \\mathbf x = \\sum_{r=0}^{m-1} \\gamma_r \\mathbf e_{r(m+1)+1}\\\\\n",
    "&{\\text{result}}\n",
    "&& \\mathrm{\\lambda_{max}\\big(\\mathbf B \\circ  \\mathbf C \\big)}\n",
    "\\end{aligned}\n",
    "\\end{equation*}$\n",
    "- - - - \n",
    "\n",
    "Thus we see, \n",
    "\n",
    "$\\lambda_{max}\\big(\\mathbf B\\big)\\lambda_{max}\\big(\\mathbf C\\big) = \\lambda_{max}\\big(\\mathbf B \\otimes  \\mathbf C \\big)  \\geq   \\lambda_{max}\\big(\\mathbf B \\circ \\mathbf C\\big) $\n",
    "\n",
    "because the Kronecker Product maximization case is the same as the Hadamard Product Optimization, except the former has less constraints than the latter, and hence the 'payoff' from the Kronecker Product maximization must be at least as big as that from the Hadamard Product Optimization.  (Put differently, the Optimization from the Hadamard Product quadratic form is always a 'backup plan' for the Kronecker Product quadratic form optimization.)  \n",
    "\n",
    "- - - -  \n",
    "*A similar phenomenon exists in the minimization case:*   \n",
    "\n",
    "$\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& {\\text{minimize}}\n",
    "& & \\mathrm{\\mathbf y^H \\big(\\mathbf B \\circ \\mathbf C\\big) \\mathbf y = \\mathbf x^H \\big(\\mathbf B \\otimes  \\mathbf C \\big)\\mathbf x}\\\\\n",
    "& \\text{subject to}\n",
    "& &\\big \\Vert \\mathbf y\\big \\Vert_2^2 = 1 \\\\\n",
    "&&& \\big \\Vert \\mathbf x\\big \\Vert_2^2 = 1 \\\\\n",
    "&&& \\mathbf x = \\sum_{r=0}^{m-1} \\gamma_r \\mathbf e_{r(m+1)+1}\\\\\n",
    "&{\\text{result}}\n",
    "&& \\mathrm{\\lambda_{min}\\big(\\mathbf B \\circ  \\mathbf C \\big)}\n",
    "\\end{aligned}\n",
    "\\end{equation*}$\n",
    "- - - -  \n",
    "\n",
    "and we conclude that: \n",
    "\n",
    "$\\lambda_{min}\\big(\\mathbf B\\big)\\lambda_{min}\\big(\\mathbf C\\big) = \\lambda_{min}\\big(\\mathbf B \\otimes  \\mathbf C \\big)  \\leq \\lambda_{min}\\big(\\mathbf B \\circ \\mathbf C\\big) $\n",
    "\n",
    "again, because the optimization (i.e. minimization) case for the quadratic form given by the Kronecker Product is the same as that for the Hadamard Product quadratic form, except there are less constraints on the former.  Thus the optimization for the former can always be the the same as the latter, though it could also be \"better\".  (Crucially, the Hadamard casee *cannot* be better than the Kronecker, since the Hadamard quadratic form optimization set of possibilities  is a proper subset of the configurations available to the Kronecker case.)  \n",
    "\n",
    "Note: if we want a more granular conclusion, we may use the fact that the Hadamard product is a principal submatrix of the Hermitian matrix created by the Kronecker product, and then recursively apply Cauchy eigenvalue interlacing. \n",
    "\n",
    "**extension:** \n",
    "\n",
    "If $\\mathbf B$ and $\\mathbf C$ are Hermitian Positive (semi)definite, then so must be $\\big(\\mathbf B \\circ \\mathbf C\\big)$\n",
    "\n",
    "We already know that $\\big(\\mathbf B \\circ \\mathbf C\\big)$ is Hermitian. \n",
    "\n",
    "In the positive definite case, all eigenvalues are real, and we have $0 \\lt \\lambda_{min}\\big(\\mathbf B\\big)$  and $0 \\lt \\lambda_{min}\\big(\\mathbf C\\big)$\n",
    "\n",
    "thus \n",
    "\n",
    "$0 \\lt \\lambda_{min}\\big(\\mathbf B\\big)\\lambda_{min}\\big(\\mathbf C\\big)  \\leq \\lambda_{min}\\big(\\mathbf B \\circ \\mathbf C\\big) $\n",
    "\n",
    "\n",
    "In the positive semi-definite case we have $0 \\leq \\lambda_{min}\\big(\\mathbf B\\big)$ and $0 \\leq \\lambda_{min}\\big(\\mathbf C\\big)$\n",
    "\n",
    "thus \n",
    "\n",
    "$0 \\leq \\lambda_{min}\\big(\\mathbf B\\big)\\lambda_{min}\\big(\\mathbf C\\big)  \\leq \\lambda_{min}\\big(\\mathbf B \\circ \\mathbf C\\big) $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: I suspect I could derive the Cauchy Eigenvalues Interlacing from a forward, then backward pass of optimizations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kronecker sum\n",
    "\n",
    "for two square matrices $\\mathbf B \\in \\mathbb C^{m x m}$ and $\\mathbf C \\in \\mathbb C^{n x n}$, the Kronecker Sum is defined as\n",
    "\n",
    "\n",
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf I_n \\otimes \\mathbf B\\big) + \\big(\\mathbf C \\otimes \\mathbf I_m\\big) $\n",
    "\n",
    "**remarks:**  \n",
    "$\\mathbf B \\oplus \\mathbf C \\neq \\mathbf C \\oplus \\mathbf B$ in general.  \n",
    "\n",
    "Also it seems that some other source may 'flip around the definition to be something like \n",
    "\n",
    "$\\big(\\mathbf B \\otimes \\mathbf I_n\\big) + \\big(\\mathbf I_m \\otimes \\mathbf C\\big)$\n",
    "\n",
    "which confuses things a bit. The takeaway is: be extra careful and check in on notation / defintions.\n",
    "\n",
    "**important special case: suppose ** $\\mathbf B$ **and** $\\mathbf C$ **are both upper triangular**\n",
    "\n",
    "$\\mathbf I \\otimes  \\mathbf B = \\begin{bmatrix}\n",
    "\\mathbf {11}^H & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & \\mathbf {00}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {11}^H & \\cdots & \\mathbf {00}^H & \\mathbf {00}^H\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {11}^H & 0\\mathbf {00}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & \\mathbf {11}^H\\\\ \n",
    "\\end{bmatrix} \\circ \\begin{bmatrix}\n",
    "\\mathbf B & \\mathbf B & \\cdots & \\mathbf B & \\mathbf B \\\\ \n",
    "\\mathbf B & \\mathbf B & \\cdots & \\mathbf B & \\mathbf B \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf B & \\mathbf B & \\cdots & \\mathbf B & \\mathbf B \\\\ \n",
    "\\mathbf B & \\mathbf B & \\cdots & \\mathbf B & \\mathbf B \\\\ \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\mathbf {B} & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & \\mathbf {00}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {B} & \\cdots & \\mathbf {00}^H & \\mathbf {00}^H\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {B} & \\mathbf {00}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & \\mathbf {B}\\\\ \n",
    "\\end{bmatrix} $\n",
    "\n",
    "\n",
    "\n",
    "$\\mathbf C \\otimes  \\mathbf I = \\begin{bmatrix}\n",
    "c_{1,1}\\mathbf {11}^H & c_{1,2}\\mathbf {11}^H & \\cdots & c_{1,n-1}\\mathbf {11}^H & c_{1,n}\\mathbf {11}^H\\\\ \n",
    "\\mathbf {00}^H & c_{2,2}\\mathbf {11}^H & \\cdots & c_{2,n-1}\\mathbf {11}^H & c_{2,n}\\mathbf {11}^H\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & c_{n-1,n-1}\\mathbf {11}^H & c_{n-1,n}\\mathbf {11}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & c_{n,n}\\mathbf {11}^H\\\\ \n",
    "\\end{bmatrix} \\circ \\begin{bmatrix}\n",
    "\\mathbf I & \\mathbf I & \\cdots & \\mathbf I & \\mathbf I \\\\ \n",
    "\\mathbf I & \\mathbf I & \\cdots & \\mathbf I & \\mathbf I \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf I & \\mathbf I & \\cdots & \\mathbf I & \\mathbf I \\\\ \n",
    "\\mathbf I & \\mathbf I & \\cdots & \\mathbf I & \\mathbf I \\\\ \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "c_{1,1}\\mathbf {I} & c_{1,2}\\mathbf {I} & \\cdots & c_{1,n-1}\\mathbf {I} & c_{1,n}\\mathbf {I}\\\\ \n",
    "\\mathbf {00}^H & c_{2,2}\\mathbf {I} & \\cdots & c_{2,n-1}\\mathbf {I} & c_{2,n}\\mathbf {I}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & c_{n-1,n-1}\\mathbf {I} & c_{n-1,n}\\mathbf {I}\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & c_{n,n}\\mathbf {I}\\\\ \n",
    "\\end{bmatrix} $\n",
    "\n",
    "and we verify that both $\\big(\\mathbf I \\otimes  \\mathbf B \\big)$ and  $\\big(\\mathbf C \\otimes  \\mathbf I \\big)$ are upper triangular. \n",
    "\n",
    "Hence we conclude $\\big(\\mathbf B \\oplus \\mathbf C \\big)$ is upper triangular if both $\\mathbf B$ and $\\mathbf C$ are upper triangular, because that the sum of two upper triangular matrices (with legal dimensions) is an upper triangular matrix.  \n",
    "\n",
    "**extension** if $\\mathbf B$ and $\\mathbf C$ are upper triangular, their eigenvalues are on their diagonal.  We examing the diagonal of $\\big(\\mathbf B \\oplus \\mathbf C \\big)$  and see that it has \n",
    "\n",
    "$c_{1,1} + b_{1,1}, c_{1,1} + b_{2,2}, ..., c_{1,1} + b_{m,m}, c_{2,2} + b_{1,1}, c_{2,2} + b_{2,2}, ..., c_{2,2} + b_{m,m}, ..., c_{n,n} + b_{1,1}, c_{n,n} + b_{2,2}, ..., c_{n,n} + b_{m,m}$\n",
    "\n",
    "or equivalently, where $s_i$ is an eigenvalue for $\\mathbf B$ and $\\lambda_i$ is an eigenvalue for $\\mathbf C$\n",
    "\n",
    "$\\lambda_{1} + s_{1}, \\lambda_{1} + s_{2}, ..., \\lambda_{1} + s_{m}, \\lambda_{2} + s_{1}, \\lambda_{2} + s_{2}, ..., \\lambda_{2} + s_{m}, ..., \\lambda_{n} + s_{1}, \\lambda_{n} + s_{2}, ..., \\lambda_{n} + s_m$\n",
    "\n",
    "The $mn$ eigenvalues above, should feel similar to the regular kronecker product setup, except they are being added, not multiplied here.  \n",
    "\n",
    "note if both matrices are the same dimension, $n$ x $n$, we may be able to more easily visualize these eigenvalues by collecting them in two matrices.  The $n$ eigenvalues of $\\mathbf B$ are contained in a vector $\\mathbf {s}$ and the eigenvalues of $\\mathbf C$ are contained in the vector $\\mathbf {\\Lambda 1}$, and $\\mathbf P$ is the full cycle permutation matrix (alternatively the Companion matrix associated with $x^n - 1$), then all $m^2$ eigenvalues are contained in cells of the matrix below.\n",
    "\n",
    "(Thus the eigenvalues are shown somewhat differently, below -- hopefully more clearly.)\n",
    "\n",
    "$\\Big(\\bigg[\\begin{array}{c|c|c|c|c}\n",
    "\\mathbf {s} & \\mathbf {s} & \\mathbf {s} &\\cdots & \\mathbf {s}\n",
    "\\end{array}\\bigg] + \\bigg[\\begin{array}{c|c|c|c|c}\n",
    "\\mathbf P^0 \\mathbf {\\Lambda 1} & \\mathbf P^1\\mathbf {\\Lambda1} & \\mathbf P^2\\mathbf {\\Lambda 1} &\\cdots & \\mathbf P^{n-1}\\mathbf {\\Lambda1}\n",
    "\\end{array}\\bigg]\\Big) $\n",
    "\n",
    "$=  \\begin{bmatrix}\n",
    "s_1 & s_{1} & s_{1} & \\dots & s_1 & s_1 \\\\ \n",
    "s_2 & s_2 & s_{2} & \\dots & s_2 & s_2 \\\\ \n",
    "s_3 & s_3 & s_3 & \\dots & s_3 & s_3 \\\\\n",
    "\\vdots & \\vdots  & \\vdots &\\ddots & \\vdots & \\vdots\\\\ \n",
    "s_{n-1} & s_{n-1} & s_{n-1} & \\dots & s_{n-1}  & s_{n-1} \\\\ \n",
    "s_{n} & s_{n}  & s_{n} & \\dots & s_n &  s_n\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "\\lambda_1 & \\lambda_{n} & \\lambda_{n-1} & \\dots & \\lambda_3 & \\lambda_2 \\\\ \n",
    "\\lambda_2 & \\lambda_1 & \\lambda_{n} & \\dots & \\lambda_4 & \\lambda_3 \\\\ \n",
    "\\lambda_3 & \\lambda_2 & \\lambda_1 & \\dots & \\lambda_5 & \\lambda_4 \\\\\n",
    "\\vdots & \\vdots  & \\vdots &\\ddots & \\vdots & \\vdots\\\\ \n",
    "\\lambda_{n-1} & \\lambda_{n-2} & \\lambda_{n-3} & \\dots & \\lambda_1  & \\lambda_{n} \\\\ \n",
    "\\lambda_{n} & \\lambda_{n-1}  & \\lambda_{n-2} & \\dots & \\lambda_2 &  \\lambda_1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "$= \\begin{bmatrix}\n",
    "s_1 + \\lambda_1 & s_1 + \\lambda_{n} & s_1 + \\lambda_{n-1} & \\dots & s_1 + \\lambda_3 & s_1 + \\lambda_2 \\\\ \n",
    "s_2 + \\lambda_2 & s_2 + \\lambda_1 & s_2 + \\lambda_{n} & \\dots & s_2 + \\lambda_4 & s_2 +\\lambda_3\\\\ \n",
    "s_3 + \\lambda_3 & s_3 + \\lambda_2 & s_3 + \\lambda_1 & \\dots & s_3 + \\lambda_5 & s_3 + \\lambda_4 \\\\\n",
    "\\vdots & \\vdots  & \\vdots &\\ddots & \\vdots & \\vdots\\\\ \n",
    "s_{n-1} + \\lambda_{n-1} & s_{n-1}+ \\lambda_{n-2} & s_{n-1} + \\lambda_{n-3} & \\dots & s_{n-1} +\\lambda_1  & s_{n-1} + \\lambda_{n} \\\\ \n",
    "s_n + \\lambda_{n} & s_{n} + \\lambda_{n-1}  & s_{n} + \\lambda_{n-2} & \\dots & s_{n} + \\lambda_2 &  s_{n} + \\lambda_1\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kronecker Sum - Schur form Implications\n",
    "\n",
    "This one has important and powerful results, but was in fact quite tricky / subtle.  I had to consult the official result and then 'unpack' it into many different lines.  \n",
    "\n",
    "\n",
    "for two square matrices $\\mathbf B \\in \\mathbb C^{m x m}$ and $\\mathbf C \\in \\mathbb C^{n x n}$\n",
    "\n",
    "where $\\mathbf B = \\mathbf{VRV}^H$ and $\\mathbf C = \\mathbf {QTQ}^H$\n",
    "\n",
    "\n",
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf I_n \\otimes \\mathbf B\\big) + \\big(\\mathbf C \\otimes \\mathbf I_m\\big) = \\big(\\mathbf I_n \\otimes \\mathbf{VRV}^H \\big) + \\big(\\mathbf {QTQ}^H \\otimes \\mathbf I_m \\big)    = \\big(\\mathbf I_n\\mathbf I_n\\mathbf I_n \\otimes \\mathbf{VRV}^H \\big) + \\big(\\mathbf {QTQ}^H \\otimes \\mathbf I_m\\mathbf I_m\\mathbf I_m \\big) $\n",
    "\n",
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf I_n \\otimes \\mathbf{V} \\big)\\big(\\mathbf I_n \\otimes \\mathbf{R} \\big)\\big(\\mathbf I_n \\otimes \\mathbf{V}^H \\big) + \\big(\\mathbf {Q} \\otimes \\mathbf I_m \\big)\\big(\\mathbf {T} \\otimes \\mathbf I_m \\big)\\big(\\mathbf {Q}^H \\otimes \\mathbf I_m \\big)$\n",
    "\n",
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf Q \\otimes \\mathbf{V} \\big)\\big(\\mathbf I_n \\otimes \\mathbf{R} \\big)\\big(\\mathbf Q^H \\otimes \\mathbf{V}^H \\big) + \\big(\\mathbf {Q} \\otimes \\mathbf V \\big)\\big(\\mathbf {T} \\otimes \\mathbf I_m \\big)\\big(\\mathbf {Q}^H \\otimes \\mathbf V^H \\big)$\n",
    "\n",
    "\n",
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf Q \\otimes \\mathbf{V} \\big)\\Big(\\big(\\mathbf I_n \\otimes \\mathbf{R} \\big) +  \\big(\\mathbf {T} \\otimes \\mathbf I_m \\big)\\Big)\\big(\\mathbf {Q}^H \\otimes \\mathbf V^H \\big)$\n",
    "\n",
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf Q \\otimes \\mathbf{V} \\big)\\big( \\mathbf{R} \\oplus \\mathbf {T}\\big)\\big(\\mathbf {Q} \\otimes \\mathbf V \\big)^H$\n",
    "\n",
    "\n",
    "where we reference earlier, (just under the line \"Many other results follow simply from the multiplication rule\")  which noted that $\\big(\\mathbf Q \\otimes \\mathbf{V} \\big)$ is a unitary matrix.  \n",
    "\n",
    "Further, per the special case worked through in the above cell, $\\big( \\mathbf{R} \\oplus \\mathbf {T}\\big)$ is itself upper triangular, and there are $mn$ eigenvalues that comes about by adding each eigenvalue from $\\mathbf B$ to each eigenvalue of $\\mathbf C$.  \n",
    "\n",
    "Thus we have the Schur Form of $\\big(\\mathbf B \\oplus \\mathbf C\\big)$ which nicely gives us the eigenvalues associate with such a matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf B \\oplus \\mathbf C = \\big(\\mathbf I_n \\otimes \\mathbf B\\big) + \\big(\\mathbf C \\otimes \\mathbf I_m\\big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sylvester equation\n",
    "\n",
    "where for again $\\mathbf B \\in \\mathbb C^{m x m}$ and $\\mathbf C \\in \\mathbb C^{n x n}$,\n",
    "\n",
    "$\\mathbf B \\mathbf X + \\mathbf X \\mathbf C = \\mathbf Y$\n",
    "\n",
    "can be re-written as\n",
    "\n",
    "$\\mathbf B \\mathbf X + \\mathbf X \\mathbf C  = \\big(\\mathbf B \\oplus \\mathbf C^T\\big)vec\\big(\\mathbf X\\big)  = \\big(\\mathbf I \\otimes \\mathbf B\\big) + \\big(\\mathbf C^T \\otimes \\mathbf I\\big)vec\\big(\\mathbf X\\big) = vec\\big(\\mathbf Y\\big)$\n",
    "\n",
    "note the appearance of $\\mathbf C^T$ **not** $\\mathbf C^H$\n",
    "\n",
    "also recall how the $vec$ operator works, for example on $\\mathbf X$  \n",
    "$\\mathbf X = \\bigg[\\begin{array}{c|c|c|c}\n",
    "\\mathbf x_1 & \\mathbf x_2 &\\cdots & \\mathbf x_n\\end{array}\\bigg]$\n",
    "\n",
    "$vec\\big(\\mathbf X\\big)  = \\begin{bmatrix}\n",
    "\\mathbf x_1 \\\\ \n",
    "\\mathbf x_2\\\\ \n",
    "\\mathbf x_3\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf x_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "i.e. it flattens the matrix $\\mathbf X$ into a vector by stacking the columns of $\\mathbf X$ on top of each other.\n",
    "\n",
    "revisiting our equation, and looking at column $k$ of both sides, we have \n",
    "\n",
    "$\\big(\\mathbf B \\mathbf x_k\\big) + \\big(\\mathbf x_1 c_{1,k} + \\mathbf x_2 c_{2,k} + ... + \\mathbf x_m c_{m,k}  \\big)  = \\mathbf Y_k$\n",
    "\n",
    "thus, accross all columns, we have \n",
    "\n",
    "\n",
    "\n",
    "$  \\begin{bmatrix}\n",
    "\\mathbf B \\mathbf x_1 \\\\ \n",
    "\\mathbf B\\mathbf x_2\\\\ \n",
    "\\mathbf B\\mathbf x_3\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf B \\mathbf x_m\n",
    "\\end{bmatrix}+ \\begin{bmatrix}\n",
    "c_{1,1}\\mathbf {I} & c_{2,1}\\mathbf {I} & \\cdots & c_{n-1,1}\\mathbf {I} & c_{n,1}\\mathbf {I}\\\\ \n",
    "c_{1,2} \\mathbf I & c_{2,2}\\mathbf {I} & \\cdots & c_{n-1,2}\\mathbf {I} & c_{n,2}\\mathbf {I}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "c_{1,n-1} \\mathbf I & c_{2,n-1}\\mathbf {I} & \\cdots & c_{n-1,n-1}\\mathbf {I} & c_{n,n-1}\\mathbf {I}\\\\\n",
    "c_{1,n} \\mathbf I & c_{2,n}\\mathbf {I} & \\cdots & c_{n-1,n}\\mathbf {I} & c_{n,n}\\mathbf {I}\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "\\mathbf x_1 \\\\ \n",
    "\\mathbf x_2\\\\ \n",
    "\\mathbf x_3\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf x_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\mathbf y_1 \\\\ \n",
    "\\mathbf y_2\\\\ \n",
    "\\mathbf y_3\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf y_m\n",
    "\\end{bmatrix} = vec\\big(\\mathbf Y\\big)$\n",
    "\n",
    "or equivalently:  \n",
    "$\\Big(\\begin{bmatrix}\n",
    "\\mathbf {B} & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & \\mathbf {00}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {B} & \\cdots & \\mathbf {00}^H & \\mathbf {00}^H\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {B} & \\mathbf {00}^H\\\\ \n",
    "\\mathbf {00}^H & \\mathbf {00}^H & \\cdots & \\mathbf {00}^H & \\mathbf {B}\\\\ \n",
    "\\end{bmatrix} +  \\begin{bmatrix}\n",
    "c_{1,1}\\mathbf {I} & c_{2,1}\\mathbf {I} & \\cdots & c_{n-1,1}\\mathbf {I} & c_{n,1}\\mathbf {I}\\\\ \n",
    "c_{1,2} \\mathbf I & c_{2,2}\\mathbf {I} & \\cdots & c_{n-1,2}\\mathbf {I} & c_{n,2}\\mathbf {I}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots   \\\\ \n",
    "c_{1,n-1} \\mathbf I & c_{2,n-1}\\mathbf {I} & \\cdots & c_{n-1,n-1}\\mathbf {I} & c_{n,n-1}\\mathbf {I}\\\\\n",
    "c_{1,n} \\mathbf I & c_{2,n}\\mathbf {I} & \\cdots & c_{n-1,n}\\mathbf {I} & c_{n,n}\\mathbf {I}\\\\\n",
    "\\end{bmatrix}\\Big)\\begin{bmatrix}\n",
    "\\mathbf x_1 \\\\ \n",
    "\\mathbf x_2\\\\ \n",
    "\\mathbf x_3\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf x_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\mathbf y_1 \\\\ \n",
    "\\mathbf y_2\\\\ \n",
    "\\mathbf y_3\\\\ \n",
    "\\vdots \\\\ \n",
    "\\mathbf y_m\n",
    "\\end{bmatrix}$\n",
    "\n",
    "or equivalently,\n",
    "\n",
    "$\\Big(\\mathbf B \\oplus \\mathbf C^T\\Big)vec\\Big(\\mathbf X\\Big) = \\Big(\\big(\\mathbf I_n \\otimes \\mathbf B\\big) + \\big(\\mathbf C^T \\otimes \\mathbf I_m\\big)\\Big) vec\\Big(\\mathbf X\\Big)= vec\\Big(\\mathbf Y\\Big)$\n",
    "\n",
    "In order for this equation to be solvable, we know that the square matrix given by \n",
    "\n",
    "$\\Big(\\mathbf B \\oplus \\mathbf C^T\\Big)$\n",
    "\n",
    "cannot have any eigenvalues equal to zero.  This means that $\\mathbf B$ cannot have any eigenvalues equal to those of $-\\mathbf C$ (or equivalently, any eigenvalues equal to those of $-\\mathbf C^T$ as transposition does not change eigenvalues -- no conjugation is involved).  An easy special case worth mentioning, is if both $\\mathbf B$ and $\\mathbf C$ are Hermitian Positive Definite, then both have strictly real valued, positive eigenvalues-- thus neither can have eigenvalues equal to the negative of the other, and hence the equation must be solvable in such a case. (The same conclusion follows if both matrices are Hermitian negative definite.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**extension: ** Problems 4.111 and 4.112 in Zhang's *Linear Algebra: Challenging Problems for Students*  \n",
    "\n",
    "4.111\n",
    "(a) \n",
    "claim: \n",
    "if $\\mathbf A\\mathbf B + \\mathbf B\\mathbf A = \\mathbf {00}^H$, and if $\\mathbf B$ is not nilpotent, then the matrix equation $\\mathbf {AX} + \\mathbf {XA} = \\mathbf B$ has no solution\n",
    "\n",
    "answer: \n",
    "based on the above analysis, we know that this equation is not solvable if some eigenvalue of $\\mathbf A$, $\\lambda_k$ is equal to the negative of some other eigenvalue of $\\mathbf A$ (or $\\mathbf A^T$) -- i.e. $\\lambda_k = -\\lambda_r$.  An important special case, that this problem tries to address, is when $\\lambda_k = 0 = -0$, i.e. when $\\mathbf A$ is singular.  That is, we know that when $\\mathbf A$ is singular, the equation $\\mathbf {AX} + \\mathbf {XA} = \\mathbf B$ has no solution. \n",
    "\n",
    "in the above problem $\\mathbf {AB} = -\\mathbf {BA}$.  If $\\mathbf A$ is non-singular, then we can use it to effect a similarity transformation, i.e.\n",
    "\n",
    "$\\mathbf B = - \\mathbf A^{-1}\\mathbf {BA}$, hence we have \n",
    "\n",
    "$trace\\big(\\mathbf B^k\\big) = - trace\\big(\\mathbf A^{-1}\\mathbf B^k \\mathbf A\\big) = -trace\\big(\\mathbf B^k\\big)$\n",
    "\n",
    "for $k = \\{1, 2, 3,...\\}$ which can only be true if $\\mathbf B$ is nilpotent, and hence all of its traces are zero (see 'Vandermonde_Matrices_Permutations_and_Discrete_Fourier_Transform.ipynb' for multiple proofs of the relation of zero trace and nilpotence -- when the underlying scalar field is not finite, as is the case in $\\mathbb R$ and $\\mathbb C$, of course.)  \n",
    "\n",
    "Hence in this case, if $\\mathbf B$ is not nilpotent, then $\\mathbf A$ must be singular, and the equation cannot be solved.  \n",
    "\n",
    "(b) \n",
    "(i) if $\\mathbf A$ is Hermitian positive definite, then $\\mathbf {AX} + \\mathbf {XA} = \\mathbf B$ can be solved.  (This was addressed at the end of the above cell.) \n",
    "\n",
    "(ii )Moreover if $\\mathbf B$ is (Hermitian) positive semi-definite, then so is $\\mathbf X$ \n",
    "\n",
    "if $\\mathbf B$ is positive semi-definite, then this means\n",
    "\n",
    "$\\mathbf y^H \\mathbf {AX}\\mathbf y + \\mathbf y^H \\mathbf {XA}\\mathbf y = \\mathbf y^H \\mathbf B \\mathbf y \\geq 0$ \n",
    "\n",
    "for any $\\mathbf y$\n",
    "\n",
    "now, we recognize that if $\\mathbf A$ is Hermitian positive definite, then its eigenvectors form a partition, and we use associativity.\n",
    "\n",
    "$\\big(\\mathbf y^H \\mathbf A\\big)\\mathbf X\\mathbf y + \\mathbf y^H \\mathbf X \\big(\\mathbf A \\mathbf y\\big) = \\Big(\\sum_{k=1}^{m} \\big(\\alpha_k \\lambda_k \\mathbf y^H \\big)\\mathbf X\\mathbf y + \\mathbf y^H \\mathbf X \\big(\\alpha_k \\lambda_k  \\mathbf y\\big) \\Big)  = \\mathbf y^H \\mathbf B \\mathbf y \\geq 0$\n",
    "\n",
    "where each $\\alpha_k \\geq 0$ and of course each eigenvalue $\\lambda_k \\geq 0$\n",
    "\n",
    "we can collect all of these real valued non-negative scalars and call that sum $\\gamma$, where $\\gamma \\geq 0$\n",
    "\n",
    "$\\gamma \\mathbf y^H \\mathbf X\\mathbf y = \\mathbf y^H \\mathbf B \\mathbf y \\geq 0$\n",
    "\n",
    "which is zero if $\\gamma = 0$, otherwise we divide it out and see the familiar inequality for positive semidefinitiness\n",
    "\n",
    "$\\mathbf y^H \\mathbf X\\mathbf y\\geq 0$\n",
    "\n",
    "for any $\\mathbf y$, which means that $\\mathbf X$ is positive semi definite.\n",
    "\n",
    "\n",
    "*4.112*\n",
    "\n",
    "The matrix equation $\\mathbf{BX} + \\mathbf{XC} = \\mathbf Y$ has a unique solution **iff**\n",
    "\n",
    "there is some $\\mathbf S$ where\n",
    "\n",
    "\n",
    "$\\mathbf S\\begin{bmatrix}\n",
    "\\mathbf B & \\mathbf Y\\\\ \n",
    " \\mathbf {00}^H& -\\mathbf C\n",
    "\\end{bmatrix} \\mathbf S^{-1} = \\begin{bmatrix}\n",
    "\\mathbf B & \\mathbf {00}^H \\\\ \n",
    " \\mathbf {00}^H& -\\mathbf C\n",
    "\\end{bmatrix}$\n",
    "\n",
    "The answer is actually given as remark 13.20 in the sample chapter 13 on Kronecker products (i.e. what this posting is based off on). \n",
    "\n",
    "$\\mathbf S = \\mathbf S^{-1} = \\begin{bmatrix}\n",
    "\\mathbf I & \\mathbf X\\\\ \n",
    " \\mathbf {00}^H& -\\mathbf I\n",
    "\\end{bmatrix} $\n",
    "\n",
    "hence \n",
    "\n",
    "$\\mathbf S\\begin{bmatrix}\n",
    "\\mathbf B & \\mathbf Y\\\\ \n",
    " \\mathbf {00}^H& -\\mathbf C\n",
    "\\end{bmatrix} \\mathbf S^{-1} = \n",
    "\\begin{bmatrix}\n",
    "\\mathbf B & \\mathbf {BX} + \\mathbf{XC} -\\mathbf Y \\\\ \n",
    " \\mathbf {00}^H& -\\mathbf C\n",
    "\\end{bmatrix}= \\begin{bmatrix}\n",
    "\\mathbf B & \\mathbf {00}^H \\\\ \n",
    " \\mathbf {00}^H& -\\mathbf C\n",
    "\\end{bmatrix}$\n",
    "\n",
    "which of course, in the upper right corner we see our equation agin:\n",
    "\n",
    "$\\mathbf {BX} + \\mathbf{XC} -\\mathbf Y = \\mathbf{00}^H$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$\\mathbf {BX} + \\mathbf{XC} = \\mathbf Y$\n",
    "\n",
    "This blocked triangular formulation would seem to indicate that there is some tie-in or useful analogy with repeated eigenvalues in an upper triangular matrix -- i.e. that such a matrix is defective and requires jordan blocks with super diagonal elements -- i.e. that that the desired similarity transform does not exist.  This analogy is perhaps worth thinking on some more.  However it is worth noting that since we've solved using the more general Kronecker Sum structure, we don't need said analogy for solving Sylvester or Lyapunov equations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pending items: \n",
    "\n",
    "**some of the exercises in the back of the chapter**   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
