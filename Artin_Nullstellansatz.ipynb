{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a different proof (adapted from Arrondo) of the Nullstellansatz using some basic ideas covered in chapter 11 and Artin_chp11.ipynb (the latter has a nice overview of Resultants).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'The art of doing mathematics consists in finding that special case which contains all the germs of generality'*  \n",
    "-David Hilbert  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The Weak Nullstellansatz states that for algebraically closed $\\mathbb F$, if an ideal $I$ in $\\mathbb F\\big[\\mathbf x\\big]$ is proper, then there is a common root for all elements of $I$.  Equivalently, there is a substitution homomorphism $\\Phi$ that sends $x_i\\mapsto c_i\\in \\mathbb F$ such that $\\Phi\\big(I\\big)=\\{0\\}$.  (It is obvious that $I$ cannot be the unit ideal because $\\Phi\\big(1\\big)=1$, hence if $I$ were the unit ideal, $\\Phi\\big(I\\big)\\neq\\{0\\}$, but the Weak Nullstellansatz tells us this is the only obstacle, i.e. any proper ideal must be in the kernel of some substitution homomorphism $\\Phi$.)  \n",
    "\n",
    "The idea behind this is \n",
    "\n",
    "**1.)** prove the Weak Nullstellansatz which is a special case of the Strong Nullstellansatz but the Weak Nullstellansatz implies this 'more general' case via some basic ideas about radical ideals and the Rabinowitsch trick (essentially by padding with an extra 'free variable').  The mechanics of the Rabinowitsch trick are not complicated, though the proof relies on some ideas with radical ideals and ultimately is outside the scope of this writeup.  \n",
    "\n",
    "**2.)** The Weak Nullstellansatz is given for $\\mathbb F\\big[x_1, x_2,..., x_{n-1},x_n\\big]$ for some algebraic closed field $\\mathbb F$.  As noted in 'Artin_chp11.ipynb', a corollary of *ex 11.1.9* is that an algebraically closed field cannot have finite cardinality -- that is $\\mathbb F$ must be an (at least countably) infinite field. \n",
    "  \n",
    "**3.)** The $n=1$ case is immediate since we know $\\mathbb F\\big[x_1\\big]$ is a Principal Ideal Domain (recall e.g. prop 2.20 and corollary 2.21 on page 398 of Artin).  Since $\\mathbb F$ is algebraically closed, all non-constant polynomials split into linear factors, so for any proper ideal $I$ is principal and has a common root; there is some $\\lambda \\in \\mathbb F$ such that the entire ideal evaluates to zero under the substitution homomorphism. For avoidance of doubt since $\\mathbb F$ is a field, any non-zero element in $\\mathbb F$ is a unit, so any ideal not involving $x_1$ is the unit ideal. (Technical nit: the desired result trivially holds in the case of the zero ideal as it is in the kernel of any homomorphism).  \n",
    "\n",
    "**4.)** This sets up an induction on $n$.   and at the inductive step we have a substitution homomorphism.  We toggle the isomorphism  $\\mathbb F\\big[x_1, x_2,..., x_{n-1},x_n\\big]\\cong  R\\big[x_n\\big]$   \n",
    "where $R:=\\mathbb F\\big[x_1, x_2,..., x_{n-1}\\big]$.  \n",
    "We now consider some proper ideal  $I\\in  R\\big[x_n\\big]$, which we know little about. However, by inductive hypothesis we do know that for *any* proper ideal $I' \\in R$ there is a set of values $\\big[c_1, c_2,...,c_{n-1}\\big] \\in \\mathbb F^{n-1}$ where we may use a substitution homomorphism so $\\phi\\big(I'\\big) = \\{0\\}$ (i.e. $I'$ is in the kernel of this homomorphism).  Note that the subset of $I$ where $x_n$ has degree zero / isn't involved / is quotiented out may be called $I'$ which is not an ideal in $R\\big[x_n\\big]$, it *is* a proper ideal in $R$ (in particular it doesn't contain 1 so it is proper).  We may consider $I' := R \\cap I$.  \n",
    "\n",
    "We then use $\\phi$ to build $\\Phi$   \n",
    "$\\Phi :  R\\big[x_n\\big] \\longrightarrow \\mathbb F\\big[x_n\\big]$  given by  \n",
    "$\\alpha \\in \\mathbb F \\mapsto \\alpha \\in \\mathbb F$  \n",
    "$x_i \\mapsto c_i$ for $i\\in\\{1,2...,n-1\\}$  \n",
    "$x_n \\mapsto x_n$  \n",
    "\n",
    "**5.)** If we consider elements in $R\\big[x_n\\big]$ of the form $\\alpha x_n^k$  for $\\alpha \\in \\mathbb F$ it is immediate that this ring homomorphism is  surjective.  Since image of a surjective homomorphism of an ideal is an ideal we have  $\\Phi\\big(I\\big)$ is an ideal in $\\mathbb F\\big[x_n\\big]$.  So if $\\Phi\\big(I\\big)$ is a *proper* ideal, then we reuse our base case and we are done.  \n",
    "\n",
    "**6.)** To show this we are argue by contradiction.  Suppose $\\Phi\\big(I\\big)$ isn't a proper ideal -- i.e. suppose it is the unit ideal, so there is some $g\\in I$ where $\\Phi\\big(g\\big) = 1$.  We want to compare this against some other 'nice' polynomial $f\\in I$. In particular we may assume WLOG that $f$ is monic in $x_n$  (justified later via normalization).     \n",
    "\n",
    "**7.)** A classical way of comparing two polynomials is via placing their coefficients in $R$ in a Sylvester Matrix. The determinant of the Sylvester Matrix is called the Resultant $=\\text{Res}\\big(f,g,x_n\\big) $ (ref notes in 'Artin_chp11.ipynb').  A determinant is a polynomial in the entries in the Sylvester Matrix so it is immediate that $=\\text{Res}\\big(f,g,x_n\\big)\\in R $.  With some work (shown in 'Artin_chp11.ipynb') we have  \n",
    "$\\text{Res}\\big(f,g,x_n\\big)\\in I \\implies \\text{Res}\\big(f,g,x_n\\big)\\in \\big(I\\cap R\\big) \\implies \\text{Res}\\big(f,g,x_n\\big)\\in I'$  \n",
    "\n",
    "**8.)** \n",
    "where $\\alpha_i, \\beta_j \\in R$ i.e. for polynomials in $R[x_n]$ we have   \n",
    "$f= \\alpha_rx_n^r +\\alpha_{r-1}x_n^{n-1}+...+\\alpha_1 x_n + \\alpha_0$  \n",
    "$g = \\beta_mx_n^m +\\beta_{m-1}x_n^{m-1}+...+\\beta_1 x_n + \\beta_0$    \n",
    "\n",
    "and for concreteness suppose $f$ has degree $r=5$ and $g$ has degree $m=3$.  \n",
    "$S_{yl} =\\left[\\begin{matrix}\\alpha_3& 0 & 0 & 0 & 0 & \\beta_5 & 0 & 0\n",
    "                        \\\\\\alpha_2 & \\alpha_3 & 0 & 0 & 0 & \\beta_4 & \\beta_5 & 0\n",
    "                         \\\\\\alpha_1 & \\alpha_2 & \\alpha_3 & 0 & 0 & \\beta_3 & \\beta_4 & \\beta_5\n",
    "                         \\\\\\alpha_0 & \\alpha_1 & \\alpha_2 & \\alpha_3 & 0 & \\beta_2 & \\beta_3 & \\beta_4\n",
    "                         \\\\0 & \\alpha_0 & \\alpha_1 & \\alpha_2 & \\alpha_3 & \\beta_1 & \\beta_2 & \\beta_3\n",
    "                         \\\\0 & 0 & \\alpha_0 & \\alpha_1 & \\alpha_2 & \\beta_0 & \\beta_1 & \\beta_2\n",
    "                         \\\\0 & 0 & 0 & \\alpha_0 & \\alpha_1 & 0 & \\beta_0 & \\beta_1\n",
    "                         \\\\0 & 0 & 0 & 0 & \\alpha_0 & 0 & 0 & \\beta_0\\end{matrix}\\right]$  \n",
    "                         \n",
    "with $J$ the 'reflection matrix' that is all zeros, except all ones on the anti-diagonal (which implies it is involutive)                            \n",
    " $\\Phi\\big(S_{yl}\\big) = \\Phi\\big(J^{-1}S_{yl}^TJ\\big) = \\Phi\\left(\\left[\\begin{matrix}\\beta_{0} & \\beta_{1} & \\beta_{2} & \\beta_{3} & \\beta_{4} & \\beta_{5} & 0 & 0\\\\0 & \\beta_{0} & \\beta_{1} & \\beta_{2} & \\beta_{3} & \\beta_{4} & \\beta_{5} & 0\\\\0 & 0 & \\beta_{0} & \\beta_{1} & \\beta_{2} & \\beta_{3} & \\beta_{4} & \\beta_{5}\\\\\\alpha_{0} & \\alpha_{1} & \\alpha_{2} & \\alpha_{3} & 0 & 0 & 0 & 0\\\\0 & \\alpha_{0} & \\alpha_{1} & \\alpha_{2} & \\alpha_{3} & 0 & 0 & 0\\\\0 & 0 & \\alpha_{0} & \\alpha_{1} & \\alpha_{2} & \\alpha_{3} & 0 & 0\\\\0 & 0 & 0 & \\alpha_{0} & \\alpha_{1} & \\alpha_{2} & \\alpha_{3} & 0\\\\0 & 0 & 0 & 0 & \\alpha_{0} & \\alpha_{1} & \\alpha_{2} & \\alpha_{3}\\end{matrix}\\right]\\right)$                 \n",
    "\n",
    "\n",
    "\n",
    "*i.)* for any d x d matrix $Z$ with components coming from our ring $R$ (or even $R[x_n]$ more generally), our homorphism $\\Phi$ should be understood to be applied component-wise. And since  \n",
    "$\\det\\Big(Z\\Big) =\\sum_{\\sigma \\in \\text{Perm(d)}}z_{\\sigma(1),1}z_{\\sigma(2),2}....z_{\\sigma(d),d}\\cdot \\text{sign}(\\sigma)$  \n",
    "we have  \n",
    "$\\det\\Big(\\Phi\\big(Z\\big)\\Big)$  \n",
    "$=\\sum_{\\sigma \\in \\text{Perm(d)}}\\Phi\\big(z_{\\sigma(1),1}\\big)\\Phi\\big(z_{\\sigma(2),2}\\big)...\\Phi\\big(z_{\\sigma(d),d}\\big)\\cdot \\Phi\\big(\\text{sign}(\\sigma)\\big)$  \n",
    "$= \\sum_{\\sigma \\in \\text{Perm(d)}}\\Phi\\big(z_{\\sigma(1),1}z_{\\sigma(2),2}...z_{\\sigma(d),d}\\cdot \\text{sign}(\\sigma)\\big)$   \n",
    "$= \\Phi\\big(\\sum_{\\sigma \\in \\text{Perm(d)}}z_{\\sigma(1),1}z_{\\sigma(2),2}...z_{\\sigma(d),d}\\cdot \\text{sign}(\\sigma)\\big)$  \n",
    "$=\\Phi\\Big(\\det\\big(Z\\big)\\Big)$   \n",
    "which allows us to compute the determinant (resultant) of $\\Phi\\big(Z\\big)$  two different ways    \n",
    "\n",
    "*ii.)* $f$ is monic $\\implies $  $f= x_n^r +\\alpha_{r-1}x_r^{n-1}+...+\\alpha_1 x_n + \\alpha_0$   i.e. $a_n =1$ or in our example $a_3 =1 $ and of course $\\Phi\\big(a_n\\big)=\\Phi\\big(1\\big)  =1$  \n",
    "\n",
    "*iii.)* $\\Phi\\big(g\\big) =1 $     \n",
    "$\\implies 1 $  \n",
    "$= \\Phi\\big(\\beta_m\\big)\\Phi\\big(x_n\\Big)^m +\\Phi\\big(\\beta_{m-1}\\big)\\Phi\\big(x_n\\big)^{m-1}+...+\\Phi\\big(\\beta_1\\big) \\Phi\\big(x_n\\big) + \\Phi\\big(\\beta_0\\big) $    \n",
    "$= \\Phi\\big(\\beta_m\\big)x_n^m +\\Phi\\big(\\beta_{m-1}\\big)x_n^{m-1}+...+\\Phi\\big(\\beta_1\\big)x_n + \\Phi\\big(\\beta_0\\big) $    \n",
    "$=0+ 0 +...+0+ \\Phi\\big(\\beta_0\\big) $    \n",
    "$= \\Phi\\big(\\beta_0\\big) $    \n",
    "\n",
    "by linear independence of different powers of $x_n^k$ we see that all coefficients of $g$ under the image of $\\Phi$ are zero except the lowest degree coefficient.  \n",
    "\n",
    "- - - -  \n",
    "**For avoidance of doubt**    \n",
    "we could re-arrange the terms in the above to read, for some $\\gamma \\in \\mathbb F$    \n",
    "$\\gamma= 1-\\Phi\\big(\\beta_0\\big) = \\Phi\\big(\\beta_m\\big)x_n^m +\\Phi\\big(\\beta_{m-1}\\big)x_n^{m-1}+...+\\Phi\\big(\\beta_1\\big)x_n = x_n\\cdot\\Big(\\Phi\\big(\\beta_m\\big)x_n^{m-1} +\\Phi\\big(\\beta_{m-1}\\big)x_n^{m-2}+...+\\Phi\\big(\\beta_1\\big)\\Big)$   \n",
    "\n",
    "Recalling that we are in an integral domain  \n",
    "$\\gamma =0 \\implies 0 = x_n\\cdot \\Big(0\\Big)\\implies \\Big(\\Phi\\big(\\beta_m\\big)x_n^{m-1} +\\Phi\\big(\\beta_{m-1}\\big)x_n^{m-2}+...+\\Phi\\big(\\beta_1\\big)\\Big) = 0 $  on the other hand   \n",
    "$\\gamma \\neq 0 \\implies $ $x_n\\cdot\\Big(\\Phi\\big(\\beta_m\\big)x_n^{m-1} +\\Phi\\big(\\beta_{m-1}\\big)x_n^{m-2}+...+\\Phi\\big(\\beta_1\\big)\\Big)$  is invertible, but $x_n$ isn't a unit so this is impossible.  Thus we have  \n",
    "\n",
    "$\\Phi\\big(\\beta_m\\big)x_n^{m-1} +\\Phi\\big(\\beta_{m-1}\\big)x_n^{m-2}+...+\\Phi\\big(\\beta_1\\big) = 0$  \n",
    "and the linear independence of $\\{x_n^{m-1}, x_n^{m-2},..., x_n, 1\\}$ implies every coefficient $\\Phi\\big(\\beta_k\\big)=0$ for $k\\in\\{1,2,...,m\\}$  \n",
    "- - - -  \n",
    "\n",
    "Thus setting $Z:= J^{-1}S_{yl}^TJ $ and (a) recalling that $\\det\\big(Z \\big) \\in I'$ which is annihilated by $\\Phi$ and (b) observing that $\\Phi\\big(A\\big)$ is lower triangular with ones on the diagonal, we have  \n",
    "\n",
    "$0 = \\Phi\\Big(\\det\\big(Z\\big)\\Big)=\\det\\Big(\\Phi\\big(Z\\big)\\Big) =1 $   \n",
    "which is the contradiction we sought.  \n",
    "\n",
    "*remark:* \n",
    "another way to think about the proof is we have an easy base case and then induct on the number of variables $x_i$.  The inductive hypothesis gives us a candidate homomorphism $\\phi$ for any proper ideal in $R$ which we can 'enlarge' $\\Phi$ to accommodate $R\\big[x_n\\big]$.  What the resultant does, though, is it allows us to take a determinant solely involving elements in $R$ -- which we know a lot of about due to our inductive hypothesis.  Put differently -- the resultant allows us to focus tease out results about the $n$ case by reducing to the $n-1$ case.         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below 4 exercises are from **Algebraic Geometry: A Problem Solving Approach** by Garrity et al.  For my purposes I assume any 'scalar' coefficients come from a non-zero ring that is commutative with unity and is an integral domain. These exercises ultimately justify step (6) where we assume WLOG the existence of a polynomial in our our ideal $I$ that is monic in $x_n$.  *ex 4.5.5* and *ex 4.5.6* are examples, not the general lemma and *may be skipped*.   \n",
    "\n",
    "**ex 4.5.5**  \n",
    "$g(x_1,x_2, x_3, x_4) := x_1 x_2+x_3x_4$.  Prove that there exists $\\lambda_1,\\lambda_2,\\lambda_3$ such that the coefficient of $x_4^2$ in $g(x_1 + \\lambda_1 x_4 ,x_2+\\lambda_2 x_4, x_3+\\lambda_3 x_4, x_4)$ is nonzero.   \n",
    "\n",
    "*proof:*  \n",
    "$g(x_1 + \\lambda_1 x_4 ,x_2+\\lambda_2 x_4, x_3+\\lambda_3 x_4, x_4) $   \n",
    "$= (x_1 + \\lambda_1 x_4)(x_2+\\lambda_2 x_4) + (x_3+\\lambda_3 x_4)x_4 $    \n",
    "$= (x_1x_2+ +x_3 x_4) + (\\lambda_2  x_1 x_4 + \\lambda_1 x_4 x_2)  +(\\lambda_1\\lambda_2  + \\lambda_3) x_4^2 $   \n",
    "$=g(x_1,x_2, x_3, x_4) + (\\lambda_2  x_1 x_4 + \\lambda_1 x_4 x_2)  +(\\lambda_1\\lambda_2  + \\lambda_3) x_4^2 $   \n",
    "solution, select $\\lambda_3:=1 \\neq \\lambda_2:= 0$  \n",
    "*is there any importance as to what we select for lambda_1?*  \n",
    "\n",
    "**ex 4.5.6**  \n",
    "let $I\\subset k[x_1,..,x_4]$ be an ideal containing the polynomial $ g(x_1,x_2, x_3, x_4)= x_1 x_2+x_3x_4$.  Prove there is a change of coordinates so that $I$ contains a polynomial monic in the variable $x_4$.  \n",
    "\n",
    "$A:=\\left[\\begin{matrix}1 & 0 & 0&0\\\\\n",
    "                            0 & 1 & 0&0\\\\\n",
    "                            0 & 0 & 1&0\\\\\n",
    "                            0 & 0 & 1&1\\\\\n",
    "                        \\end{matrix}\\right] $   \n",
    "\n",
    "$ \\bigg[\\begin{array}{c|c|c|c|c} x_1 & x_2&x_3 & x_4\\end{array}\\bigg] = \\bigg[\\begin{array}{c|c|c|c|c} x_1^* & x_2^* & x_3^* & x_4^*\\end{array}\\bigg]A$    \n",
    "\n",
    "\n",
    "This is an invertible mapping from one space to the other  \n",
    "we may also interpret this as an invertible homomorpism (i.e. an isomorphism) from $R[\\mathbf x]\\longrightarrow R[\\mathbf x^*]$  given by  \n",
    "$\\phi(r)\\mapsto r$ for $r\\in R$  \n",
    "$\\phi(x_1)\\mapsto x_1^*$  \n",
    "$\\phi(x_2)\\mapsto x_2^*$  \n",
    "$\\phi(x_3)\\mapsto x_3^*+x_4^*$  \n",
    "$\\phi(x_4)\\mapsto x_4^*$  \n",
    "\n",
    "thus  $\\phi\\big(I\\big) = I^* \\in R[\\mathbf x^*]$  \n",
    "and $I^*$ has a polynomial that is monic in $x_4^*$  \n",
    "\n",
    "\n",
    "**ex 4.5.7**  \n",
    "Let $\\mathbb K$ be an infinite field and $g$ be a nonconstant polynomial in $\\mathbb K[x_1,..,x_{n-1},x_n]$ for $n\\geq 2$.  Prove that there exists $\\lambda_1,..., \\lambda_{n-1}$ in $\\mathbb K$ such that the coefficient in $x_n^d$ in $g(x_1 + \\lambda_1 x_n , ... , x_{n-1}+\\lambda_{n-1} x_n, x_n)$ is non-zero, where $d$ is the total degree of $g(x_1 + \\lambda_1 x_n , ... , x_{n-1}+\\lambda_{n-1} x_n, x_n)$.   \n",
    "\n",
    "*proof:*   \n",
    "$A:=\\left[\\begin{matrix}1 & \\cdots & 0&0\\\\\n",
    "                            \\lambda_1 & \\ddots&0 &0\\\\\n",
    "                            \\vdots &\\vdots &\\vdots &\\vdots \\\\\n",
    "                            0 & \\cdots  & 1&0\\\\\n",
    "                            0 & \\cdots  & \\lambda_{n-1}&1\\\\\n",
    "                        \\end{matrix}\\right]$  \n",
    "\n",
    "$ \\bigg[\\begin{array}{c|c|c|c|c} x_1 & \\cdots &x_{n-1} & x_n\\end{array}\\bigg] = \\bigg[\\begin{array}{c|c|c|c|c} x_1^* & \\cdots & x_{n-1}^* & x_n^*\\end{array}\\bigg]A $    \n",
    "notice that the change of coordinate preserves that degree $d$ of the polynomial so $g$ necessarily has degree $d$ and we may bipartition its monomials into those, $q$, of degree $d$ and those $p$ of degree $\\lt m$  \n",
    "\n",
    "$g(x_1, ... , x_{n-1}, x_n) = \\Big(\\sum_{k} q_k(x_1, ... , x_{n-1}, x_n)\\Big) + \\Big(\\sum_{k} p_k(x_1, ... , x_{n-1}, x_n)\\Big)$  \n",
    "\n",
    "$\\implies g(x_1 + \\lambda_1 x_n , ... , x_{n-1}+\\lambda_{n-1} x_n, x_n)$  \n",
    "$= \\Big(\\sum_{k} q_k(x_1 + \\lambda_1 x_n , ... , x_{n-1}+\\lambda_{n-1} x_n, x_n)\\Big) + \\Big(\\sum_{k} p_k(x_1 + \\lambda_1 x_n , ... , x_{n-1}+\\lambda_{n-1} x_n, x_n)\\Big)$  \n",
    "where the first summation has degree $d$ and results in a polynomial in $x_n^d$ (with coefficients in $\\mathbb K$, including the $\\lambda_i$) + terms involving lower terms of $x_n$.  The expansion here is obvious, though may be formalized by inducting on $n$.  \n",
    "\n",
    "*for avoidance of doubt*  \n",
    "when we look at the monomials in the change of coordinate / homomorphism space, and in particular the maximal degree ones, i.e. those in  \n",
    "$\\Big(\\sum_{k} q_k(x_1 + \\lambda_1 x_n , ... , x_{n-1}+\\lambda_{n-1} x_n, x_n)\\Big)$  \n",
    "if we see a monomial of the form $\\alpha\\lambda_1^{k_1}\\lambda_2^{k_2}..\\lambda_{n-1}^{n-1}x^d$ for some $\\alpha\\in \\mathbb K$ we know this occurs *iff* the pre-image monomial was $\\alpha x_1^{k_1}x_2^{k_2}..x_{n-1}^{n-1}x^r$ where $r=d-\\sum_{j=1}^{n-1}k_j$.     \n",
    "- - - - -  \n",
    "\n",
    "Thus we have a polynomial $h(x_n)$ that is degree $d$ in $x_n$ which we may regard as a polynomial in $\\mathbb K[\\lambda_1,..,\\lambda_{n-1}][x_n] \\cong \\mathbb K[\\lambda_1,..,\\lambda_{n-1},x_n]$. Some satisfactory choice of $\\lambda_j$ for $j\\in\\{1,2..,n-1\\}$ must exist where this polynomial is not identically zero.  Equivalently there must be a substitution homomorphism that $\\lambda_j \\mapsto k_j \\in \\mathbb K$ where the image is non-zero (i.e. the image is $\\alpha \\cdot x_n^d$ for $\\alpha \\in \\mathbb K-\\{0\\}$.  \n",
    "\n",
    "*Justification:* Since $\\mathbb K$ is an infinite field and our polynomial has $n-1$ variables $[\\lambda_1,..,\\lambda_{n-1}]$ each of which is scaled by a coefficient in $\\mathbb K$ and then the sum is multiplied by $x_n^d$.  If this were mapped to zero everywhere under said substitution homomorphism, we could simplify the argument by setting $x_n:=1$ (another substitution homomorphism).  Hence it suffices to consider polynomials in $[\\lambda_1,..,\\lambda_{n-1}]$ with degree $\\leq d$ and coefficients in $\\mathbb K$ -- the sum of these polynomials is referred to as 'our polynomial'.  We may select $S \\subset \\mathbb K$ where $\\big \\vert S\\big \\vert = t$ and by Schwartz-Zippel, the probability that a point in $S^{n-1}$, selected uniformly at random, is zero under the image of our polynomial is $\\leq \\frac{d}{t}$; selecting $t$ large enough implies this probability is strictly less than one and hence a non-zero assignment must exist.   \n",
    "\n",
    "(For a different approach not using Schwartz-Zippel, one could specialize to $\\mathbb C$ and consider the complex multivariate Taylor polynomial in $[\\lambda_1,..,\\lambda_{n-1}]$ and repeatedly take partial derivatives -- if the function was identically zero then all $\\lambda_i:=0$ because the underlying taylor polynomial of degree d would be that of the zero function.)   \n",
    "\n",
    "Thus we know there exists and a (invertible) homomorpism from $R[\\mathbf x]\\longrightarrow R[\\mathbf x^*]$  given by  \n",
    "$\\phi(r)\\mapsto r$ for $r\\in R$  \n",
    "$\\phi(x_1)\\mapsto x_1^* + \\lambda_1 x_n*$  \n",
    "$\\vdots$  \n",
    "$\\phi(x_{n-1})\\mapsto x_{n-1}^*+\\lambda_{n-1}x_n^*$  \n",
    "$\\phi(x_n)\\mapsto x_n^*$  \n",
    "where $\\lambda_i$ are assigned to values in $\\mathbb K$ such that $(x_n^*)^d$ is a degree d monomial with a non-zero coefficient in $\\mathbb K$.  \n",
    "\n",
    "**ex 4.5.8**  \n",
    "Let $\\mathbb K$ be an infinite field and $I$ be a proper ideal of $\\mathbb K[x_1,...,x_n]$. Prove that there is a change of coordinates to that $I$ contains a polynomial $f$ that is monic in the variable $x_n$.   \n",
    "\n",
    "using the prior exercise we have and the surjectivity of our homormophism  \n",
    "$\\phi\\big(I\\big) = I^* \\in R[\\mathbf x^*]$  \n",
    "\n",
    "then consider $I^{**} := \\alpha^{-1} I^*$ which would map our polynomial $\\alpha x^d \\mapsto x^d$  \n",
    "but since ideals are closed under scaling, i.e. $i \\in I^* \\implies \\alpha^{-1} \\cdot i \\in I^*$  we see that  \n",
    "$I^{**} = I^*$ hence $I^*$ contains a polynomial $f$ that is monic in the variable $x_n$.  \n",
    "\n",
    "\n",
    "**conclusion:**  \n",
    "what this means for the proof of the weak Nullstellansatz is that we are able to assume WLOG that our ideal $I \\in R[x_1,...,x_{n-1},x_n]$ has a polynomial that is monic in $x_n$.  Our goal is to prove that $I$ is not the unit ideal.  So we 'actually' are doing is showing that the isomorphic case of $I^*\\in R[x_1^*,...,x_{n-1}^*,x_n^*]$ is not the unit ideal, hence $1 \\notin I^*$ but this means that $1 \\notin I$ (invert the isomorphism, or recognize that homomorphism maps the multiplicative identity to the multiplicative identity hence if 1 was not in the image $I^*$ then it wasn't in the preimage $I$).      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
